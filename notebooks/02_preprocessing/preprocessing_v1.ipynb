{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ë²„ì „ê´€ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec  3 13:30:09 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  | 00000000:4C:00.0 Off |                  N/A |\n",
      "| 40%   31C    P8              18W / 350W |  22044MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbZ7SU9P2TYN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /data/ephemeral/home/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "from pathlib import Path\n",
    "from transformers import BartForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from datetime import datetime\n",
    "\n",
    "import wandb\n",
    "wandb.login(key=\"\")                     # API KEY ì…ë ¥\n",
    "\n",
    "# # wandb êº¼ë‘ê¸°\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qq46k6_CNQn"
   },
   "source": [
    "### Config ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "referenced_widgets": [
      "e920dbc173c045d1a32143349f1dff8e",
      "58c794fb7ce543a39fdf66d757f6eeab",
      "8a6464a355f7464c989033965d418a8a",
      "3645438ace1f4596a8dbc157b48c1521",
      "58001a60eacc44d5b38a68648adccde4",
      "6f5fde5b0ac840a18bd5cc380e564ff6",
      "45187decb58b4ad39ad532259c6277e5",
      "2307c6dcbe0141acb5e61baae19cade7",
      "4747b668e2fa4ab58a449446f80030f5",
      "14f6c91d6c634379b498586c51e606e0",
      "08d05bc20a96432badd459e1ffaf868e",
      "5dfcf310ca9e4e2794076098a5d69cea",
      "3c284a826f6843f6aa47eacad478ac30",
      "6caedd60c6b747469c82930be1f95d6d",
      "64f2218f899d446393cfea44f206f0a6",
      "d068f541df3f438dbd5138863e64b2f2",
      "affff1d8a89e4c14955d1b2aa39ff1ab",
      "13651c09564a4337b8274c1cb436faa5",
      "3bcd6b6b956347b29e1efa20a1d00542",
      "2fd3d7bbcd6948d8904d33001f95ea03",
      "d22fbc2c5dbf422399e496c9b500025a",
      "775d8bbeceac4e2da4f21ab6235c89ed",
      "de1a3f7701c243839fe03b930a9b9e30",
      "ebc22683058a4f229c5588e52fc93536",
      "52095cc7087243ac916055e569fd22f3",
      "a15af9e8158f4903b9189f3d322a5ef3",
      "21d2e54b5a0a4f79973a512105da43eb",
      "083ea69907bb48d4a8fff919bac51aad",
      "2a190bda0b72407e9a953cd2104dd3b2",
      "c18f0e3bc35e44d9915c3f84cd282a26",
      "3a04e871b74b45d7bf02fd33bb103577",
      "ac00d6c2cf974b33a628acb3f1471316",
      "285007b45236478ca147c6df752c8da4"
     ]
    },
    "id": "gZOE9TInCQHJ",
    "outputId": "8ce58487-6199-408c-cb37-49af1e218bc2"
   },
   "outputs": [],
   "source": [
    "# config ì„¤ì •ì— tokenizer ëª¨ë“ˆì´ ì‚¬ìš©ë˜ë¯€ë¡œ ë¯¸ë¦¬ tokenizerë¥¼ ì •ì˜í•´ì¤ë‹ˆë‹¤.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "5vsACJI7CVb8"
   },
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"../data/\",\n",
    "        \"data_raw_path\": \"../data/raw/\",                                       \n",
    "        \"model_name\": \"digit82/kobart-summarization\",                           # ëª¨ë¸ ì´ë¦„\n",
    "        \"output_dir\": \"../outputs/checkpoints/\"                                 \n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 512,\n",
    "        \"decoder_max_len\": 100,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#',\n",
    "                           '#PhoneNumber#', '#Address#', '#PassportNumber#']    # íŠ¹ì • ë‹¨ì–´ë“¤ì´ ë¶„í•´ë˜ì§€ ì•Šë„ë¡ í•˜ê¸° ìœ„í•¨\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 20,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"per_device_train_batch_size\": 50,\n",
    "        \"per_device_eval_batch_size\": 32,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine',\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 5,\n",
    "        \"fp16\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 100,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "        # \"report_to\": \"none\"  \n",
    "        \"report_to\": \"wandb\"                                                        # wandb ì‚¬ìš© ì˜µì…˜\n",
    "    },\n",
    "    \"wandb\": {\n",
    "        # \"entity\": \"bubblekid43\",                                                   \n",
    "        \"project\": \"NLP-private\",                                                   \n",
    "        \"name\": \"preprocessed_v1\"                                                       # ë²„ì „ê´€ë¦¬\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"../outputs/checkpoints/\",                                      \n",
    "        \"result_path\": \"../outputs/prediction/\",\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 100,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\" : 32,\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\",\n",
    "                          f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]       # ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì •ì˜\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "REJybO5UCabF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ config ì €ì¥ ì™„ë£Œ : ../configs/config_v1.yaml\n",
      "\n",
      "ğŸ” config êµ¬ì„± ì •ë³´ í™•ì¸\n",
      "{'general': {'data_path': '../data/', 'data_raw_path': '../data/raw/', 'model_name': 'digit82/kobart-summarization', 'output_dir': '../outputs/checkpoints/'}, 'inference': {'batch_size': 32, 'ckt_path': '../outputs/checkpoints/', 'early_stopping': True, 'generate_max_length': 100, 'no_repeat_ngram_size': 2, 'num_beams': 4, 'remove_tokens': ['<usr>', '<s>', '</s>', '<pad>'], 'result_path': '../outputs/prediction/'}, 'tokenizer': {'bos_token': '<s>', 'decoder_max_len': 100, 'encoder_max_len': 512, 'eos_token': '</s>', 'special_tokens': ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#']}, 'training': {'do_eval': True, 'do_train': True, 'early_stopping_patience': 3, 'early_stopping_threshold': 0.001, 'evaluation_strategy': 'epoch', 'fp16': True, 'generation_max_length': 100, 'gradient_accumulation_steps': 1, 'learning_rate': 1e-05, 'load_best_model_at_end': True, 'logging_dir': './logs', 'logging_strategy': 'epoch', 'lr_scheduler_type': 'cosine', 'num_train_epochs': 20, 'optim': 'adamw_torch', 'overwrite_output_dir': True, 'per_device_eval_batch_size': 32, 'per_device_train_batch_size': 50, 'predict_with_generate': True, 'report_to': 'wandb', 'save_strategy': 'epoch', 'save_total_limit': 5, 'seed': 42, 'warmup_ratio': 0.1, 'weight_decay': 0.01}, 'wandb': {'name': 'preprocessed_v1', 'project': 'NLP-private'}}\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ì˜ êµ¬ì„± ì •ë³´ë¥¼ YAML íŒŒì¼ë¡œ ì €ì¥\n",
    "config_path = \"../configs/config_v1.yaml\"                                            # ë²„ì „ê´€ë¦¬\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)\n",
    "print(f\"ğŸ’¾ config ì €ì¥ ì™„ë£Œ : {config_path}\")\n",
    "\n",
    "# ì €ì¥ëœ config íŒŒì¼ ë¶ˆëŸ¬ì™€ì„œ ë‚´ìš© í™•ì¸\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "print(\"\\nğŸ” config êµ¬ì„± ì •ë³´ í™•ì¸\")\n",
    "print(loaded_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2zt0b-8ogCL"
   },
   "source": [
    "### ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "QFHIE2G04y-K",
    "outputId": "19312d21-f5bf-495f-c626-cc17b82024a4"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„° ê²½ë¡œ ì •ì˜\n",
    "data_path = Path(loaded_config['general']['data_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train_df.head()\n",
      "     fname                                           dialogue  \\\n",
      "0  train_0  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mr. Smith. ì €ëŠ” Dr. Hawkinsì…ë‹ˆë‹¤...   \n",
      "1  train_1  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mrs. Parker. ì˜ ì§€ë‚´ì…¨ë‚˜ìš”?\\n#Pers...   \n",
      "2  train_2  #Person1#: ì €ê¸°ìš”, ì—´ì‡  ì„¸íŠ¸ ë³¸ ì  ìˆì–´ìš”?\\n#Person2#: ì–´ë–¤ ...   \n",
      "3  train_3  #Person1#: ë„ˆ ì—¬ìì¹œêµ¬ ìˆëŠ” ê±° ì™œ ë§ ì•ˆ í–ˆì–´?\\n#Person2#: ë¯¸...   \n",
      "4  train_4  #Person1#: ì•ˆë…•, ì˜¤ëŠ˜ ë„ˆë¬´ ë©‹ì ¸ ë³´ì´ë„¤ìš”. ì €ë‘ ì¶¤ í•œ ê³¡ ì¶”ì‹¤ë˜ìš”?\\n...   \n",
      "\n",
      "                                             summary      topic  \n",
      "0  Mr. SmithëŠ” Dr. Hawkinsì—ê²Œ ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ëŸ¬ ì™€ì„œ, ë§¤ë…„ ê²€ì§„ í•„...       ê±´ê°•ê²€ì§„  \n",
      "1  Mrs. Parkerê°€ Rickyì™€ í•¨ê»˜ ë°±ì‹  ì ‘ì¢…ì„ ìœ„í•´ ë°©ë¬¸í•˜ì˜€ê³ , Dr. Pe...      ë°±ì‹  ì ‘ì¢…  \n",
      "2  #Person1#ì€ ì—´ì‡  ì„¸íŠ¸ë¥¼ ìƒì–´ë²„ë¦¬ê³  #Person2#ì—ê²Œ ì°¾ëŠ” ê²ƒì„ ë„ì™€ë‹¬ë¼...      ì—´ì‡  ë¶„ì‹¤  \n",
      "3  #Person1#ì€ #Person2#ê°€ ì—¬ìì¹œêµ¬ê°€ ìˆê³  ê²°í˜¼í•  ì˜ˆì •ì´ë¼ëŠ” ì‚¬ì‹¤ì„ ë§...  ì—¬ìì¹œêµ¬ì™€ì˜ ê²°í˜¼  \n",
      "4  Malikì€ Wenê³¼ Nikkiì—ê²Œ ì¶¤ì„ ì œì•ˆí•˜ê³ , Wenì€ ë°œì„ ë°ŸëŠ” ê²ƒì„ ê°ìˆ˜í•˜...       ì¶¤ ì œì•ˆ  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>#Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mr. Smith. ì €ëŠ” Dr. Hawkinsì…ë‹ˆë‹¤...</td>\n",
       "      <td>Mr. SmithëŠ” Dr. Hawkinsì—ê²Œ ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ëŸ¬ ì™€ì„œ, ë§¤ë…„ ê²€ì§„ í•„...</td>\n",
       "      <td>ê±´ê°•ê²€ì§„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>#Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mrs. Parker. ì˜ ì§€ë‚´ì…¨ë‚˜ìš”?\\n#Pers...</td>\n",
       "      <td>Mrs. Parkerê°€ Rickyì™€ í•¨ê»˜ ë°±ì‹  ì ‘ì¢…ì„ ìœ„í•´ ë°©ë¬¸í•˜ì˜€ê³ , Dr. Pe...</td>\n",
       "      <td>ë°±ì‹  ì ‘ì¢…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>#Person1#: ì €ê¸°ìš”, ì—´ì‡  ì„¸íŠ¸ ë³¸ ì  ìˆì–´ìš”?\\n#Person2#: ì–´ë–¤ ...</td>\n",
       "      <td>#Person1#ì€ ì—´ì‡  ì„¸íŠ¸ë¥¼ ìƒì–´ë²„ë¦¬ê³  #Person2#ì—ê²Œ ì°¾ëŠ” ê²ƒì„ ë„ì™€ë‹¬ë¼...</td>\n",
       "      <td>ì—´ì‡  ë¶„ì‹¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>#Person1#: ë„ˆ ì—¬ìì¹œêµ¬ ìˆëŠ” ê±° ì™œ ë§ ì•ˆ í–ˆì–´?\\n#Person2#: ë¯¸...</td>\n",
       "      <td>#Person1#ì€ #Person2#ê°€ ì—¬ìì¹œêµ¬ê°€ ìˆê³  ê²°í˜¼í•  ì˜ˆì •ì´ë¼ëŠ” ì‚¬ì‹¤ì„ ë§...</td>\n",
       "      <td>ì—¬ìì¹œêµ¬ì™€ì˜ ê²°í˜¼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>#Person1#: ì•ˆë…•, ì˜¤ëŠ˜ ë„ˆë¬´ ë©‹ì ¸ ë³´ì´ë„¤ìš”. ì €ë‘ ì¶¤ í•œ ê³¡ ì¶”ì‹¤ë˜ìš”?\\n...</td>\n",
       "      <td>Malikì€ Wenê³¼ Nikkiì—ê²Œ ì¶¤ì„ ì œì•ˆí•˜ê³ , Wenì€ ë°œì„ ë°ŸëŠ” ê²ƒì„ ê°ìˆ˜í•˜...</td>\n",
       "      <td>ì¶¤ ì œì•ˆ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fname                                           dialogue  \\\n",
       "0  train_0  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mr. Smith. ì €ëŠ” Dr. Hawkinsì…ë‹ˆë‹¤...   \n",
       "1  train_1  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mrs. Parker. ì˜ ì§€ë‚´ì…¨ë‚˜ìš”?\\n#Pers...   \n",
       "2  train_2  #Person1#: ì €ê¸°ìš”, ì—´ì‡  ì„¸íŠ¸ ë³¸ ì  ìˆì–´ìš”?\\n#Person2#: ì–´ë–¤ ...   \n",
       "3  train_3  #Person1#: ë„ˆ ì—¬ìì¹œêµ¬ ìˆëŠ” ê±° ì™œ ë§ ì•ˆ í–ˆì–´?\\n#Person2#: ë¯¸...   \n",
       "4  train_4  #Person1#: ì•ˆë…•, ì˜¤ëŠ˜ ë„ˆë¬´ ë©‹ì ¸ ë³´ì´ë„¤ìš”. ì €ë‘ ì¶¤ í•œ ê³¡ ì¶”ì‹¤ë˜ìš”?\\n...   \n",
       "\n",
       "                                             summary      topic  \n",
       "0  Mr. SmithëŠ” Dr. Hawkinsì—ê²Œ ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ëŸ¬ ì™€ì„œ, ë§¤ë…„ ê²€ì§„ í•„...       ê±´ê°•ê²€ì§„  \n",
       "1  Mrs. Parkerê°€ Rickyì™€ í•¨ê»˜ ë°±ì‹  ì ‘ì¢…ì„ ìœ„í•´ ë°©ë¬¸í•˜ì˜€ê³ , Dr. Pe...      ë°±ì‹  ì ‘ì¢…  \n",
       "2  #Person1#ì€ ì—´ì‡  ì„¸íŠ¸ë¥¼ ìƒì–´ë²„ë¦¬ê³  #Person2#ì—ê²Œ ì°¾ëŠ” ê²ƒì„ ë„ì™€ë‹¬ë¼...      ì—´ì‡  ë¶„ì‹¤  \n",
       "3  #Person1#ì€ #Person2#ê°€ ì—¬ìì¹œêµ¬ê°€ ìˆê³  ê²°í˜¼í•  ì˜ˆì •ì´ë¼ëŠ” ì‚¬ì‹¤ì„ ë§...  ì—¬ìì¹œêµ¬ì™€ì˜ ê²°í˜¼  \n",
       "4  Malikì€ Wenê³¼ Nikkiì—ê²Œ ì¶¤ì„ ì œì•ˆí•˜ê³ , Wenì€ ë°œì„ ë°ŸëŠ” ê²ƒì„ ê°ìˆ˜í•˜...       ì¶¤ ì œì•ˆ  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train data\n",
    "train_df = pd.read_csv(data_path / 'raw' / 'train.csv')\n",
    "print('âœ… train_df.head()')\n",
    "print(train_df.head())\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "FAGaYvNZ09Sq",
    "outputId": "bf8bf286-19e7-469d-ffae-41e6ad795ae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… val_df.head()\n",
      "   fname                                           dialogue  \\\n",
      "0  dev_0  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸ìš”?\\n#Person2#: ìš”ì¦˜ ...   \n",
      "1  dev_1  #Person1#: ì•¼ Jimmy, ì˜¤ëŠ˜ ì¢€ ì´ë”° ìš´ë™í•˜ëŸ¬ ê°€ì.\\n#Person2...   \n",
      "2  dev_2  #Person1#: ë‚˜ ì§„ì§œ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ ì¢€ ê·¸ë§Œ ë¨¹ì–´ì•¼ê² ì–´. \\n#Per...   \n",
      "3  dev_3  #Person1#: ë„ˆ UFO ë¯¿ì–´?\\n#Person2#: ë‹¹ì—°í•˜ì§€, ìˆëŠ” ê±° ì•„ëƒ...   \n",
      "4  dev_4  #Person1#: ì˜¤ëŠ˜ í•™êµ ê°”ì–´?\\n#Person2#: ë‹¹ì—°íˆ ê°”ì§€. ë„ˆëŠ”?\\n...   \n",
      "\n",
      "                                             summary      topic  \n",
      "0  #Person2#ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2#ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜...      ì˜ì‚¬ ìƒë‹´  \n",
      "1   #Person1#ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.      ìš´ë™ ê³„íš  \n",
      "2  #Person1#ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2#...     ê±´ê°•í•œ ì‹ë‹¨  \n",
      "3  #Person2#ëŠ” UFOë¥¼ ë¯¿ê³  ê¿ˆì—ì„œ ë³¼ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤. #Person1#ì€ ...   UFOì™€ ì™¸ê³„ì¸  \n",
      "4  #Person1#ì€ ì˜¤ëŠ˜ í•™êµì— ê°€ì§€ ì•Šì•˜ê³ , #Person2#ëŠ” ë‚´ì¼ í•™êµ ëŒ€ì‹  ...  í•™êµì™€ ì£¼ë§ ê³„íš  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_0</td>\n",
       "      <td>#Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸ìš”?\\n#Person2#: ìš”ì¦˜ ...</td>\n",
       "      <td>#Person2#ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2#ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜...</td>\n",
       "      <td>ì˜ì‚¬ ìƒë‹´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_1</td>\n",
       "      <td>#Person1#: ì•¼ Jimmy, ì˜¤ëŠ˜ ì¢€ ì´ë”° ìš´ë™í•˜ëŸ¬ ê°€ì.\\n#Person2...</td>\n",
       "      <td>#Person1#ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.</td>\n",
       "      <td>ìš´ë™ ê³„íš</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_2</td>\n",
       "      <td>#Person1#: ë‚˜ ì§„ì§œ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ ì¢€ ê·¸ë§Œ ë¨¹ì–´ì•¼ê² ì–´. \\n#Per...</td>\n",
       "      <td>#Person1#ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2#...</td>\n",
       "      <td>ê±´ê°•í•œ ì‹ë‹¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_3</td>\n",
       "      <td>#Person1#: ë„ˆ UFO ë¯¿ì–´?\\n#Person2#: ë‹¹ì—°í•˜ì§€, ìˆëŠ” ê±° ì•„ëƒ...</td>\n",
       "      <td>#Person2#ëŠ” UFOë¥¼ ë¯¿ê³  ê¿ˆì—ì„œ ë³¼ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤. #Person1#ì€ ...</td>\n",
       "      <td>UFOì™€ ì™¸ê³„ì¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev_4</td>\n",
       "      <td>#Person1#: ì˜¤ëŠ˜ í•™êµ ê°”ì–´?\\n#Person2#: ë‹¹ì—°íˆ ê°”ì§€. ë„ˆëŠ”?\\n...</td>\n",
       "      <td>#Person1#ì€ ì˜¤ëŠ˜ í•™êµì— ê°€ì§€ ì•Šì•˜ê³ , #Person2#ëŠ” ë‚´ì¼ í•™êµ ëŒ€ì‹  ...</td>\n",
       "      <td>í•™êµì™€ ì£¼ë§ ê³„íš</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fname                                           dialogue  \\\n",
       "0  dev_0  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸ìš”?\\n#Person2#: ìš”ì¦˜ ...   \n",
       "1  dev_1  #Person1#: ì•¼ Jimmy, ì˜¤ëŠ˜ ì¢€ ì´ë”° ìš´ë™í•˜ëŸ¬ ê°€ì.\\n#Person2...   \n",
       "2  dev_2  #Person1#: ë‚˜ ì§„ì§œ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ ì¢€ ê·¸ë§Œ ë¨¹ì–´ì•¼ê² ì–´. \\n#Per...   \n",
       "3  dev_3  #Person1#: ë„ˆ UFO ë¯¿ì–´?\\n#Person2#: ë‹¹ì—°í•˜ì§€, ìˆëŠ” ê±° ì•„ëƒ...   \n",
       "4  dev_4  #Person1#: ì˜¤ëŠ˜ í•™êµ ê°”ì–´?\\n#Person2#: ë‹¹ì—°íˆ ê°”ì§€. ë„ˆëŠ”?\\n...   \n",
       "\n",
       "                                             summary      topic  \n",
       "0  #Person2#ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2#ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜...      ì˜ì‚¬ ìƒë‹´  \n",
       "1   #Person1#ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.      ìš´ë™ ê³„íš  \n",
       "2  #Person1#ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2#...     ê±´ê°•í•œ ì‹ë‹¨  \n",
       "3  #Person2#ëŠ” UFOë¥¼ ë¯¿ê³  ê¿ˆì—ì„œ ë³¼ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤. #Person1#ì€ ...   UFOì™€ ì™¸ê³„ì¸  \n",
       "4  #Person1#ì€ ì˜¤ëŠ˜ í•™êµì— ê°€ì§€ ì•Šì•˜ê³ , #Person2#ëŠ” ë‚´ì¼ í•™êµ ëŒ€ì‹  ...  í•™êµì™€ ì£¼ë§ ê³„íš  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# validation data\n",
    "val_df = pd.read_csv(data_path / 'raw' / 'dev.csv')\n",
    "print('âœ… val_df.head()')\n",
    "print(val_df.head())\n",
    "display(val_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… test_df: (499, 2)\n",
      "    fname                                           dialogue\n",
      "0  test_0  #Person1#: Ms. Dawson, ë°›ì•„ì“°ê¸° ì¢€ ë¶€íƒë“œë ¤ì•¼ê² ì–´ìš”. \\n#Per...\n",
      "1  test_1  #Person1#: ë“œë””ì–´ ì™”ë„¤! ë­ê°€ ì´ë ‡ê²Œ ì˜¤ë˜ ê±¸ë ¸ì–´?\\n#Person2#: ...\n",
      "2  test_2  #Person1#: Kate, ì—¬ê¸°ì„œ ì¼ì–´ë‚œ ì¼ì„ ë¯¿ê¸° í˜ë“¤ ê±°ì•¼.\\n#Person...\n",
      "3  test_3  #Person1#: ìƒì¼ ì¶•í•˜í•´, ì´ê±° ë„ˆë¥¼ ìœ„í•œ ì„ ë¬¼ì´ì•¼, Brian.\\n#Per...\n",
      "4  test_4  #Person1#: ì´ ì˜¬ë¦¼í”½ ê³µì› ì •ë§ í¬ë‹¤! \\n#Person2#: ë§ì•„. ì§€ê¸ˆ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>#Person1#: Ms. Dawson, ë°›ì•„ì“°ê¸° ì¢€ ë¶€íƒë“œë ¤ì•¼ê² ì–´ìš”. \\n#Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person1#: ë“œë””ì–´ ì™”ë„¤! ë­ê°€ ì´ë ‡ê²Œ ì˜¤ë˜ ê±¸ë ¸ì–´?\\n#Person2#: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>#Person1#: Kate, ì—¬ê¸°ì„œ ì¼ì–´ë‚œ ì¼ì„ ë¯¿ê¸° í˜ë“¤ ê±°ì•¼.\\n#Person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>#Person1#: ìƒì¼ ì¶•í•˜í•´, ì´ê±° ë„ˆë¥¼ ìœ„í•œ ì„ ë¬¼ì´ì•¼, Brian.\\n#Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person1#: ì´ ì˜¬ë¦¼í”½ ê³µì› ì •ë§ í¬ë‹¤! \\n#Person2#: ë§ì•„. ì§€ê¸ˆ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fname                                           dialogue\n",
       "0  test_0  #Person1#: Ms. Dawson, ë°›ì•„ì“°ê¸° ì¢€ ë¶€íƒë“œë ¤ì•¼ê² ì–´ìš”. \\n#Per...\n",
       "1  test_1  #Person1#: ë“œë””ì–´ ì™”ë„¤! ë­ê°€ ì´ë ‡ê²Œ ì˜¤ë˜ ê±¸ë ¸ì–´?\\n#Person2#: ...\n",
       "2  test_2  #Person1#: Kate, ì—¬ê¸°ì„œ ì¼ì–´ë‚œ ì¼ì„ ë¯¿ê¸° í˜ë“¤ ê±°ì•¼.\\n#Person...\n",
       "3  test_3  #Person1#: ìƒì¼ ì¶•í•˜í•´, ì´ê±° ë„ˆë¥¼ ìœ„í•œ ì„ ë¬¼ì´ì•¼, Brian.\\n#Per...\n",
       "4  test_4  #Person1#: ì´ ì˜¬ë¦¼í”½ ê³µì› ì •ë§ í¬ë‹¤! \\n#Person2#: ë§ì•„. ì§€ê¸ˆ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test data\n",
    "test_df = pd.read_csv(data_path / 'raw' / 'test.csv')\n",
    "print('âœ… test_df:', test_df.shape)\n",
    "print(test_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IIaIrpH4kWo"
   },
   "source": [
    "### ë°ì´í„° ê°€ê³µ ë° ë°ì´í„°ì…‹ í´ë˜ìŠ¤ êµ¬ì¶•\n",
    ">- csv file ì„ ë¶ˆëŸ¬ì™€ì„œ encoder ì™€ decoderì˜ ì…ë ¥í˜•íƒœë¡œ ê°€ê³µí•˜ê¸°\n",
    ">- ê°€ê³µëœ ë°ì´í„°ë¥¼ torch dataset class ë¡œ êµ¬ì¶•í•˜ì—¬ ëª¨ë¸ì— ì…ë ¥ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== ì „ì²˜ë¦¬ ìœ í‹¸ í•¨ìˆ˜ë“¤ ========== #\n",
    "\n",
    "# 1. í™”ì íƒœê·¸ 1/2 ì •ê·œí™”\n",
    "    # normalize_speaker_tags()ì—ì„œ\n",
    "    # í•œ ìƒ˜í”Œ ë‚´ì—ì„œ ë“±ì¥í•˜ëŠ” #PersonX#ë“¤ì„\n",
    "        # 1ë²ˆì§¸ ë“±ì¥ â†’ #Person1#\n",
    "        # 2ë²ˆì§¸ ë“±ì¥ â†’ #Person2#\n",
    "        # ê·¸ ì´í›„ â†’ ì „ë¶€ #Person2#ë¡œ í•©ì¹˜ë„ë¡ ì„¤ê³„\n",
    "    # dialogueì™€ summaryì— ë™ì¼ ë§¤í•‘ ì ìš©\n",
    "\n",
    "# 2. turn êµ¬ì¡° ì •ë¦¬\n",
    "    # ì¤„ ë‹¨ìœ„(\\n)ë¥¼ ìœ ì§€í•˜ë©´ì„œ\n",
    "    # ê° ì¤„ë§ˆë‹¤ strip / ê³µë°± ì •ê·œí™”ë§Œ ìˆ˜í–‰\n",
    "    # ì¤„ ìì²´ë¥¼ í•©ì¹˜ê±°ë‚˜ ìˆœì„œë¥¼ ë°”ê¾¸ì§€ ì•ŠìŒ\n",
    "\n",
    "# 3. ê³µë°±/ê°œí–‰ ì •ê·œí™”\n",
    "# normalize_spaces_and_newlines()ì—ì„œ\n",
    "# ì¤„ ì•ë’¤ ê³µë°± ì œê±°, ì¤‘ë³µ ê³µë°±ì„ \" \" í•œ ì¹¸ìœ¼ë¡œ í†µì¼\n",
    "# ì™„ì „ ë¹ˆ ì¤„ ì‚­ì œ\n",
    "\n",
    "# 4. íŠ¹ìˆ˜ë¬¸ì (..., !! ë“±) ì •ê·œí™”\n",
    "# normalize_special_chars()ì—ì„œ\n",
    "# ..., ...., ....... â†’ ...\n",
    "# !!, !!!! â†’ !\n",
    "# ??, ???? â†’ ?\n",
    "# ~~, ~~~ â†’ ~\n",
    "\n",
    "# 5. Tier1 ë…¸ì´ì¦ˆ ì¶•ì•½\n",
    "# compress_tier1_noise()ì—ì„œ\n",
    "# ã…‹ã…‹ã…‹ã…‹ â†’ ã…‹ã…‹, ã…ã…ã…ã… â†’ ã…ã…\n",
    "# ã… ã… ã… , ã…œã…œã…œ â†’ ã… ã… \n",
    "# ì–´ì–´ì–´ì–´, ì•„ì•„ì•„, ìœ¼ìœ¼ìœ¼, ìŒìŒìŒ ê°™ì€ ê±´\n",
    "    # ì–´ / ì•„ / ìŒ ìœ¼ë¡œ ì¶•ì•½\n",
    "\n",
    "# 6. leading filler ì œê±°\n",
    "# remove_leading_filler_after_tag()ì—ì„œ\n",
    "# íŒ¨í„´: #PersonX#: ë„¤, ... â†’ #PersonX#: ...\n",
    "# ë„¤,, ì•„,, ì‘,, ìŒ,, ì–´,, ê·¸ë˜, ëª¨ë‘ ì œê±° ëŒ€ìƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™” (..., !!, ??? ë“±)\n",
    "def normalize_special_chars(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # ... ë˜ëŠ” ....... â†’ ...\n",
    "    text = re.sub(r\"\\.{3,}\", \"...\", text)\n",
    "    # !!!, !!!! â†’ !\n",
    "    text = re.sub(r\"!{2,}\", \"!\", text)\n",
    "    # ???, ???? â†’ ?\n",
    "    text = re.sub(r\"\\?{2,}\", \"?\", text)\n",
    "    # ~~, ~~~ â†’ ~\n",
    "    text = re.sub(r\"~{2,}\", \"~\", text)\n",
    "    return text\n",
    "\n",
    "# 2) ê³µë°±/ê°œí–‰ ì •ê·œí™”\n",
    "def normalize_spaces_and_newlines(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # ê°œë³„ ì¤„ ì²˜ë¦¬: ì–‘ë ê³µë°± ì œê±° + ì¤‘ë³µ ê³µë°± ì œê±°\n",
    "    lines = text.split(\"\\n\")\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        line = re.sub(r\"\\s{2,}\", \" \", line)  # ì¤‘ë³µ ê³µë°± â†’ í•œ ì¹¸\n",
    "        if line:  # ì™„ì „ ë¹ˆ ì¤„ì€ ì œê±°\n",
    "            new_lines.append(line)\n",
    "    return \"\\n\".join(new_lines)\n",
    "\n",
    "# 3) Tier1 ë…¸ì´ì¦ˆ ì¶•ì•½ (ã…‹,ã…,ã… ,ã…œ, ì–´/ì•„/ìŒ ë°˜ë³µ ë“±)\n",
    "def compress_tier1_noise(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    # ã…‹ã…‹ã…‹ã…‹, ã…ã…ã…ã… â†’ ã…‹ã…‹ / ã…ã…\n",
    "    text = re.sub(r\"[ã…‹]{2,}\", \"ã…‹ã…‹\", text)\n",
    "    text = re.sub(r\"[ã…]{2,}\", \"ã…ã…\", text)\n",
    "\n",
    "    # ã… ã… ã… ã… , ã…œã…œã…œ â†’ ã… ã… \n",
    "    text = re.sub(r\"[ã… ã…œ]{2,}\", \"ã… ã… \", text)\n",
    "\n",
    "    # ì–´ì–´ì–´ì–´, ì•„ì•„ì•„ì•„, ìœ¼ìœ¼ìœ¼ â†’ ì–´ / ì•„ / ìŒ ìœ¼ë¡œ ì¶•ì•½\n",
    "    def _compress_filler_token(token: str) -> str:\n",
    "        # ì–´/ì•„/ìŒ/ìœ¼ + ë°˜ë³µ + ì•½ê°„ì˜ íŠ¹ìˆ˜ë¬¸ì\n",
    "        if re.fullmatch(r\"[ì•„ì–´ìœ¼ìŒ]+[\\.â€¦!?~]*\", token):\n",
    "            # 'ìŒ', 'ìœ¼' ê³„ì—´ì€ 'ìŒ'ìœ¼ë¡œ í†µì¼\n",
    "            if \"ìŒ\" in token or \"ìœ¼\" in token:\n",
    "                return \"ìŒ\"\n",
    "            # 'ì•„'ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ 'ì•„', ì•„ë‹ˆë©´ 'ì–´'\n",
    "            if \"ì•„\" in token:\n",
    "                return \"ì•„\"\n",
    "            return \"ì–´\"\n",
    "        return token\n",
    "\n",
    "    tokens = text.split(\" \")\n",
    "    tokens = [_compress_filler_token(tok) for tok in tokens]\n",
    "    text = \" \".join(tokens)\n",
    "\n",
    "    return text\n",
    "\n",
    "# 4) í™”ì íƒœê·¸ ì •ê·œí™” + 1/2ë¡œ ë§¤í•‘\n",
    "SPEAKER_TAG_PATTERN = re.compile(r\"^(#Person(\\d+)#):\")\n",
    "\n",
    "def normalize_speaker_tags(dialogue: str, summary: str | None = None):\n",
    "    \"\"\"\n",
    "    - dialogueë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ìŠ¤ìº”í•˜ë©´ì„œ\n",
    "    - ë“±ì¥í•˜ëŠ” í™”ì íƒœê·¸(#Person3#, #Person4# ë“±)ë¥¼\n",
    "      #Person1#, #Person2# ë‘ ê°œë¡œë§Œ ë§¤í•‘\n",
    "    - ê°™ì€ ìƒ˜í”Œ ë‚´ì—ì„œëŠ” dialogue/summary ëª¨ë‘ ì¼ê´€ëœ ë§¤í•‘ ì‚¬ìš©\n",
    "    \"\"\"\n",
    "    if not isinstance(dialogue, str):\n",
    "        return dialogue, summary\n",
    "\n",
    "    # 1) dialogueì—ì„œ í™”ì ë“±ì¥ ìˆœì„œì— ë”°ë¼ ë§¤í•‘ ìƒì„±\n",
    "    lines = dialogue.split(\"\\n\")\n",
    "    orig_to_norm = {}\n",
    "    next_slot = 1  # 1 â†’ #Person1#, 2 â†’ #Person2#\n",
    "\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        m = SPEAKER_TAG_PATTERN.match(line.strip())\n",
    "        if m:\n",
    "            full_tag = m.group(1)   # \"#PersonX#\"\n",
    "            spk_id = m.group(2)     # \"3\", \"4\", ...\n",
    "\n",
    "            if full_tag not in orig_to_norm:\n",
    "                if next_slot == 1:\n",
    "                    orig_to_norm[full_tag] = \"#Person1#\"\n",
    "                    next_slot = 2\n",
    "                elif next_slot == 2:\n",
    "                    orig_to_norm[full_tag] = \"#Person2#\"\n",
    "                    next_slot = 3\n",
    "                else:\n",
    "                    # ì„¸ ë²ˆì§¸ ì´í›„ í™”ìëŠ” ì „ë¶€ #Person2#ë¡œ í•©ì¹˜ê¸°\n",
    "                    orig_to_norm[full_tag] = \"#Person2#\"\n",
    "\n",
    "            norm_tag = orig_to_norm[full_tag]\n",
    "            # \"#PersonX#:\" â†’ \"#PersonY#:\"\n",
    "            line = re.sub(r\"^#Person\\d+#\", norm_tag, line.strip())\n",
    "        new_lines.append(line)\n",
    "\n",
    "    new_dialogue = \"\\n\".join(new_lines)\n",
    "\n",
    "    # 2) summaryì—ë„ ë™ì¼ ë§¤í•‘ ì ìš© (í˜¹ì‹œ ëª¨ë¥¼ #Person3# ë“±ì¥ ì¼€ì´ìŠ¤ ëŒ€ë¹„)\n",
    "    new_summary = summary\n",
    "    if isinstance(summary, str) and orig_to_norm:\n",
    "        for full_tag, norm_tag in orig_to_norm.items():\n",
    "            new_summary = new_summary.replace(full_tag, norm_tag)\n",
    "\n",
    "    return new_dialogue, new_summary\n",
    "\n",
    "# 5) leading filler ì œê±° (#PersonX#: ë„¤, / ì•„, / ì‘, / ìŒ ë“±)\n",
    "LEADING_FILLERS = (\"ë„¤\", \"ì•„\", \"ì‘\", \"ìŒ\", \"ì–´\", \"ê·¸ë˜\")\n",
    "\n",
    "def remove_leading_filler_after_tag(dialogue: str) -> str:\n",
    "    if not isinstance(dialogue, str):\n",
    "        return dialogue\n",
    "\n",
    "    lines = dialogue.split(\"\\n\")\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        # íŒ¨í„´: \"#PersonX#: ë„¤, ...\" â†’ \"#PersonX#: ...\"\n",
    "        pattern = r\"^(#Person\\d+#:\\s*)(%s)[,]?\\s*\" % \"|\".join(LEADING_FILLERS)\n",
    "        line = re.sub(pattern, r\"\\1\", line)\n",
    "        new_lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "oWPawUUflwHa"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ì…ë ¥ì„ ìƒì„±\n",
    "class Preprocess:\n",
    "    def __init__(self,\n",
    "            bos_token: str,\n",
    "            eos_token: str,\n",
    "        ) -> None:\n",
    "\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "\n",
    "    @staticmethod\n",
    "    def make_set_as_df(file_path, is_train: bool = True):\n",
    "        \"\"\"\n",
    "        ê¸°ì¡´ baselineê³¼ ë™ì¼í•œ ì—­í• :\n",
    "        - train/dev: fname, dialogue, summary\n",
    "        - test    : fname, dialogue\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        if is_train:\n",
    "            df = df[['fname', 'dialogue', 'summary']]\n",
    "        else:\n",
    "            df = df[['fname', 'dialogue']]\n",
    "        return df\n",
    "\n",
    "    def preprocess_pair(self, dialogue: str, summary: str | None = None, is_test: bool = False):\n",
    "        \"\"\"\n",
    "        Preprocess_v1 ì „ì²´ ì ìš©:\n",
    "        - í™”ì íƒœê·¸ 1/2 ì •ê·œí™”\n",
    "        - turn êµ¬ì¡° ìœ ì§€(ì¤„ ë‹¨ìœ„ ì²˜ë¦¬)\n",
    "        - ê³µë°±/ê°œí–‰ ì •ê·œí™”\n",
    "        - íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”\n",
    "        - Tier1 ë…¸ì´ì¦ˆ ì¶•ì•½\n",
    "        - leading filler ì œê±°\n",
    "        \"\"\"\n",
    "\n",
    "        # 1) í™”ì íƒœê·¸ 1/2 ì •ê·œí™” (dialogue & summary ë™ì‹œì—)\n",
    "        dialogue, summary = normalize_speaker_tags(dialogue, summary)\n",
    "\n",
    "        # 2) ê³µë°±/ê°œí–‰ ì •ê·œí™” (ì¤„ë‹¨ìœ„ strip + ë¹ˆì¤„ ì œê±°)\n",
    "        dialogue = normalize_spaces_and_newlines(dialogue)\n",
    "        if summary is not None:\n",
    "            summary = normalize_spaces_and_newlines(summary)\n",
    "\n",
    "        # 3) íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™” (.../!!/??/~~)\n",
    "        dialogue = normalize_special_chars(dialogue)\n",
    "        if summary is not None:\n",
    "            summary = normalize_special_chars(summary)\n",
    "\n",
    "        # 4) Tier1 ë…¸ì´ì¦ˆ ì¶•ì•½ (ì–´/ì•„/ìŒ, ã…‹ã…‹, ã… ã…  ë“±)\n",
    "        dialogue = compress_tier1_noise(dialogue)\n",
    "        if summary is not None:\n",
    "            summary = compress_tier1_noise(summary)\n",
    "\n",
    "        # 5) leading filler ì œê±° (#PersonX#: ë„¤, / ì•„, / ì‘, / ìŒ ë“±)\n",
    "        dialogue = remove_leading_filler_after_tag(dialogue)\n",
    "\n",
    "        if is_test:\n",
    "            return dialogue, None\n",
    "        else:\n",
    "            return dialogue, summary\n",
    "\n",
    "    # BART ëª¨ë¸ì˜ ì…ë ¥, ì¶œë ¥ í˜•íƒœë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì „ì²˜ë¦¬ë¥¼ ì§„í–‰\n",
    "    def make_input(self, dataset: pd.DataFrame, is_test: bool = False):\n",
    "        \"\"\"\n",
    "        - dataset: make_set_as_dfë¡œ ë§Œë“  df\n",
    "        - is_test:\n",
    "            - True  â†’ dialogueë§Œ ìˆê³  summary ì—†ìŒ\n",
    "            - False â†’ dialogue + summary ëª¨ë‘ ìˆìŒ\n",
    "        \"\"\"\n",
    "        if is_test:\n",
    "            encoder_input_list = []\n",
    "            decoder_input_list = []\n",
    "\n",
    "            for row in dataset.itertuples(index=False):\n",
    "                clean_dialogue, _ = self.preprocess_pair(row.dialogue, None, is_test=True)\n",
    "                encoder_input_list.append(clean_dialogue)\n",
    "                # testì—ì„œëŠ” ë””ì½”ë” ì…ë ¥ì— bos_tokenë§Œ ì‚¬ìš©\n",
    "                decoder_input_list.append(self.bos_token)\n",
    "\n",
    "            return encoder_input_list, decoder_input_list\n",
    "\n",
    "        else:\n",
    "            encoder_input_list = []\n",
    "            decoder_input_list = []\n",
    "            decoder_output_list = []\n",
    "\n",
    "            for row in dataset.itertuples(index=False):\n",
    "                clean_dialogue, clean_summary = self.preprocess_pair(row.dialogue, row.summary, is_test=False)\n",
    "\n",
    "                # encoder input: ì „ì²˜ë¦¬ëœ dialogue\n",
    "                encoder_input_list.append(clean_dialogue)\n",
    "\n",
    "                # decoder input: bos + summary (teacher forcing)\n",
    "                decoder_input_list.append(self.bos_token + str(clean_summary))\n",
    "\n",
    "                # decoder output: summary + eos\n",
    "                decoder_output_list.append(str(clean_summary) + self.eos_token)\n",
    "\n",
    "            return encoder_input_list, decoder_input_list, decoder_output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preprocessed_csv(preprocessor, config, version=\"v1\"):\n",
    "    \"\"\"\n",
    "    Preprocess_v1 ì ìš© â†’ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜\n",
    "    ì˜ˆ:\n",
    "        train_preprocessed_v1.csv\n",
    "        dev_preprocessed_v1.csv\n",
    "        test_preprocessed_v1.csv\n",
    "    \"\"\"\n",
    "    data_path = config['general']['data_path']\n",
    "\n",
    "    # --- íŒŒì¼ ê²½ë¡œ ì •ì˜ ---\n",
    "    train_path = f\"{data_path}/raw/train.csv\"\n",
    "    dev_path = f\"{data_path}/raw/dev.csv\"\n",
    "    test_path = f\"{data_path}/raw/test.csv\"\n",
    "\n",
    "    # --- ë°ì´í„° ë¡œë“œ ---\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    dev_df = pd.read_csv(dev_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    # ìƒˆ ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸°\n",
    "    new_train = []\n",
    "    new_dev = []\n",
    "    new_test = []\n",
    "\n",
    "    # ===== Train ì „ì²˜ë¦¬ =====\n",
    "    for row in train_df.itertuples(index=False):\n",
    "        clean_dialogue, clean_summary = preprocessor.preprocess_pair(\n",
    "            row.dialogue,\n",
    "            row.summary,\n",
    "            is_test=False\n",
    "        )\n",
    "        new_train.append([row.fname, clean_dialogue, clean_summary, row.topic])\n",
    "\n",
    "    # ===== Dev ì „ì²˜ë¦¬ =====\n",
    "    for row in dev_df.itertuples(index=False):\n",
    "        clean_dialogue, clean_summary = preprocessor.preprocess_pair(\n",
    "            row.dialogue,\n",
    "            row.summary,\n",
    "            is_test=False\n",
    "        )\n",
    "        new_dev.append([row.fname, clean_dialogue, clean_summary, row.topic])\n",
    "\n",
    "    # ===== Test ì „ì²˜ë¦¬ =====\n",
    "    for row in test_df.itertuples(index=False):\n",
    "        clean_dialogue, _ = preprocessor.preprocess_pair(\n",
    "            row.dialogue,\n",
    "            None,\n",
    "            is_test=True\n",
    "        )\n",
    "        new_test.append([row.fname, clean_dialogue])\n",
    "\n",
    "    # ===== pandas DataFrame ë³€í™˜ =====\n",
    "    new_train_df = pd.DataFrame(new_train, columns=[\"fname\", \"dialogue\", \"summary\", \"topic\"])\n",
    "    new_dev_df = pd.DataFrame(new_dev, columns=[\"fname\", \"dialogue\", \"summary\", \"topic\"])\n",
    "    new_test_df = pd.DataFrame(new_test, columns=[\"fname\", \"dialogue\"])\n",
    "\n",
    "    # ===== íŒŒì¼ë¡œ ì €ì¥ =====\n",
    "    save_dir = f\"{data_path}/processed/preprocessed_{version}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    new_train_df.to_csv(f\"{save_dir}/train_preprocessed_{version}.csv\", index=False)\n",
    "    new_dev_df.to_csv(f\"{save_dir}/dev_preprocessed_{version}.csv\", index=False)\n",
    "    new_test_df.to_csv(f\"{save_dir}/test_preprocessed_{version}.csv\", index=False)\n",
    "\n",
    "    print(\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ | ì €ì¥ ìœ„ì¹˜: {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "6GDvodoF8sED"
   },
   "outputs": [],
   "source": [
    "# Trainì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜\n",
    "class DatasetForTrain(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}      # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()}     # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        # item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item.update(item2)\n",
    "        # item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]                                                                  \n",
    "        item['labels'] = self.labels['input_ids'][idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Validationì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜\n",
    "class DatasetForVal(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}      # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()}     # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        # item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item.update(item2)\n",
    "        # item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        item['labels'] = self.labels['input_ids'][idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Testì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜\n",
    "class DatasetForInference(Dataset):\n",
    "    def __init__(self, encoder_input, test_id, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.test_id = test_id\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
    "        item['ID'] = self.test_id[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "hT9z4vvS2CCb"
   },
   "outputs": [],
   "source": [
    "# tokenization ê³¼ì •ê¹Œì§€ ì§„í–‰ëœ ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì— ì…ë ¥ë  ë°ì´í„°ë¥¼ ì¶œë ¥\n",
    "def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n",
    "    train_file_path = os.path.join(data_path, 'raw', 'train.csv')\n",
    "    val_file_path = os.path.join(data_path, 'raw', 'dev.csv')\n",
    "\n",
    "    # train, validationì— ëŒ€í•´ ê°ê° ë°ì´í„°í”„ë ˆì„ì„ êµ¬ì¶•\n",
    "    train_data = preprocessor.make_set_as_df(train_file_path)\n",
    "    val_data = preprocessor.make_set_as_df(val_file_path)\n",
    "\n",
    "    # print('\\nğŸš€ train, valid ë°ì´í„° ë¡œë“œ ì¤‘...')\n",
    "    encoder_input_train , decoder_input_train, decoder_output_train = preprocessor.make_input(train_data)\n",
    "    encoder_input_val , decoder_input_val, decoder_output_val = preprocessor.make_input(val_data)\n",
    "    print(\"\\nâœ… í•™ìŠµ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\")\n",
    "\n",
    "    # print('\\nğŸš€ train, valid ë°ì´í„°ì…‹ ìƒì„± ì¤‘...')\n",
    "    tokenized_encoder_inputs = tokenizer(encoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                            add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_inputs = tokenizer(decoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_ouputs = tokenizer(decoder_output_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    train_inputs_dataset = DatasetForTrain(tokenized_encoder_inputs, tokenized_decoder_inputs, tokenized_decoder_ouputs,len(encoder_input_train))\n",
    "\n",
    "    val_tokenized_encoder_inputs = tokenizer(encoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_inputs = tokenizer(decoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_ouputs = tokenizer(decoder_output_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    val_inputs_dataset = DatasetForVal(val_tokenized_encoder_inputs, val_tokenized_decoder_inputs, val_tokenized_decoder_ouputs,len(encoder_input_val))\n",
    "    print(\"\\nâœ… í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!\")\n",
    "\n",
    "    return train_inputs_dataset, val_inputs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5sKIJ5K5Pz1"
   },
   "source": [
    "### Trainer ë° Trainingargs êµ¬ì¶•í•˜ê¸°\n",
    ">- Huggingface ì˜ Trainer ì™€ Training argumentsë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµì„ ì¼ê´„ì ìœ¼ë¡œ ì²˜ë¦¬í•´ì£¼ëŠ” í´ë˜ìŠ¤ë¥¼ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "aQk8ILcEeGNz"
   },
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì„±ëŠ¥ì— ëŒ€í•œ í‰ê°€ ì§€í‘œ ì •ì˜\n",
    "def compute_metrics(config,tokenizer,pred):\n",
    "    rouge = Rouge()\n",
    "    predictions = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    # ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•´ ë¯¸ë¦¬ ì •ì˜ëœ ë¶ˆí•„ìš”í•œ ìƒì„± í† í°ë“¤ì„ ì œê±°\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "    remove_tokens = config['inference']['remove_tokens']        # configì—ì„œ ì •ì˜í•œ ë¶ˆí•„ìš”í•œ ìƒì„± í† í°\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "\n",
    "    print('\\nğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...')\n",
    "    print(f\"PRED: {replaced_predictions[0]}\")\n",
    "    print(f\"GOLD: {replaced_labels[0]}\")\n",
    "    # print('-'*150)\n",
    "    # print(f\"PRED: {replaced_predictions[1]}\")\n",
    "    # print(f\"GOLD: {replaced_labels[1]}\")\n",
    "    # print('-'*150)\n",
    "    # print(f\"PRED: {replaced_predictions[2]}\")\n",
    "    # print(f\"GOLD: {replaced_labels[2]}\")\n",
    "    print('\\nâœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!')\n",
    "\n",
    "    # ìµœì¢…ì ì¸ ROUGE ì ìˆ˜ë¥¼ ê³„ì‚°\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "\n",
    "    # ROUGE ì ìˆ˜ ì¤‘ F-1 scoreë¥¼ í†µí•´ í‰ê°€\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "RInkG8g-HjBi"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµì„ ìœ„í•œ trainer í´ë˜ìŠ¤ì™€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì •ì˜\n",
    "def load_trainer_for_train(config,generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset):\n",
    "    \n",
    "    # print('\\nğŸš€ training arguments ì •ì˜ ì¤‘...')\n",
    "    # set training args\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "                output_dir=config['general']['output_dir'],\n",
    "                overwrite_output_dir=config['training']['overwrite_output_dir'],\n",
    "                num_train_epochs=config['training']['num_train_epochs'],\n",
    "                learning_rate=config['training']['learning_rate'],\n",
    "                per_device_train_batch_size=config['training']['per_device_train_batch_size'],\n",
    "                per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],\n",
    "                warmup_ratio=config['training']['warmup_ratio'],\n",
    "                weight_decay=config['training']['weight_decay'],\n",
    "                lr_scheduler_type=config['training']['lr_scheduler_type'],\n",
    "                optim =config['training']['optim'],\n",
    "                gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],\n",
    "                evaluation_strategy=config['training']['evaluation_strategy'],\n",
    "                save_strategy =config['training']['save_strategy'],\n",
    "                save_total_limit=config['training']['save_total_limit'],\n",
    "                fp16=config['training']['fp16'],\n",
    "                load_best_model_at_end=config['training']['load_best_model_at_end'],\n",
    "                seed=config['training']['seed'],\n",
    "                logging_dir=config['training']['logging_dir'],\n",
    "                logging_strategy=config['training']['logging_strategy'],\n",
    "                predict_with_generate=config['training']['predict_with_generate'],\n",
    "                generation_max_length=config['training']['generation_max_length'],\n",
    "                do_train=config['training']['do_train'],\n",
    "                do_eval=config['training']['do_eval'],\n",
    "                report_to=config['training']['report_to']                             # wandb ì‚¬ìš© ì„¤ì •\n",
    "            )\n",
    "\n",
    "    # wandb ì´ˆê¸°í™”\n",
    "    wandb.init(\n",
    "        # entity=config['wandb']['entity'],\n",
    "        project=config['wandb']['project'],\n",
    "        name=config['wandb']['name'],\n",
    "        dir=\"/root/nlp-competition/wandb\",\n",
    "    )\n",
    "\n",
    "    # wandb checkpoints ì €ì¥í•˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •\n",
    "    os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "    os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "\n",
    "    # EarlyStopping : Validation lossê°€ ë” ì´ìƒ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ í•™ìŠµì„ ì¤‘ë‹¨\n",
    "    MyCallback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=config['training']['early_stopping_patience'],\n",
    "        early_stopping_threshold=config['training']['early_stopping_threshold']\n",
    "    )\n",
    "    print('\\nâœ… training arguments ì •ì˜ ì™„ë£Œ!')\n",
    "    \n",
    "    # print('\\nğŸš€ trainer ìƒì„± ì¤‘...')\n",
    "    # Trainer í´ë˜ìŠ¤ ì •ì˜\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=generate_model,                                                           # ì‚¬ìš©ìê°€ ì‚¬ì „ í•™ìŠµí•˜ê¸° ìœ„í•´ ì‚¬ìš©í•  ëª¨ë¸ ì…ë ¥\n",
    "        args=training_args,\n",
    "        train_dataset=train_inputs_dataset,\n",
    "        eval_dataset=val_inputs_dataset,\n",
    "        compute_metrics = lambda pred: compute_metrics(config,tokenizer, pred),\n",
    "        callbacks = [MyCallback]\n",
    "    )\n",
    "    print('\\nâœ… trainer ìƒì„± ì™„ë£Œ!')\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "KKWHe8dE5fSx"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµì„ ìœ„í•œ tokenizerì™€ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "def load_tokenizer_and_model_for_train(config,device):\n",
    "\n",
    "    # print('\\nğŸš€ tokenizer & model ë¡œë“œ ì¤‘...')\n",
    "    print(f'\\nğŸ¤– ëª¨ë¸ëª… : {config[\"general\"][\"model_name\"]}')\n",
    "    model_name = config['general']['model_name']\n",
    "    bart_config = BartConfig().from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    generate_model = BartForConditionalGeneration.from_pretrained(config['general']['model_name'],config=bart_config)\n",
    "\n",
    "    special_tokens_dict={'additional_special_tokens':config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))          # ì‚¬ì „ì— special tokenì„ ì¶”ê°€í–ˆìœ¼ë¯€ë¡œ ì¬êµ¬ì„±\n",
    "    generate_model.to(device)\n",
    "    # print(generate_model.config)\n",
    "    # print('âœ… tokenizer & model ë¡œë“œ ì™„ë£Œ!')\n",
    "\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´í¬í¬ì¸íŠ¸ í‰ê°€ í•¨ìˆ˜\n",
    "def eval_checkpoint(ckpt_path, config, tokenizer, eval_dataset):\n",
    "    print(f\"\\n=== Evaluate {ckpt_path} ===\")\n",
    "    model = BartForConditionalGeneration.from_pretrained(ckpt_path)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    args = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"../outputs/tmp_eval\",\n",
    "        per_device_eval_batch_size=config[\"training\"][\"per_device_eval_batch_size\"],\n",
    "        predict_with_generate=True,\n",
    "        do_train=False,\n",
    "        do_eval=True,\n",
    "        report_to=\"wandb\",           # wandb ì„¤ì •\n",
    "    )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=lambda pred: compute_metrics(config, tokenizer, pred),\n",
    "    )\n",
    "\n",
    "    metrics = trainer.evaluate()\n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best & ë§ˆì§€ë§‰ checkpoint ì°¾ëŠ” í•¨ìˆ˜\n",
    "def get_best_and_last_checkpoints(config):\n",
    "    output_dir = Path(config[\"general\"][\"output_dir\"])\n",
    "    ckpt_root = Path(config[\"inference\"][\"ckt_path\"])\n",
    "\n",
    "    # ë§ˆì§€ë§‰ checkpoint ì°¾ê¸°\n",
    "    ckpt_dirs = [p for p in ckpt_root.glob(\"checkpoint-*\") if p.is_dir()]\n",
    "    def _get_step(p: Path) -> int:\n",
    "        return int(p.name.split(\"-\")[-1])\n",
    "    ckpt_dirs = sorted(ckpt_dirs, key=_get_step)\n",
    "    last_ckpt = ckpt_dirs[-1]\n",
    "\n",
    "    # best checkpoint ì°¾ê¸°\n",
    "    state_path = last_ckpt / \"trainer_state.json\"\n",
    "    with open(state_path, \"r\") as f:\n",
    "        state = json.load(f)\n",
    "    best_ckpt = state.get(\"best_model_checkpoint\", None)\n",
    "\n",
    "    print(f\"\\nğŸš€ ì²´í¬í¬ì¸íŠ¸ íƒìƒ‰ ì¤‘...\")\n",
    "    print(\"- best checkpoint :\", best_ckpt)\n",
    "    print(\"- last_ckpt :\", last_ckpt)\n",
    "\n",
    "    return str(best_ckpt), str(last_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_exp_config(config: dict) -> dict:\n",
    "    # ìˆ˜ì • í•„ìš”\n",
    "    return {\n",
    "        \"exp_name\": config.get(\"wandb\", {}).get(\"name\", \"no_name\"),\n",
    "        \"model_name\": config[\"general\"][\"model_name\"],\n",
    "        \"num_train_epochs\": config[\"training\"][\"num_train_epochs\"],\n",
    "        \"learning_rate\": config[\"training\"][\"learning_rate\"],\n",
    "        \"per_device_train_batch_size\": config[\"training\"][\"per_device_train_batch_size\"],\n",
    "        \"per_device_eval_batch_size\": config[\"training\"][\"per_device_eval_batch_size\"],\n",
    "        \"warmup_ratio\": config[\"training\"][\"warmup_ratio\"],\n",
    "        \"weight_decay\": config[\"training\"][\"weight_decay\"],\n",
    "        \"gradient_accumulation_steps\": config[\"training\"][\"gradient_accumulation_steps\"],\n",
    "        \"seed\": config[\"training\"][\"seed\"],\n",
    "        \"lr_scheduler_type\": config[\"training\"][\"lr_scheduler_type\"],\n",
    "        \"optim\": config[\"training\"][\"optim\"],\n",
    "        \"generation_max_length\": config[\"training\"][\"generation_max_length\"],\n",
    "    }\n",
    "\n",
    "# í•œ ë²ˆì˜ ì‹¤í—˜ ê²°ê³¼ë¥¼ exp_log.csvì— ëˆ„ì  ì €ì¥í•˜ëŠ” í•¨ìˆ˜\n",
    "def log_experiment_result(config: dict, metrics: dict, ckpt_info: dict | None = None,\n",
    "                          csv_path: str = \"../outputs/exp_log.csv\",) -> pd.DataFrame:\n",
    "\n",
    "    row = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        **extract_exp_config(config),\n",
    "    }\n",
    "\n",
    "    # í‰ê°€ì§€í‘œ ë¶™ì´ê¸° (eval_* ë§Œ í•„í„°ë§)\n",
    "    for k, v in metrics.items():\n",
    "        if k.startswith(\"eval_\"):\n",
    "            col_name = k.replace(\"-\", \"_\")\n",
    "            row[col_name] = v\n",
    "\n",
    "    # checkpoint ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€\n",
    "    if ckpt_info is not None:\n",
    "        row.update(ckpt_info)\n",
    "\n",
    "    # DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "    row_df = pd.DataFrame([row])\n",
    "\n",
    "    # ê¸°ì¡´ csvê°€ ìˆìœ¼ë©´ append, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±\n",
    "    csv_path = Path(csv_path)\n",
    "    if csv_path.exists():\n",
    "        prev_df = pd.read_csv(csv_path)\n",
    "        new_df = pd.concat([prev_df, row_df], ignore_index=True)\n",
    "    else:\n",
    "        new_df = row_df\n",
    "\n",
    "    # ì €ì¥\n",
    "    new_df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nğŸ’¾ ì‹¤í—˜ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {csv_path}\")\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvutzKQYvQgl"
   },
   "source": [
    "### ëª¨ë¸ í•™ìŠµ\n",
    ">- ì•ì—ì„œ êµ¬ì¶•í•œ í´ë˜ìŠ¤ ë° í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "qnA96wmR44is"
   },
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    # ì‚¬ìš©í•  device ì •ì˜\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print(f'âš¡ ì‚¬ìš© ë””ë°”ì´ìŠ¤ : {device} | torch ë²„ì „ : {torch.__version__}')\n",
    "\n",
    "    # ì‚¬ìš©í•  ëª¨ë¸ê³¼ tokenizer ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_train(config,device)\n",
    "    print('âœ… tokenizer ìŠ¤í˜ì…œ í† í° :', tokenizer.special_tokens_map)\n",
    "\n",
    "    # í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token']) # decoder_start_token: str, eos_token: str\n",
    "    data_path = config['general']['data_path']\n",
    "    train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config,preprocessor, data_path, tokenizer)\n",
    "\n",
    "    # ì „ì²˜ë¦¬í•œ íŒŒì¼ csvë¡œ ì €ì¥í•˜ê¸°\n",
    "    save_preprocessed_csv(preprocessor, config, version=\"v1\")       # ë²„ì „ê´€ë¦¬\n",
    "\n",
    "    # Trainer í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    trainer = load_trainer_for_train(config, generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset)\n",
    "    # ì €ì¥ëœ checkpoint ì´í›„ë¶€í„° ì‹¤í–‰ (ì¤‘ê°„ì— í•™ìŠµì´ ì¤‘ë‹¨ë¼ë„ ë¬¸ì œ ì—†ë„ë¡ í•˜ê¸° ìœ„í•¨)\n",
    "    trainer.train()\n",
    "\n",
    "    # best / last ckpt ìë™ ì°¾ê¸°\n",
    "    best_ckpt, last_ckpt = get_best_and_last_checkpoints(config)\n",
    "\n",
    "    # ë‘ ê°œ ì²´í¬í¬ì¸íŠ¸ í‰ê°€ â†’ DataFrame ë¹„êµ\n",
    "    all_results = []\n",
    "    for name, ckpt in [(\"best\", best_ckpt), (\"last\", last_ckpt)]:\n",
    "        metrics = eval_checkpoint(ckpt, config, tokenizer, val_inputs_dataset)\n",
    "        all_results.append({\n",
    "            \"type\": name,\n",
    "            \"checkpoint\": os.path.basename(ckpt),\n",
    "            **{k: v for k, v in metrics.items() if k.startswith(\"eval_\")},\n",
    "        })\n",
    "    df = pd.DataFrame(all_results)\n",
    "    display(df.round(4))\n",
    "\n",
    "    # ì‹¤í—˜ ë¡œê·¸ ì‘ì„±\n",
    "    exp_df = log_experiment_result(\n",
    "        config,\n",
    "        metrics,\n",
    "        ckpt_info={\"which\": \"best\", \"ckpt\": best_ckpt},\n",
    "        csv_path=\"../outputs/exp_log.csv\",\n",
    "    )\n",
    "\n",
    "    # wandb ì¢…ë£Œ\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1DMS60wL-Dhv",
    "outputId": "cbb6aba7-18ff-4d12-b9e7-2a2ef31d94d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ ì‚¬ìš© ë””ë°”ì´ìŠ¤ : cuda:0 | torch ë²„ì „ : 2.1.0\n",
      "\n",
      "ğŸ¤– ëª¨ë¸ëª… : digit82/kobart-summarization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… tokenizer ìŠ¤í˜ì…œ í† í° : {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask>', 'additional_special_tokens': ['#PassportNumber#', '#Person2#', '#Address#', '#Person1#', '#PhoneNumber#', '#Person3#']}\n",
      "\n",
      "âœ… í•™ìŠµ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\n",
      "\n",
      "âœ… í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!\n",
      "âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!\n",
      "ğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ | ì €ì¥ ìœ„ì¹˜: {save_dir}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/nlp-competition/wandb/wandb/run-20251203_133022-6urgo0sx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aistages-nlp-3/NLP-private/runs/6urgo0sx' target=\"_blank\">preprocessed_v1</a></strong> to <a href='https://wandb.ai/aistages-nlp-3/NLP-private' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aistages-nlp-3/NLP-private' target=\"_blank\">https://wandb.ai/aistages-nlp-3/NLP-private</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aistages-nlp-3/NLP-private/runs/6urgo0sx' target=\"_blank\">https://wandb.ai/aistages-nlp-3/NLP-private/runs/6urgo0sx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… training arguments ì •ì˜ ì™„ë£Œ!\n",
      "\n",
      "âœ… trainer ìƒì„± ì™„ë£Œ!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/5000 18:26 < 18:27, 2.26 it/s, Epoch 10/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.667100</td>\n",
       "      <td>2.442965</td>\n",
       "      <td>0.213520</td>\n",
       "      <td>0.038543</td>\n",
       "      <td>0.205219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.236400</td>\n",
       "      <td>0.583098</td>\n",
       "      <td>0.332040</td>\n",
       "      <td>0.104247</td>\n",
       "      <td>0.316468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.585200</td>\n",
       "      <td>0.539191</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>0.118897</td>\n",
       "      <td>0.329498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.528365</td>\n",
       "      <td>0.357266</td>\n",
       "      <td>0.127183</td>\n",
       "      <td>0.334730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.497400</td>\n",
       "      <td>0.521791</td>\n",
       "      <td>0.357967</td>\n",
       "      <td>0.126282</td>\n",
       "      <td>0.335148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.473100</td>\n",
       "      <td>0.519781</td>\n",
       "      <td>0.362211</td>\n",
       "      <td>0.132777</td>\n",
       "      <td>0.341396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.453800</td>\n",
       "      <td>0.517959</td>\n",
       "      <td>0.366974</td>\n",
       "      <td>0.134447</td>\n",
       "      <td>0.345595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.435300</td>\n",
       "      <td>0.518494</td>\n",
       "      <td>0.365444</td>\n",
       "      <td>0.133990</td>\n",
       "      <td>0.344706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.419600</td>\n",
       "      <td>0.520999</td>\n",
       "      <td>0.367978</td>\n",
       "      <td>0.132917</td>\n",
       "      <td>0.345380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.405900</td>\n",
       "      <td>0.523201</td>\n",
       "      <td>0.364991</td>\n",
       "      <td>0.131607</td>\n",
       "      <td>0.341342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ì‹œëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.                                                                           \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ê°ê¸° ì¦ìƒì„ ì„¤ëª…í•©ë‹ˆë‹¤. #Person2# ëŠ” ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                                 \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ê°ê¸°ì— ê±¸ë ¸ë‹¤ê³  ë§í•©ë‹ˆë‹¤. #Person2# ëŠ” ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                                                       \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤. #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                                                            \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤. #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                                                            \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤. #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                                                 \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤. #Person1# ì€ #Person2# ì—ê²Œ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                                                        \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ìˆ¨ì‰¬ê¸° í˜ë“¤ê³  ìˆ¨ì‰¬ëŠ” ê²ƒì´ ë¶ˆí¸í•©ë‹ˆë‹¤. #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œí•©ë‹ˆë‹¤.                                                                      \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ìˆ¨ì‰¬ê¸° í˜ë“¤ë‹¤ê³  í˜¸ì†Œí•©ë‹ˆë‹¤. #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                                       \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ìˆ¨ì‰¬ê¸° í˜ë“¤ê³  ìˆ¨ì‰¬ëŠ” ê²ƒì´ ë¶ˆí¸í•©ë‹ˆë‹¤. #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œí•©ë‹ˆë‹¤.                                                                      \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ì²´í¬í¬ì¸íŠ¸ íƒìƒ‰ ì¤‘...\n",
      "- best checkpoint : ../outputs/checkpoints/checkpoint-1750\n",
      "- last_ckpt : ../outputs/checkpoints/checkpoint-2500\n",
      "\n",
      "=== Evaluate ../outputs/checkpoints/checkpoint-1750 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤. #Person1# ì€ #Person2# ì—ê²Œ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "{'eval_loss': 0.5179585218429565, 'eval_rouge-1': 0.31770169064476134, 'eval_rouge-2': 0.1301270192344097, 'eval_rouge-l': 0.29521319320901046, 'eval_runtime': 5.1245, 'eval_samples_per_second': 97.376, 'eval_steps_per_second': 3.122}\n",
      "\n",
      "=== Evaluate ../outputs/checkpoints/checkpoint-2500 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ìˆ¨ì‰¬ê¸° í˜ë“¤ê³  ìˆ¨ì‰¬ëŠ” ê²ƒì´ ë¶ˆí¸í•©ë‹ˆë‹¤. #Person1# ì€ ì²œì‹ \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "{'eval_loss': 0.5232008099555969, 'eval_rouge-1': 0.31587622171998314, 'eval_rouge-2': 0.1306555021876341, 'eval_rouge-l': 0.2903306938606965, 'eval_runtime': 5.2973, 'eval_samples_per_second': 94.199, 'eval_steps_per_second': 3.02}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_rouge-1</th>\n",
       "      <th>eval_rouge-2</th>\n",
       "      <th>eval_rouge-l</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best</td>\n",
       "      <td>checkpoint-1750</td>\n",
       "      <td>0.5180</td>\n",
       "      <td>0.3177</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.2952</td>\n",
       "      <td>5.1245</td>\n",
       "      <td>97.376</td>\n",
       "      <td>3.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last</td>\n",
       "      <td>checkpoint-2500</td>\n",
       "      <td>0.5232</td>\n",
       "      <td>0.3159</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.2903</td>\n",
       "      <td>5.2973</td>\n",
       "      <td>94.199</td>\n",
       "      <td>3.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type       checkpoint  eval_loss  eval_rouge-1  eval_rouge-2  eval_rouge-l  \\\n",
       "0  best  checkpoint-1750     0.5180        0.3177        0.1301        0.2952   \n",
       "1  last  checkpoint-2500     0.5232        0.3159        0.1307        0.2903   \n",
       "\n",
       "   eval_runtime  eval_samples_per_second  eval_steps_per_second  \n",
       "0        5.1245                   97.376                  3.122  \n",
       "1        5.2973                   94.199                  3.020  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ ì‹¤í—˜ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: ../outputs/exp_log.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b48ba2879347f0aa463a18cf93d22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='472.660 MB of 472.660 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>eval/rouge-1</td><td>â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–†</td></tr><tr><td>eval/rouge-2</td><td>â–â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/rouge-l</td><td>â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–…</td></tr><tr><td>eval/runtime</td><td>â–ˆâ–„â–„â–†â–…â–…â–…â–…â–…â–…â–â–</td></tr><tr><td>eval/samples_per_second</td><td>â–â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ˆ</td></tr><tr><td>eval/steps_per_second</td><td>â–â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ˆ</td></tr><tr><td>train/epoch</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–â–</td></tr><tr><td>train/learning_rate</td><td>â–â–ˆâ–ˆâ–ˆâ–‡â–†â–†â–…â–„â–‚</td></tr><tr><td>train/loss</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.5232</td></tr><tr><td>eval/rouge-1</td><td>0.31588</td></tr><tr><td>eval/rouge-2</td><td>0.13066</td></tr><tr><td>eval/rouge-l</td><td>0.29033</td></tr><tr><td>eval/runtime</td><td>5.2973</td></tr><tr><td>eval/samples_per_second</td><td>94.199</td></tr><tr><td>eval/steps_per_second</td><td>3.02</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>0</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.4059</td></tr><tr><td>train/total_flos</td><td>3.79774353014784e+16</td></tr><tr><td>train/train_loss</td><td>1.07017</td></tr><tr><td>train/train_runtime</td><td>1104.444</td></tr><tr><td>train/train_samples_per_second</td><td>225.58</td></tr><tr><td>train/train_steps_per_second</td><td>4.527</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">preprocessed_v1</strong> at: <a href='https://wandb.ai/aistages-nlp-3/NLP-private/runs/6urgo0sx' target=\"_blank\">https://wandb.ai/aistages-nlp-3/NLP-private/runs/6urgo0sx</a><br/>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/root/nlp-competition/wandb/wandb/run-20251203_133022-6urgo0sx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(loaded_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFtWqowCGzEc"
   },
   "source": [
    "### ëª¨ë¸ ì¶”ë¡ \n",
    ">- test dataë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "lV1Do7nlTylG"
   },
   "outputs": [],
   "source": [
    "# tokenization ê³¼ì •ê¹Œì§€ ì§„í–‰ëœ test ë°ì´í„° ì¶œë ¥\n",
    "def prepare_test_dataset(config,preprocessor, tokenizer):\n",
    "    \n",
    "    test_file_path = os.path.join(config['general']['data_path'], 'raw', 'test.csv')\n",
    "\n",
    "    test_data = preprocessor.make_set_as_df(test_file_path,is_train=False)\n",
    "    test_id = test_data['fname']\n",
    "    encoder_input_test , decoder_input_test = preprocessor.make_input(test_data,is_test=True)\n",
    "    print('\\nâœ… test ë°ì´í„° ë¡œë“œ ì™„ë£Œ!')\n",
    "\n",
    "    test_tokenized_encoder_inputs = tokenizer(encoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,)\n",
    "    test_tokenized_decoder_inputs = tokenizer(decoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False,)\n",
    "\n",
    "    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n",
    "    print('\\nâœ… test ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!')\n",
    "\n",
    "    return test_data, test_encoder_inputs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "eb49bLULT3aS"
   },
   "outputs": [],
   "source": [
    "# ì¶”ë¡ ì„ ìœ„í•œ tokenizerì™€ í•™ìŠµì‹œí‚¨ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "def load_tokenizer_and_model_for_test(config,device):\n",
    "    model_name = config['general']['model_name']\n",
    "    ckt_path = config['inference']['ckt_path']\n",
    "    print('\\nğŸ¤– ëª¨ë¸ëª… :', model_name)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    # ìë™ íƒìƒ‰ëœ best checkpointë¥¼ ëª¨ë¸ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    best_ckpt, last_ckpt = get_best_and_last_checkpoints(config)\n",
    "    generate_model = BartForConditionalGeneration.from_pretrained(best_ckpt)\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))\n",
    "    generate_model.to(device)\n",
    "    print('ğŸ§  ìµœì¢… ëª¨ë¸ :', best_ckpt)\n",
    "    print('âœ… tokenizer & model ë¡œë“œ ì™„ë£Œ!')\n",
    "\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "Axzu9rsoGLgJ"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ì´ ìƒì„±í•œ ìš”ì•½ë¬¸ì˜ ì¶œë ¥ ê²°ê³¼ ë³´ê¸°\n",
    "def inference(config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print(f'âš¡ ì‚¬ìš© ë””ë°”ì´ìŠ¤ : {device} | torch ë²„ì „ : {torch.__version__}')\n",
    "    \n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_test(config,device)\n",
    "\n",
    "    data_path = config['general']['data_path']\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
    "\n",
    "    test_data, test_encoder_inputs_dataset = prepare_test_dataset(config,preprocessor, tokenizer)\n",
    "    dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=config['inference']['batch_size'])\n",
    "\n",
    "    summary = []\n",
    "    text_ids = []\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataloader):\n",
    "            text_ids.extend(item['ID'])\n",
    "            generated_ids = generate_model.generate(input_ids=item['input_ids'].to('cuda:0'),\n",
    "                            no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                            early_stopping=config['inference']['early_stopping'],\n",
    "                            max_length=config['inference']['generate_max_length'],\n",
    "                            num_beams=config['inference']['num_beams'],\n",
    "                        )\n",
    "            for ids in generated_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "\n",
    "    # ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•˜ì—¬ ë…¸ì´ì¦ˆì— í•´ë‹¹ë˜ëŠ” ìŠ¤í˜ì…œ í† í° ì œê±°\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    preprocessed_summary = summary.copy()\n",
    "    for token in remove_tokens:\n",
    "        preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": test_data['fname'],\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    result_path = config['inference']['result_path']\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    save_name = \"output_preprocessed_v1.csv\"                                # ë²„ì „ê´€ë¦¬\n",
    "    output.to_csv(os.path.join(result_path, save_name), index=False)         \n",
    "    print(f\"ğŸ’¾ ì¶”ë¡  ê²°ê³¼ ì €ì¥ ì™„ë£Œ : {result_path}{save_name}\")\n",
    "\n",
    "    print(\"\\nğŸ’¬ testë¬¸ ìš”ì•½ ê²°ê³¼\")\n",
    "    print(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "-pJ1ZXf-5V50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ ì‚¬ìš© ë””ë°”ì´ìŠ¤ : cuda:0 | torch ë²„ì „ : 2.1.0\n",
      "\n",
      "ğŸ¤– ëª¨ë¸ëª… : digit82/kobart-summarization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ì²´í¬í¬ì¸íŠ¸ íƒìƒ‰ ì¤‘...\n",
      "- best checkpoint : ../outputs/checkpoints/checkpoint-1750\n",
      "- last_ckpt : ../outputs/checkpoints/checkpoint-2500\n",
      "ğŸ§  ìµœì¢… ëª¨ë¸ : ../outputs/checkpoints/checkpoint-1750\n",
      "âœ… tokenizer & model ë¡œë“œ ì™„ë£Œ!\n",
      "\n",
      "âœ… test ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\n",
      "\n",
      "âœ… test ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:23<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ ì¶”ë¡  ê²°ê³¼ ì €ì¥ ì™„ë£Œ : ../outputs/prediction/output_preprocessed_v1.csv\n",
      "\n",
      "ğŸ’¬ testë¬¸ ìš”ì•½ ê²°ê³¼\n",
      "        fname                                            summary\n",
      "0      test_0    Ms. Dawsonì€ #Person1# ì—ê²Œ ì‚¬ë‚´ ë©”ëª¨ë¥¼ ì‘ì„±í•˜ê³  ë°°í¬í•˜ë¼ê³  ìš”...\n",
      "1      test_1   #Person2# ëŠ” #Person1# ì—ê²Œ ì¶œí‡´ê·¼ ì‹œê°„ì— êµí†µì²´ì¦ì´ ì‹¬í•˜ë‹¤ê³  ë§...\n",
      "2      test_2    KateëŠ” Mashaì™€ Heroê°€ ì´í˜¼í–ˆë‹¤ê³  #Person1# ì—ê²Œ ë§í•©ë‹ˆë‹¤. ...\n",
      "3      test_3    Brianì€ ìì‹ ì˜ ìƒì¼ì„ ì¶•í•˜í•˜ê¸° ìœ„í•´ ìƒì¼ íŒŒí‹°ì— ì°¸ì„í–ˆë‹¤. #Person1...\n",
      "4      test_4   #Person2# ëŠ” #Person1# ì—ê²Œ ì˜¬ë¦¼í”½ ê³µì›ì˜ ì „ì²´ ì¢Œì„ì´ 5000ì„...\n",
      "..        ...                                                ...\n",
      "494  test_495    Jackì€ Charlieì—ê²Œ ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ê²Œì„ì„ ì œì•ˆí•˜ê³ , ê·¸ë…€ëŠ” ìˆ™ì œë¥¼ ë¨¼ì €...\n",
      "495  test_496   #Person2# ëŠ” #Person1# ì—ê²Œ ì‹œê³¨ ìŒì•…ì— ê´€ì‹¬ì„ ê°–ê²Œ ëœ ê³„ê¸°ì™€ ...\n",
      "496  test_497    AliceëŠ” #Person1# ì—ê²Œ ì„¸íƒê¸°ì— ë¹„ëˆ„ê°€ ë“¤ì–´ ìˆì§€ ì•Šë‹¤ê³  ì„¤ëª…í•˜ê³ ,...\n",
      "497  test_498    SteveëŠ” Matthewì—ê²Œ ìƒˆë¡œ ì´ì‚¬í•  ì§‘ì„ ì°¾ê³  ìˆë‹¤ê³  ë§í•˜ê³ , Mrs. ...\n",
      "498  test_499    FrankëŠ” Betsyì—ê²Œ ìŠ¹ì§„ ì†Œì‹ì„ ì „í•˜ê³ , íŒŒí‹°ì— 150ëª…ì´ ì°¸ì„í•  ê²ƒì´ë¼...\n",
      "\n",
      "[499 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ì¶”ë¡  ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    output = inference(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "OsPmLfhbzZqS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ê²°ì¸¡ì¹˜ ë° ë°ì´í„°íƒ€ì… í™•ì¸\n",
      "- shape: (499, 2)\n",
      "\n",
      "- null check:\n",
      " fname      0\n",
      "summary    0\n",
      "dtype: int64\n",
      "\n",
      "- dtypes:\n",
      " fname      object\n",
      "summary    object\n",
      "dtype: object\n",
      "\n",
      "- duplicated id: 0\n",
      "\n",
      "ğŸ”ìš”ì•½ ê¸¸ì´ ì´ìƒì¹˜ í™•ì¸\n",
      "count    499.000000\n",
      "mean     106.208417\n",
      "std       19.204058\n",
      "min       63.000000\n",
      "25%       93.000000\n",
      "50%      102.000000\n",
      "75%      118.000000\n",
      "max      178.000000\n",
      "Name: summary_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ì œì¶œ ì „ í™•ì¸\n",
    "print(\"ğŸ” ê²°ì¸¡ì¹˜ ë° ë°ì´í„°íƒ€ì… í™•ì¸\")\n",
    "print(\"- shape:\", output.shape)\n",
    "print(\"\\n- null check:\\n\", output.isnull().sum())\n",
    "print(\"\\n- dtypes:\\n\", output.dtypes)\n",
    "print(\"\\n- duplicated id:\", output['fname'].duplicated().sum())\n",
    "\n",
    "print(\"\\nğŸ”ìš”ì•½ ê¸¸ì´ ì´ìƒì¹˜ í™•ì¸\")\n",
    "output_summary_length = output.copy()\n",
    "output_summary_length['summary_length'] = output_summary_length['summary'].str.len()\n",
    "print(output_summary_length['summary_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ì‹¤í—˜ ë¡œê·¸\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>warmup_ratio</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_rouge_l</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>which</th>\n",
       "      <th>ckpt</th>\n",
       "      <th>lb_rouge_1</th>\n",
       "      <th>lb_rouge_2</th>\n",
       "      <th>lb_rouge_l</th>\n",
       "      <th>lb_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-28 18:01:14</td>\n",
       "      <td>baseline_v1</td>\n",
       "      <td>digit82/kobart-summarization</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148929</td>\n",
       "      <td>5.0999</td>\n",
       "      <td>97.845</td>\n",
       "      <td>3.137</td>\n",
       "      <td>best</td>\n",
       "      <td>../outputs/checkpoints/checkpoint-1750</td>\n",
       "      <td>0.5634</td>\n",
       "      <td>0.3668</td>\n",
       "      <td>0.4819</td>\n",
       "      <td>47.0683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-12-03 10:17:28</td>\n",
       "      <td>preprocessed_v1</td>\n",
       "      <td>digit82/kobart-summarization</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284882</td>\n",
       "      <td>5.0909</td>\n",
       "      <td>98.018</td>\n",
       "      <td>3.143</td>\n",
       "      <td>best</td>\n",
       "      <td>../outputs/checkpoints/checkpoint-1750</td>\n",
       "      <td>0.5638</td>\n",
       "      <td>0.3680</td>\n",
       "      <td>0.4789</td>\n",
       "      <td>47.0228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-03 13:49:06</td>\n",
       "      <td>preprocessed_v1</td>\n",
       "      <td>digit82/kobart-summarization</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290331</td>\n",
       "      <td>5.2973</td>\n",
       "      <td>94.199</td>\n",
       "      <td>3.020</td>\n",
       "      <td>best</td>\n",
       "      <td>../outputs/checkpoints/checkpoint-1750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp         exp_name                    model_name  \\\n",
       "0  2025-11-28 18:01:14      baseline_v1  digit82/kobart-summarization   \n",
       "1  2025-12-03 10:17:28  preprocessed_v1  digit82/kobart-summarization   \n",
       "2  2025-12-03 13:49:06  preprocessed_v1  digit82/kobart-summarization   \n",
       "\n",
       "   num_train_epochs  learning_rate  per_device_train_batch_size  \\\n",
       "0                20        0.00001                           50   \n",
       "1                20        0.00001                           50   \n",
       "2                20        0.00001                           50   \n",
       "\n",
       "   per_device_eval_batch_size  warmup_ratio  weight_decay  \\\n",
       "0                          32           0.1          0.01   \n",
       "1                          32           0.1          0.01   \n",
       "2                          32           0.1          0.01   \n",
       "\n",
       "   gradient_accumulation_steps  ...  eval_rouge_l eval_runtime  \\\n",
       "0                            1  ...      0.148929       5.0999   \n",
       "1                            1  ...      0.284882       5.0909   \n",
       "2                            1  ...      0.290331       5.2973   \n",
       "\n",
       "  eval_samples_per_second  eval_steps_per_second  which  \\\n",
       "0                  97.845                  3.137   best   \n",
       "1                  98.018                  3.143   best   \n",
       "2                  94.199                  3.020   best   \n",
       "\n",
       "                                     ckpt  lb_rouge_1  lb_rouge_2  lb_rouge_l  \\\n",
       "0  ../outputs/checkpoints/checkpoint-1750      0.5634      0.3668      0.4819   \n",
       "1  ../outputs/checkpoints/checkpoint-1750      0.5638      0.3680      0.4789   \n",
       "2  ../outputs/checkpoints/checkpoint-1750         NaN         NaN         NaN   \n",
       "\n",
       "   lb_final  \n",
       "0   47.0683  \n",
       "1   47.0228  \n",
       "2       NaN  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ì œì¶œ í›„ LB ì ìˆ˜ > ì‹¤í—˜ ë¡œê·¸ì— ê¸°ë¡\n",
    "log_path = \"../outputs/exp_log.csv\"\n",
    "exp_log = pd.read_csv(log_path)\n",
    "\n",
    "print(\"ğŸ“ ì‹¤í—˜ ë¡œê·¸\")\n",
    "display(exp_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ë¦¬ë”ë³´ë“œ ê°’ ì¶”ê°€í•˜ê¸°\n",
    "# exp_log.loc[1, \"lb_rouge_1\"] = 0.5638\n",
    "# exp_log.loc[1, \"lb_rouge_2\"] = 0.3680\n",
    "# exp_log.loc[1, \"lb_rouge_l\"] = 0.4789\n",
    "# exp_log.loc[1, \"lb_final\"]   = 47.0228\n",
    "\n",
    "# exp_log.to_csv(log_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_rouge_1</th>\n",
       "      <th>eval_rouge_2</th>\n",
       "      <th>eval_rouge_l</th>\n",
       "      <th>lb_rouge_1</th>\n",
       "      <th>lb_rouge_2</th>\n",
       "      <th>lb_rouge_l</th>\n",
       "      <th>lb_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-28 18:01:14</td>\n",
       "      <td>baseline_v1</td>\n",
       "      <td>0.596968</td>\n",
       "      <td>0.154657</td>\n",
       "      <td>0.042543</td>\n",
       "      <td>0.148929</td>\n",
       "      <td>0.5634</td>\n",
       "      <td>0.3668</td>\n",
       "      <td>0.4819</td>\n",
       "      <td>47.0683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-12-03 10:17:28</td>\n",
       "      <td>preprocessed_v1</td>\n",
       "      <td>0.523068</td>\n",
       "      <td>0.310635</td>\n",
       "      <td>0.129385</td>\n",
       "      <td>0.284882</td>\n",
       "      <td>0.5638</td>\n",
       "      <td>0.3680</td>\n",
       "      <td>0.4789</td>\n",
       "      <td>47.0228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-03 13:49:06</td>\n",
       "      <td>preprocessed_v1</td>\n",
       "      <td>0.523201</td>\n",
       "      <td>0.315876</td>\n",
       "      <td>0.130656</td>\n",
       "      <td>0.290331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp         exp_name  eval_loss  eval_rouge_1  \\\n",
       "0  2025-11-28 18:01:14      baseline_v1   0.596968      0.154657   \n",
       "1  2025-12-03 10:17:28  preprocessed_v1   0.523068      0.310635   \n",
       "2  2025-12-03 13:49:06  preprocessed_v1   0.523201      0.315876   \n",
       "\n",
       "   eval_rouge_2  eval_rouge_l  lb_rouge_1  lb_rouge_2  lb_rouge_l  lb_final  \n",
       "0      0.042543      0.148929      0.5634      0.3668      0.4819   47.0683  \n",
       "1      0.129385      0.284882      0.5638      0.3680      0.4789   47.0228  \n",
       "2      0.130656      0.290331         NaN         NaN         NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ì ìˆ˜ë§Œ ë³´ê¸°\n",
    "display(exp_log[[\"timestamp\", \"exp_name\", \"eval_loss\", \"eval_rouge_1\", \"eval_rouge_2\", \"eval_rouge_l\", \"lb_rouge_1\", \"lb_rouge_2\", \"lb_rouge_l\", \"lb_final\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²˜ë¦¬\n",
    "# ë°ì´í„° ì¦ê°•, hard case ë¶„ì„, error patternì— ë”°ë¥¸ rule ì¶”ê°€\n",
    "# Solar + baseline ì¡°í•©\n",
    "#     (1) ì—ëŸ¬ ì¼€ì´ìŠ¤ì— í•œí•´ Solarë¡œ í›„ì²˜ë¦¬\n",
    "#     (2) baseline ìš”ì•½ì´ ë„ˆë¬´ ì§§ì„ ë•Œë§Œ Solar ì¬ìš”ì•½"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "NLP venv",
   "language": "python",
   "name": "nlp-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "083ea69907bb48d4a8fff919bac51aad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08d05bc20a96432badd459e1ffaf868e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13651c09564a4337b8274c1cb436faa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14f6c91d6c634379b498586c51e606e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21d2e54b5a0a4f79973a512105da43eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2307c6dcbe0141acb5e61baae19cade7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "285007b45236478ca147c6df752c8da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a190bda0b72407e9a953cd2104dd3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fd3d7bbcd6948d8904d33001f95ea03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3645438ace1f4596a8dbc157b48c1521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14f6c91d6c634379b498586c51e606e0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_08d05bc20a96432badd459e1ffaf868e",
      "value": " 295/295 [00:00&lt;00:00, 21.3kB/s]"
     }
    },
    "3a04e871b74b45d7bf02fd33bb103577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bcd6b6b956347b29e1efa20a1d00542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c284a826f6843f6aa47eacad478ac30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_affff1d8a89e4c14955d1b2aa39ff1ab",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_13651c09564a4337b8274c1cb436faa5",
      "value": "tokenizer.json: 100%"
     }
    },
    "45187decb58b4ad39ad532259c6277e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4747b668e2fa4ab58a449446f80030f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52095cc7087243ac916055e569fd22f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c18f0e3bc35e44d9915c3f84cd282a26",
      "max": 109,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a04e871b74b45d7bf02fd33bb103577",
      "value": 109
     }
    },
    "58001a60eacc44d5b38a68648adccde4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58c794fb7ce543a39fdf66d757f6eeab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f5fde5b0ac840a18bd5cc380e564ff6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_45187decb58b4ad39ad532259c6277e5",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "5dfcf310ca9e4e2794076098a5d69cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c284a826f6843f6aa47eacad478ac30",
       "IPY_MODEL_6caedd60c6b747469c82930be1f95d6d",
       "IPY_MODEL_64f2218f899d446393cfea44f206f0a6"
      ],
      "layout": "IPY_MODEL_d068f541df3f438dbd5138863e64b2f2"
     }
    },
    "64f2218f899d446393cfea44f206f0a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d22fbc2c5dbf422399e496c9b500025a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_775d8bbeceac4e2da4f21ab6235c89ed",
      "value": " 682k/682k [00:00&lt;00:00, 5.40MB/s]"
     }
    },
    "6caedd60c6b747469c82930be1f95d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bcd6b6b956347b29e1efa20a1d00542",
      "max": 682133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fd3d7bbcd6948d8904d33001f95ea03",
      "value": 682133
     }
    },
    "6f5fde5b0ac840a18bd5cc380e564ff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775d8bbeceac4e2da4f21ab6235c89ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a6464a355f7464c989033965d418a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2307c6dcbe0141acb5e61baae19cade7",
      "max": 295,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4747b668e2fa4ab58a449446f80030f5",
      "value": 295
     }
    },
    "a15af9e8158f4903b9189f3d322a5ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac00d6c2cf974b33a628acb3f1471316",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_285007b45236478ca147c6df752c8da4",
      "value": " 109/109 [00:00&lt;00:00, 9.44kB/s]"
     }
    },
    "ac00d6c2cf974b33a628acb3f1471316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "affff1d8a89e4c14955d1b2aa39ff1ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18f0e3bc35e44d9915c3f84cd282a26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d068f541df3f438dbd5138863e64b2f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d22fbc2c5dbf422399e496c9b500025a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de1a3f7701c243839fe03b930a9b9e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebc22683058a4f229c5588e52fc93536",
       "IPY_MODEL_52095cc7087243ac916055e569fd22f3",
       "IPY_MODEL_a15af9e8158f4903b9189f3d322a5ef3"
      ],
      "layout": "IPY_MODEL_21d2e54b5a0a4f79973a512105da43eb"
     }
    },
    "e920dbc173c045d1a32143349f1dff8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58c794fb7ce543a39fdf66d757f6eeab",
       "IPY_MODEL_8a6464a355f7464c989033965d418a8a",
       "IPY_MODEL_3645438ace1f4596a8dbc157b48c1521"
      ],
      "layout": "IPY_MODEL_58001a60eacc44d5b38a68648adccde4"
     }
    },
    "ebc22683058a4f229c5588e52fc93536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_083ea69907bb48d4a8fff919bac51aad",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2a190bda0b72407e9a953cd2104dd3b2",
      "value": "special_tokens_map.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
