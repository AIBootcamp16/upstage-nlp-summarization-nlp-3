{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ë²„ì „ê´€ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 28 12:58:40 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  | 00000000:4C:00.0 Off |                  N/A |\n",
      "| 39%   30C    P8              18W / 350W |      3MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbZ7SU9P2TYN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /data/ephemeral/home/.netrc\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "from pathlib import Path\n",
    "from transformers import BartForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from datetime import datetime\n",
    "\n",
    "import wandb\n",
    "wandb.login(key=\"\")                     # API KEY ì…ë ¥\n",
    "\n",
    "# wandb êº¼ë‘ê¸°\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qq46k6_CNQn"
   },
   "source": [
    "### Config ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "referenced_widgets": [
      "e920dbc173c045d1a32143349f1dff8e",
      "58c794fb7ce543a39fdf66d757f6eeab",
      "8a6464a355f7464c989033965d418a8a",
      "3645438ace1f4596a8dbc157b48c1521",
      "58001a60eacc44d5b38a68648adccde4",
      "6f5fde5b0ac840a18bd5cc380e564ff6",
      "45187decb58b4ad39ad532259c6277e5",
      "2307c6dcbe0141acb5e61baae19cade7",
      "4747b668e2fa4ab58a449446f80030f5",
      "14f6c91d6c634379b498586c51e606e0",
      "08d05bc20a96432badd459e1ffaf868e",
      "5dfcf310ca9e4e2794076098a5d69cea",
      "3c284a826f6843f6aa47eacad478ac30",
      "6caedd60c6b747469c82930be1f95d6d",
      "64f2218f899d446393cfea44f206f0a6",
      "d068f541df3f438dbd5138863e64b2f2",
      "affff1d8a89e4c14955d1b2aa39ff1ab",
      "13651c09564a4337b8274c1cb436faa5",
      "3bcd6b6b956347b29e1efa20a1d00542",
      "2fd3d7bbcd6948d8904d33001f95ea03",
      "d22fbc2c5dbf422399e496c9b500025a",
      "775d8bbeceac4e2da4f21ab6235c89ed",
      "de1a3f7701c243839fe03b930a9b9e30",
      "ebc22683058a4f229c5588e52fc93536",
      "52095cc7087243ac916055e569fd22f3",
      "a15af9e8158f4903b9189f3d322a5ef3",
      "21d2e54b5a0a4f79973a512105da43eb",
      "083ea69907bb48d4a8fff919bac51aad",
      "2a190bda0b72407e9a953cd2104dd3b2",
      "c18f0e3bc35e44d9915c3f84cd282a26",
      "3a04e871b74b45d7bf02fd33bb103577",
      "ac00d6c2cf974b33a628acb3f1471316",
      "285007b45236478ca147c6df752c8da4"
     ]
    },
    "id": "gZOE9TInCQHJ",
    "outputId": "8ce58487-6199-408c-cb37-49af1e218bc2"
   },
   "outputs": [],
   "source": [
    "# config ì„¤ì •ì— tokenizer ëª¨ë“ˆì´ ì‚¬ìš©ë˜ë¯€ë¡œ ë¯¸ë¦¬ tokenizerë¥¼ ì •ì˜í•´ì¤ë‹ˆë‹¤.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "5vsACJI7CVb8"
   },
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"../data/\",\n",
    "        \"data_raw_path\": \"../data/raw/\",                                       \n",
    "        \"model_name\": \"digit82/kobart-summarization\",                           # ëª¨ë¸ ì´ë¦„\n",
    "        \"output_dir\": \"../outputs/checkpoints/\"                                 \n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 512,\n",
    "        \"decoder_max_len\": 100,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#',\n",
    "                           '#PhoneNumber#', '#Address#', '#PassportNumber#']    # íŠ¹ì • ë‹¨ì–´ë“¤ì´ ë¶„í•´ë˜ì§€ ì•Šë„ë¡ í•˜ê¸° ìœ„í•¨\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 20,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"per_device_train_batch_size\": 50,\n",
    "        \"per_device_eval_batch_size\": 32,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine',\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 5,\n",
    "        \"fp16\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 100,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "        \"report_to\": \"none\"  \n",
    "        # \"report_to\": \"wandb\"                                                        # wandb ì‚¬ìš© ì˜µì…˜\n",
    "    },\n",
    "    \"wandb\": {\n",
    "        # \"entity\": \"bubblekid43\",                                                   \n",
    "        \"project\": \"NLP-private\",                                                   \n",
    "        \"name\": \"baseline_v1\"                                                       # ë²„ì „ê´€ë¦¬\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"../outputs/checkpoints/\",                                      \n",
    "        \"result_path\": \"../outputs/prediction/\",\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 100,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\" : 32,\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\",\n",
    "                          f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]       # ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì •ì˜\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "REJybO5UCabF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ config ì €ì¥ ì™„ë£Œ : ../configs/config_v1.yaml\n",
      "\n",
      "ğŸ” config êµ¬ì„± ì •ë³´ í™•ì¸\n",
      "{'general': {'data_path': '../data/', 'data_raw_path': '../data/raw/', 'model_name': 'digit82/kobart-summarization', 'output_dir': '../outputs/checkpoints/'}, 'inference': {'batch_size': 32, 'ckt_path': '../outputs/checkpoints/', 'early_stopping': True, 'generate_max_length': 100, 'no_repeat_ngram_size': 2, 'num_beams': 4, 'remove_tokens': ['<usr>', '<s>', '</s>', '<pad>'], 'result_path': '../outputs/prediction/'}, 'tokenizer': {'bos_token': '<s>', 'decoder_max_len': 100, 'encoder_max_len': 512, 'eos_token': '</s>', 'special_tokens': ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#']}, 'training': {'do_eval': True, 'do_train': True, 'early_stopping_patience': 3, 'early_stopping_threshold': 0.001, 'evaluation_strategy': 'epoch', 'fp16': True, 'generation_max_length': 100, 'gradient_accumulation_steps': 1, 'learning_rate': 1e-05, 'load_best_model_at_end': True, 'logging_dir': './logs', 'logging_strategy': 'epoch', 'lr_scheduler_type': 'cosine', 'num_train_epochs': 20, 'optim': 'adamw_torch', 'overwrite_output_dir': True, 'per_device_eval_batch_size': 32, 'per_device_train_batch_size': 50, 'predict_with_generate': True, 'report_to': 'none', 'save_strategy': 'epoch', 'save_total_limit': 5, 'seed': 42, 'warmup_ratio': 0.1, 'weight_decay': 0.01}, 'wandb': {'name': 'baseline_v1', 'project': 'NLP-private'}}\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ì˜ êµ¬ì„± ì •ë³´ë¥¼ YAML íŒŒì¼ë¡œ ì €ì¥\n",
    "config_path = \"../configs/config_v1.yaml\"                                            # ë²„ì „ê´€ë¦¬\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)\n",
    "print(f\"ğŸ’¾ config ì €ì¥ ì™„ë£Œ : {config_path}\")\n",
    "\n",
    "# ì €ì¥ëœ config íŒŒì¼ ë¶ˆëŸ¬ì™€ì„œ ë‚´ìš© í™•ì¸\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "print(\"\\nğŸ” config êµ¬ì„± ì •ë³´ í™•ì¸\")\n",
    "print(loaded_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2zt0b-8ogCL"
   },
   "source": [
    "### ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "QFHIE2G04y-K",
    "outputId": "19312d21-f5bf-495f-c626-cc17b82024a4"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„° ê²½ë¡œ ì •ì˜\n",
    "data_path = Path(loaded_config['general']['data_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train_df.head()\n",
      "     fname                                           dialogue  \\\n",
      "0  train_0  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mr. Smith. ì €ëŠ” Dr. Hawkinsì…ë‹ˆë‹¤...   \n",
      "1  train_1  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mrs. Parker. ì˜ ì§€ë‚´ì…¨ë‚˜ìš”?\\n#Pers...   \n",
      "2  train_2  #Person1#: ì €ê¸°ìš”, ì—´ì‡  ì„¸íŠ¸ ë³¸ ì  ìˆì–´ìš”?\\n#Person2#: ì–´ë–¤ ...   \n",
      "3  train_3  #Person1#: ë„ˆ ì—¬ìì¹œêµ¬ ìˆëŠ” ê±° ì™œ ë§ ì•ˆ í–ˆì–´?\\n#Person2#: ë¯¸...   \n",
      "4  train_4  #Person1#: ì•ˆë…•, ì˜¤ëŠ˜ ë„ˆë¬´ ë©‹ì ¸ ë³´ì´ë„¤ìš”. ì €ë‘ ì¶¤ í•œ ê³¡ ì¶”ì‹¤ë˜ìš”?\\n...   \n",
      "\n",
      "                                             summary      topic  \n",
      "0  Mr. SmithëŠ” Dr. Hawkinsì—ê²Œ ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ëŸ¬ ì™€ì„œ, ë§¤ë…„ ê²€ì§„ í•„...       ê±´ê°•ê²€ì§„  \n",
      "1  Mrs. Parkerê°€ Rickyì™€ í•¨ê»˜ ë°±ì‹  ì ‘ì¢…ì„ ìœ„í•´ ë°©ë¬¸í•˜ì˜€ê³ , Dr. Pe...      ë°±ì‹  ì ‘ì¢…  \n",
      "2  #Person1#ì€ ì—´ì‡  ì„¸íŠ¸ë¥¼ ìƒì–´ë²„ë¦¬ê³  #Person2#ì—ê²Œ ì°¾ëŠ” ê²ƒì„ ë„ì™€ë‹¬ë¼...      ì—´ì‡  ë¶„ì‹¤  \n",
      "3  #Person1#ì€ #Person2#ê°€ ì—¬ìì¹œêµ¬ê°€ ìˆê³  ê²°í˜¼í•  ì˜ˆì •ì´ë¼ëŠ” ì‚¬ì‹¤ì„ ë§...  ì—¬ìì¹œêµ¬ì™€ì˜ ê²°í˜¼  \n",
      "4  Malikì€ Wenê³¼ Nikkiì—ê²Œ ì¶¤ì„ ì œì•ˆí•˜ê³ , Wenì€ ë°œì„ ë°ŸëŠ” ê²ƒì„ ê°ìˆ˜í•˜...       ì¶¤ ì œì•ˆ  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>#Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mr. Smith. ì €ëŠ” Dr. Hawkinsì…ë‹ˆë‹¤...</td>\n",
       "      <td>Mr. SmithëŠ” Dr. Hawkinsì—ê²Œ ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ëŸ¬ ì™€ì„œ, ë§¤ë…„ ê²€ì§„ í•„...</td>\n",
       "      <td>ê±´ê°•ê²€ì§„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>#Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mrs. Parker. ì˜ ì§€ë‚´ì…¨ë‚˜ìš”?\\n#Pers...</td>\n",
       "      <td>Mrs. Parkerê°€ Rickyì™€ í•¨ê»˜ ë°±ì‹  ì ‘ì¢…ì„ ìœ„í•´ ë°©ë¬¸í•˜ì˜€ê³ , Dr. Pe...</td>\n",
       "      <td>ë°±ì‹  ì ‘ì¢…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>#Person1#: ì €ê¸°ìš”, ì—´ì‡  ì„¸íŠ¸ ë³¸ ì  ìˆì–´ìš”?\\n#Person2#: ì–´ë–¤ ...</td>\n",
       "      <td>#Person1#ì€ ì—´ì‡  ì„¸íŠ¸ë¥¼ ìƒì–´ë²„ë¦¬ê³  #Person2#ì—ê²Œ ì°¾ëŠ” ê²ƒì„ ë„ì™€ë‹¬ë¼...</td>\n",
       "      <td>ì—´ì‡  ë¶„ì‹¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>#Person1#: ë„ˆ ì—¬ìì¹œêµ¬ ìˆëŠ” ê±° ì™œ ë§ ì•ˆ í–ˆì–´?\\n#Person2#: ë¯¸...</td>\n",
       "      <td>#Person1#ì€ #Person2#ê°€ ì—¬ìì¹œêµ¬ê°€ ìˆê³  ê²°í˜¼í•  ì˜ˆì •ì´ë¼ëŠ” ì‚¬ì‹¤ì„ ë§...</td>\n",
       "      <td>ì—¬ìì¹œêµ¬ì™€ì˜ ê²°í˜¼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>#Person1#: ì•ˆë…•, ì˜¤ëŠ˜ ë„ˆë¬´ ë©‹ì ¸ ë³´ì´ë„¤ìš”. ì €ë‘ ì¶¤ í•œ ê³¡ ì¶”ì‹¤ë˜ìš”?\\n...</td>\n",
       "      <td>Malikì€ Wenê³¼ Nikkiì—ê²Œ ì¶¤ì„ ì œì•ˆí•˜ê³ , Wenì€ ë°œì„ ë°ŸëŠ” ê²ƒì„ ê°ìˆ˜í•˜...</td>\n",
       "      <td>ì¶¤ ì œì•ˆ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fname                                           dialogue  \\\n",
       "0  train_0  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mr. Smith. ì €ëŠ” Dr. Hawkinsì…ë‹ˆë‹¤...   \n",
       "1  train_1  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mrs. Parker. ì˜ ì§€ë‚´ì…¨ë‚˜ìš”?\\n#Pers...   \n",
       "2  train_2  #Person1#: ì €ê¸°ìš”, ì—´ì‡  ì„¸íŠ¸ ë³¸ ì  ìˆì–´ìš”?\\n#Person2#: ì–´ë–¤ ...   \n",
       "3  train_3  #Person1#: ë„ˆ ì—¬ìì¹œêµ¬ ìˆëŠ” ê±° ì™œ ë§ ì•ˆ í–ˆì–´?\\n#Person2#: ë¯¸...   \n",
       "4  train_4  #Person1#: ì•ˆë…•, ì˜¤ëŠ˜ ë„ˆë¬´ ë©‹ì ¸ ë³´ì´ë„¤ìš”. ì €ë‘ ì¶¤ í•œ ê³¡ ì¶”ì‹¤ë˜ìš”?\\n...   \n",
       "\n",
       "                                             summary      topic  \n",
       "0  Mr. SmithëŠ” Dr. Hawkinsì—ê²Œ ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ëŸ¬ ì™€ì„œ, ë§¤ë…„ ê²€ì§„ í•„...       ê±´ê°•ê²€ì§„  \n",
       "1  Mrs. Parkerê°€ Rickyì™€ í•¨ê»˜ ë°±ì‹  ì ‘ì¢…ì„ ìœ„í•´ ë°©ë¬¸í•˜ì˜€ê³ , Dr. Pe...      ë°±ì‹  ì ‘ì¢…  \n",
       "2  #Person1#ì€ ì—´ì‡  ì„¸íŠ¸ë¥¼ ìƒì–´ë²„ë¦¬ê³  #Person2#ì—ê²Œ ì°¾ëŠ” ê²ƒì„ ë„ì™€ë‹¬ë¼...      ì—´ì‡  ë¶„ì‹¤  \n",
       "3  #Person1#ì€ #Person2#ê°€ ì—¬ìì¹œêµ¬ê°€ ìˆê³  ê²°í˜¼í•  ì˜ˆì •ì´ë¼ëŠ” ì‚¬ì‹¤ì„ ë§...  ì—¬ìì¹œêµ¬ì™€ì˜ ê²°í˜¼  \n",
       "4  Malikì€ Wenê³¼ Nikkiì—ê²Œ ì¶¤ì„ ì œì•ˆí•˜ê³ , Wenì€ ë°œì„ ë°ŸëŠ” ê²ƒì„ ê°ìˆ˜í•˜...       ì¶¤ ì œì•ˆ  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train data\n",
    "train_df = pd.read_csv(data_path / 'raw' / 'train.csv')\n",
    "print('âœ… train_df.head()')\n",
    "print(train_df.head())\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "FAGaYvNZ09Sq",
    "outputId": "bf8bf286-19e7-469d-ffae-41e6ad795ae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… val_df.head()\n",
      "   fname                                           dialogue  \\\n",
      "0  dev_0  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸ìš”?\\n#Person2#: ìš”ì¦˜ ...   \n",
      "1  dev_1  #Person1#: ì•¼ Jimmy, ì˜¤ëŠ˜ ì¢€ ì´ë”° ìš´ë™í•˜ëŸ¬ ê°€ì.\\n#Person2...   \n",
      "2  dev_2  #Person1#: ë‚˜ ì§„ì§œ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ ì¢€ ê·¸ë§Œ ë¨¹ì–´ì•¼ê² ì–´. \\n#Per...   \n",
      "3  dev_3  #Person1#: ë„ˆ UFO ë¯¿ì–´?\\n#Person2#: ë‹¹ì—°í•˜ì§€, ìˆëŠ” ê±° ì•„ëƒ...   \n",
      "4  dev_4  #Person1#: ì˜¤ëŠ˜ í•™êµ ê°”ì–´?\\n#Person2#: ë‹¹ì—°íˆ ê°”ì§€. ë„ˆëŠ”?\\n...   \n",
      "\n",
      "                                             summary      topic  \n",
      "0  #Person2#ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2#ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜...      ì˜ì‚¬ ìƒë‹´  \n",
      "1   #Person1#ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.      ìš´ë™ ê³„íš  \n",
      "2  #Person1#ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2#...     ê±´ê°•í•œ ì‹ë‹¨  \n",
      "3  #Person2#ëŠ” UFOë¥¼ ë¯¿ê³  ê¿ˆì—ì„œ ë³¼ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤. #Person1#ì€ ...   UFOì™€ ì™¸ê³„ì¸  \n",
      "4  #Person1#ì€ ì˜¤ëŠ˜ í•™êµì— ê°€ì§€ ì•Šì•˜ê³ , #Person2#ëŠ” ë‚´ì¼ í•™êµ ëŒ€ì‹  ...  í•™êµì™€ ì£¼ë§ ê³„íš  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_0</td>\n",
       "      <td>#Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸ìš”?\\n#Person2#: ìš”ì¦˜ ...</td>\n",
       "      <td>#Person2#ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2#ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜...</td>\n",
       "      <td>ì˜ì‚¬ ìƒë‹´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_1</td>\n",
       "      <td>#Person1#: ì•¼ Jimmy, ì˜¤ëŠ˜ ì¢€ ì´ë”° ìš´ë™í•˜ëŸ¬ ê°€ì.\\n#Person2...</td>\n",
       "      <td>#Person1#ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.</td>\n",
       "      <td>ìš´ë™ ê³„íš</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_2</td>\n",
       "      <td>#Person1#: ë‚˜ ì§„ì§œ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ ì¢€ ê·¸ë§Œ ë¨¹ì–´ì•¼ê² ì–´. \\n#Per...</td>\n",
       "      <td>#Person1#ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2#...</td>\n",
       "      <td>ê±´ê°•í•œ ì‹ë‹¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_3</td>\n",
       "      <td>#Person1#: ë„ˆ UFO ë¯¿ì–´?\\n#Person2#: ë‹¹ì—°í•˜ì§€, ìˆëŠ” ê±° ì•„ëƒ...</td>\n",
       "      <td>#Person2#ëŠ” UFOë¥¼ ë¯¿ê³  ê¿ˆì—ì„œ ë³¼ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤. #Person1#ì€ ...</td>\n",
       "      <td>UFOì™€ ì™¸ê³„ì¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev_4</td>\n",
       "      <td>#Person1#: ì˜¤ëŠ˜ í•™êµ ê°”ì–´?\\n#Person2#: ë‹¹ì—°íˆ ê°”ì§€. ë„ˆëŠ”?\\n...</td>\n",
       "      <td>#Person1#ì€ ì˜¤ëŠ˜ í•™êµì— ê°€ì§€ ì•Šì•˜ê³ , #Person2#ëŠ” ë‚´ì¼ í•™êµ ëŒ€ì‹  ...</td>\n",
       "      <td>í•™êµì™€ ì£¼ë§ ê³„íš</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fname                                           dialogue  \\\n",
       "0  dev_0  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸ìš”?\\n#Person2#: ìš”ì¦˜ ...   \n",
       "1  dev_1  #Person1#: ì•¼ Jimmy, ì˜¤ëŠ˜ ì¢€ ì´ë”° ìš´ë™í•˜ëŸ¬ ê°€ì.\\n#Person2...   \n",
       "2  dev_2  #Person1#: ë‚˜ ì§„ì§œ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ ì¢€ ê·¸ë§Œ ë¨¹ì–´ì•¼ê² ì–´. \\n#Per...   \n",
       "3  dev_3  #Person1#: ë„ˆ UFO ë¯¿ì–´?\\n#Person2#: ë‹¹ì—°í•˜ì§€, ìˆëŠ” ê±° ì•„ëƒ...   \n",
       "4  dev_4  #Person1#: ì˜¤ëŠ˜ í•™êµ ê°”ì–´?\\n#Person2#: ë‹¹ì—°íˆ ê°”ì§€. ë„ˆëŠ”?\\n...   \n",
       "\n",
       "                                             summary      topic  \n",
       "0  #Person2#ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2#ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜...      ì˜ì‚¬ ìƒë‹´  \n",
       "1   #Person1#ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.      ìš´ë™ ê³„íš  \n",
       "2  #Person1#ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2#...     ê±´ê°•í•œ ì‹ë‹¨  \n",
       "3  #Person2#ëŠ” UFOë¥¼ ë¯¿ê³  ê¿ˆì—ì„œ ë³¼ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤. #Person1#ì€ ...   UFOì™€ ì™¸ê³„ì¸  \n",
       "4  #Person1#ì€ ì˜¤ëŠ˜ í•™êµì— ê°€ì§€ ì•Šì•˜ê³ , #Person2#ëŠ” ë‚´ì¼ í•™êµ ëŒ€ì‹  ...  í•™êµì™€ ì£¼ë§ ê³„íš  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# validation data\n",
    "val_df = pd.read_csv(data_path / 'raw' / 'dev.csv')\n",
    "print('âœ… val_df.head()')\n",
    "print(val_df.head())\n",
    "display(val_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… test_df: (499, 2)\n",
      "    fname                                           dialogue\n",
      "0  test_0  #Person1#: Ms. Dawson, ë°›ì•„ì“°ê¸° ì¢€ ë¶€íƒë“œë ¤ì•¼ê² ì–´ìš”. \\n#Per...\n",
      "1  test_1  #Person1#: ë“œë””ì–´ ì™”ë„¤! ë­ê°€ ì´ë ‡ê²Œ ì˜¤ë˜ ê±¸ë ¸ì–´?\\n#Person2#: ...\n",
      "2  test_2  #Person1#: Kate, ì—¬ê¸°ì„œ ì¼ì–´ë‚œ ì¼ì„ ë¯¿ê¸° í˜ë“¤ ê±°ì•¼.\\n#Person...\n",
      "3  test_3  #Person1#: ìƒì¼ ì¶•í•˜í•´, ì´ê±° ë„ˆë¥¼ ìœ„í•œ ì„ ë¬¼ì´ì•¼, Brian.\\n#Per...\n",
      "4  test_4  #Person1#: ì´ ì˜¬ë¦¼í”½ ê³µì› ì •ë§ í¬ë‹¤! \\n#Person2#: ë§ì•„. ì§€ê¸ˆ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>#Person1#: Ms. Dawson, ë°›ì•„ì“°ê¸° ì¢€ ë¶€íƒë“œë ¤ì•¼ê² ì–´ìš”. \\n#Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person1#: ë“œë””ì–´ ì™”ë„¤! ë­ê°€ ì´ë ‡ê²Œ ì˜¤ë˜ ê±¸ë ¸ì–´?\\n#Person2#: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>#Person1#: Kate, ì—¬ê¸°ì„œ ì¼ì–´ë‚œ ì¼ì„ ë¯¿ê¸° í˜ë“¤ ê±°ì•¼.\\n#Person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>#Person1#: ìƒì¼ ì¶•í•˜í•´, ì´ê±° ë„ˆë¥¼ ìœ„í•œ ì„ ë¬¼ì´ì•¼, Brian.\\n#Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person1#: ì´ ì˜¬ë¦¼í”½ ê³µì› ì •ë§ í¬ë‹¤! \\n#Person2#: ë§ì•„. ì§€ê¸ˆ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fname                                           dialogue\n",
       "0  test_0  #Person1#: Ms. Dawson, ë°›ì•„ì“°ê¸° ì¢€ ë¶€íƒë“œë ¤ì•¼ê² ì–´ìš”. \\n#Per...\n",
       "1  test_1  #Person1#: ë“œë””ì–´ ì™”ë„¤! ë­ê°€ ì´ë ‡ê²Œ ì˜¤ë˜ ê±¸ë ¸ì–´?\\n#Person2#: ...\n",
       "2  test_2  #Person1#: Kate, ì—¬ê¸°ì„œ ì¼ì–´ë‚œ ì¼ì„ ë¯¿ê¸° í˜ë“¤ ê±°ì•¼.\\n#Person...\n",
       "3  test_3  #Person1#: ìƒì¼ ì¶•í•˜í•´, ì´ê±° ë„ˆë¥¼ ìœ„í•œ ì„ ë¬¼ì´ì•¼, Brian.\\n#Per...\n",
       "4  test_4  #Person1#: ì´ ì˜¬ë¦¼í”½ ê³µì› ì •ë§ í¬ë‹¤! \\n#Person2#: ë§ì•„. ì§€ê¸ˆ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test data\n",
    "test_df = pd.read_csv(data_path / 'raw' / 'test.csv')\n",
    "print('âœ… test_df:', test_df.shape)\n",
    "print(test_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IIaIrpH4kWo"
   },
   "source": [
    "### ë°ì´í„° ê°€ê³µ ë° ë°ì´í„°ì…‹ í´ë˜ìŠ¤ êµ¬ì¶•\n",
    ">- csv file ì„ ë¶ˆëŸ¬ì™€ì„œ encoder ì™€ decoderì˜ ì…ë ¥í˜•íƒœë¡œ ê°€ê³µí•˜ê¸°\n",
    ">- ê°€ê³µëœ ë°ì´í„°ë¥¼ torch dataset class ë¡œ êµ¬ì¶•í•˜ì—¬ ëª¨ë¸ì— ì…ë ¥ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oWPawUUflwHa"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ì…ë ¥ì„ ìƒì„±\n",
    "class Preprocess:\n",
    "    def __init__(self,\n",
    "            bos_token: str,\n",
    "            eos_token: str,\n",
    "        ) -> None:\n",
    "\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "\n",
    "    @staticmethod\n",
    "    # ì‹¤í—˜ì— í•„ìš”í•œ ì»¬ëŸ¼ ê°€ì ¸ì˜¤ê¸°\n",
    "    def make_set_as_df(file_path, is_train = True):\n",
    "        if is_train:\n",
    "            df = pd.read_csv(file_path)\n",
    "            train_df = df[['fname','dialogue','summary']]\n",
    "            return train_df\n",
    "        else:\n",
    "            df = pd.read_csv(file_path)\n",
    "            test_df = df[['fname','dialogue']]\n",
    "            return test_df\n",
    "\n",
    "    # BART ëª¨ë¸ì˜ ì…ë ¥, ì¶œë ¥ í˜•íƒœë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì „ì²˜ë¦¬ë¥¼ ì§„í–‰\n",
    "    def make_input(self, dataset,is_test = False):\n",
    "        if is_test:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
    "            return encoder_input.tolist(), list(decoder_input)\n",
    "        else:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = dataset['summary'].apply(lambda x : self.bos_token + str(x))    # Ground truthë¥¼ ë””ì½”ë”ì˜ inputìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ\n",
    "            decoder_output = dataset['summary'].apply(lambda x : str(x) + self.eos_token)\n",
    "            return encoder_input.tolist(), decoder_input.tolist(), decoder_output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6GDvodoF8sED"
   },
   "outputs": [],
   "source": [
    "# Trainì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜\n",
    "class DatasetForTrain(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}      # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()}     # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        # item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item.update(item2)\n",
    "        # item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]                                                                  \n",
    "        item['labels'] = self.labels['input_ids'][idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Validationì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜\n",
    "class DatasetForVal(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}      # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()}     # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        # item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item.update(item2)\n",
    "        # item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        item['labels'] = self.labels['input_ids'][idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Testì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜\n",
    "class DatasetForInference(Dataset):\n",
    "    def __init__(self, encoder_input, test_id, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.test_id = test_id\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
    "        item['ID'] = self.test_id[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hT9z4vvS2CCb"
   },
   "outputs": [],
   "source": [
    "# tokenization ê³¼ì •ê¹Œì§€ ì§„í–‰ëœ ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì— ì…ë ¥ë  ë°ì´í„°ë¥¼ ì¶œë ¥\n",
    "def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n",
    "    train_file_path = os.path.join(data_path, 'raw', 'train.csv')\n",
    "    val_file_path = os.path.join(data_path, 'raw', 'dev.csv')\n",
    "\n",
    "    # train, validationì— ëŒ€í•´ ê°ê° ë°ì´í„°í”„ë ˆì„ì„ êµ¬ì¶•\n",
    "    train_data = preprocessor.make_set_as_df(train_file_path)\n",
    "    val_data = preprocessor.make_set_as_df(val_file_path)\n",
    "\n",
    "    # print('\\nğŸš€ train, valid ë°ì´í„° ë¡œë“œ ì¤‘...')\n",
    "    encoder_input_train , decoder_input_train, decoder_output_train = preprocessor.make_input(train_data)\n",
    "    encoder_input_val , decoder_input_val, decoder_output_val = preprocessor.make_input(val_data)\n",
    "    print(\"\\nâœ… í•™ìŠµ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\")\n",
    "\n",
    "    # print('\\nğŸš€ train, valid ë°ì´í„°ì…‹ ìƒì„± ì¤‘...')\n",
    "    tokenized_encoder_inputs = tokenizer(encoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                            add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_inputs = tokenizer(decoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_ouputs = tokenizer(decoder_output_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    train_inputs_dataset = DatasetForTrain(tokenized_encoder_inputs, tokenized_decoder_inputs, tokenized_decoder_ouputs,len(encoder_input_train))\n",
    "\n",
    "    val_tokenized_encoder_inputs = tokenizer(encoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_inputs = tokenizer(decoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_ouputs = tokenizer(decoder_output_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    val_inputs_dataset = DatasetForVal(val_tokenized_encoder_inputs, val_tokenized_decoder_inputs, val_tokenized_decoder_ouputs,len(encoder_input_val))\n",
    "    print(\"\\nâœ… í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!\")\n",
    "\n",
    "    return train_inputs_dataset, val_inputs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5sKIJ5K5Pz1"
   },
   "source": [
    "### Trainer ë° Trainingargs êµ¬ì¶•í•˜ê¸°\n",
    ">- Huggingface ì˜ Trainer ì™€ Training argumentsë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµì„ ì¼ê´„ì ìœ¼ë¡œ ì²˜ë¦¬í•´ì£¼ëŠ” í´ë˜ìŠ¤ë¥¼ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "aQk8ILcEeGNz"
   },
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì„±ëŠ¥ì— ëŒ€í•œ í‰ê°€ ì§€í‘œ ì •ì˜\n",
    "def compute_metrics(config,tokenizer,pred):\n",
    "    rouge = Rouge()\n",
    "    predictions = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    # ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•´ ë¯¸ë¦¬ ì •ì˜ëœ ë¶ˆí•„ìš”í•œ ìƒì„± í† í°ë“¤ì„ ì œê±°\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "    remove_tokens = config['inference']['remove_tokens']        # configì—ì„œ ì •ì˜í•œ ë¶ˆí•„ìš”í•œ ìƒì„± í† í°\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "\n",
    "    print('\\nğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...')\n",
    "    print(f\"PRED: {replaced_predictions[0]}\")\n",
    "    print(f\"GOLD: {replaced_labels[0]}\")\n",
    "    # print('-'*150)\n",
    "    # print(f\"PRED: {replaced_predictions[1]}\")\n",
    "    # print(f\"GOLD: {replaced_labels[1]}\")\n",
    "    # print('-'*150)\n",
    "    # print(f\"PRED: {replaced_predictions[2]}\")\n",
    "    # print(f\"GOLD: {replaced_labels[2]}\")\n",
    "    print('\\nâœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!')\n",
    "\n",
    "    # ìµœì¢…ì ì¸ ROUGE ì ìˆ˜ë¥¼ ê³„ì‚°\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "\n",
    "    # ROUGE ì ìˆ˜ ì¤‘ F-1 scoreë¥¼ í†µí•´ í‰ê°€\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "RInkG8g-HjBi"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµì„ ìœ„í•œ trainer í´ë˜ìŠ¤ì™€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì •ì˜\n",
    "def load_trainer_for_train(config,generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset):\n",
    "    \n",
    "    # print('\\nğŸš€ training arguments ì •ì˜ ì¤‘...')\n",
    "    # set training args\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "                output_dir=config['general']['output_dir'],\n",
    "                overwrite_output_dir=config['training']['overwrite_output_dir'],\n",
    "                num_train_epochs=config['training']['num_train_epochs'],\n",
    "                learning_rate=config['training']['learning_rate'],\n",
    "                per_device_train_batch_size=config['training']['per_device_train_batch_size'],\n",
    "                per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],\n",
    "                warmup_ratio=config['training']['warmup_ratio'],\n",
    "                weight_decay=config['training']['weight_decay'],\n",
    "                lr_scheduler_type=config['training']['lr_scheduler_type'],\n",
    "                optim =config['training']['optim'],\n",
    "                gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],\n",
    "                evaluation_strategy=config['training']['evaluation_strategy'],\n",
    "                save_strategy =config['training']['save_strategy'],\n",
    "                save_total_limit=config['training']['save_total_limit'],\n",
    "                fp16=config['training']['fp16'],\n",
    "                load_best_model_at_end=config['training']['load_best_model_at_end'],\n",
    "                seed=config['training']['seed'],\n",
    "                logging_dir=config['training']['logging_dir'],\n",
    "                logging_strategy=config['training']['logging_strategy'],\n",
    "                predict_with_generate=config['training']['predict_with_generate'],\n",
    "                generation_max_length=config['training']['generation_max_length'],\n",
    "                do_train=config['training']['do_train'],\n",
    "                do_eval=config['training']['do_eval'],\n",
    "                # report_to=config['training']['report_to']                             # wandb ì‚¬ìš© ì„¤ì •\n",
    "            )\n",
    "\n",
    "    # wandb ì´ˆê¸°í™”\n",
    "    # wandb.init(\n",
    "    #     # entity=config['wandb']['entity'],\n",
    "    #     project=config['wandb']['project'],\n",
    "    #     name=config['wandb']['name'],\n",
    "    # )\n",
    "\n",
    "    # wandb checkpoints ì €ì¥í•˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •\n",
    "    # os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "    # os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "\n",
    "    # EarlyStopping : Validation lossê°€ ë” ì´ìƒ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ í•™ìŠµì„ ì¤‘ë‹¨\n",
    "    MyCallback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=config['training']['early_stopping_patience'],\n",
    "        early_stopping_threshold=config['training']['early_stopping_threshold']\n",
    "    )\n",
    "    print('\\nâœ… training arguments ì •ì˜ ì™„ë£Œ!')\n",
    "    \n",
    "    # print('\\nğŸš€ trainer ìƒì„± ì¤‘...')\n",
    "    # Trainer í´ë˜ìŠ¤ ì •ì˜\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=generate_model,                                                           # ì‚¬ìš©ìê°€ ì‚¬ì „ í•™ìŠµí•˜ê¸° ìœ„í•´ ì‚¬ìš©í•  ëª¨ë¸ ì…ë ¥\n",
    "        args=training_args,\n",
    "        train_dataset=train_inputs_dataset,\n",
    "        eval_dataset=val_inputs_dataset,\n",
    "        compute_metrics = lambda pred: compute_metrics(config,tokenizer, pred),\n",
    "        callbacks = [MyCallback]\n",
    "    )\n",
    "    print('\\nâœ… trainer ìƒì„± ì™„ë£Œ!')\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KKWHe8dE5fSx"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµì„ ìœ„í•œ tokenizerì™€ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "def load_tokenizer_and_model_for_train(config,device):\n",
    "\n",
    "    # print('\\nğŸš€ tokenizer & model ë¡œë“œ ì¤‘...')\n",
    "    print(f'\\nğŸ¤– ëª¨ë¸ëª… : {config[\"general\"][\"model_name\"]}')\n",
    "    model_name = config['general']['model_name']\n",
    "    bart_config = BartConfig().from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    generate_model = BartForConditionalGeneration.from_pretrained(config['general']['model_name'],config=bart_config)\n",
    "\n",
    "    special_tokens_dict={'additional_special_tokens':config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))          # ì‚¬ì „ì— special tokenì„ ì¶”ê°€í–ˆìœ¼ë¯€ë¡œ ì¬êµ¬ì„±\n",
    "    generate_model.to(device)\n",
    "    # print(generate_model.config)\n",
    "    # print('âœ… tokenizer & model ë¡œë“œ ì™„ë£Œ!')\n",
    "\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´í¬í¬ì¸íŠ¸ í‰ê°€ í•¨ìˆ˜\n",
    "def eval_checkpoint(ckpt_path, config, tokenizer, eval_dataset):\n",
    "    print(f\"\\n=== Evaluate {ckpt_path} ===\")\n",
    "    model = BartForConditionalGeneration.from_pretrained(ckpt_path)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    args = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"./tmp_eval\",\n",
    "        per_device_eval_batch_size=config[\"training\"][\"per_device_eval_batch_size\"],\n",
    "        predict_with_generate=True,\n",
    "        do_train=False,\n",
    "        do_eval=True,\n",
    "        report_to=\"none\",           # wandb ì„¤ì •\n",
    "    )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=lambda pred: compute_metrics(config, tokenizer, pred),\n",
    "    )\n",
    "\n",
    "    metrics = trainer.evaluate()\n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best & ë§ˆì§€ë§‰ checkpoint ì°¾ëŠ” í•¨ìˆ˜\n",
    "def get_best_and_last_checkpoints(config):\n",
    "    output_dir = Path(config[\"general\"][\"output_dir\"])\n",
    "    ckpt_root = Path(config[\"inference\"][\"ckt_path\"])\n",
    "\n",
    "    # ë§ˆì§€ë§‰ checkpoint ì°¾ê¸°\n",
    "    ckpt_dirs = [p for p in ckpt_root.glob(\"checkpoint-*\") if p.is_dir()]\n",
    "    def _get_step(p: Path) -> int:\n",
    "        return int(p.name.split(\"-\")[-1])\n",
    "    ckpt_dirs = sorted(ckpt_dirs, key=_get_step)\n",
    "    last_ckpt = ckpt_dirs[-1]\n",
    "\n",
    "    # best checkpoint ì°¾ê¸°\n",
    "    state_path = last_ckpt / \"trainer_state.json\"\n",
    "    with open(state_path, \"r\") as f:\n",
    "        state = json.load(f)\n",
    "    best_ckpt = state.get(\"best_model_checkpoint\", None)\n",
    "\n",
    "    print(f\"\\nğŸš€ ì²´í¬í¬ì¸íŠ¸ íƒìƒ‰ ì¤‘...\")\n",
    "    print(\"- best checkpoint :\", best_ckpt)\n",
    "    print(\"- last_ckpt :\", last_ckpt)\n",
    "\n",
    "    return str(best_ckpt), str(last_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_exp_config(config: dict) -> dict:\n",
    "    # ìˆ˜ì • í•„ìš”\n",
    "    return {\n",
    "        \"exp_name\": config.get(\"wandb\", {}).get(\"name\", \"no_name\"),\n",
    "        \"model_name\": config[\"general\"][\"model_name\"],\n",
    "        \"num_train_epochs\": config[\"training\"][\"num_train_epochs\"],\n",
    "        \"learning_rate\": config[\"training\"][\"learning_rate\"],\n",
    "        \"per_device_train_batch_size\": config[\"training\"][\"per_device_train_batch_size\"],\n",
    "        \"per_device_eval_batch_size\": config[\"training\"][\"per_device_eval_batch_size\"],\n",
    "        \"warmup_ratio\": config[\"training\"][\"warmup_ratio\"],\n",
    "        \"weight_decay\": config[\"training\"][\"weight_decay\"],\n",
    "        \"gradient_accumulation_steps\": config[\"training\"][\"gradient_accumulation_steps\"],\n",
    "        \"seed\": config[\"training\"][\"seed\"],\n",
    "        \"lr_scheduler_type\": config[\"training\"][\"lr_scheduler_type\"],\n",
    "        \"optim\": config[\"training\"][\"optim\"],\n",
    "        \"generation_max_length\": config[\"training\"][\"generation_max_length\"],\n",
    "    }\n",
    "\n",
    "# í•œ ë²ˆì˜ ì‹¤í—˜ ê²°ê³¼ë¥¼ exp_log.csvì— ëˆ„ì  ì €ì¥í•˜ëŠ” í•¨ìˆ˜\n",
    "def log_experiment_result(config: dict, metrics: dict, ckpt_info: dict | None = None,\n",
    "                          csv_path: str = \"../outputs/exp_log.csv\",) -> pd.DataFrame:\n",
    "\n",
    "    row = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        **extract_exp_config(config),\n",
    "    }\n",
    "\n",
    "    # í‰ê°€ì§€í‘œ ë¶™ì´ê¸° (eval_* ë§Œ í•„í„°ë§)\n",
    "    for k, v in metrics.items():\n",
    "        if k.startswith(\"eval_\"):\n",
    "            col_name = k.replace(\"-\", \"_\")\n",
    "            row[col_name] = v\n",
    "\n",
    "    # checkpoint ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€\n",
    "    if ckpt_info is not None:\n",
    "        row.update(ckpt_info)\n",
    "\n",
    "    # DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "    row_df = pd.DataFrame([row])\n",
    "\n",
    "    # ê¸°ì¡´ csvê°€ ìˆìœ¼ë©´ append, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±\n",
    "    csv_path = Path(csv_path)\n",
    "    if csv_path.exists():\n",
    "        prev_df = pd.read_csv(csv_path)\n",
    "        new_df = pd.concat([prev_df, row_df], ignore_index=True)\n",
    "    else:\n",
    "        new_df = row_df\n",
    "\n",
    "    # ì €ì¥\n",
    "    new_df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nğŸ’¾ ì‹¤í—˜ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {csv_path}\")\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvutzKQYvQgl"
   },
   "source": [
    "### ëª¨ë¸ í•™ìŠµ\n",
    ">- ì•ì—ì„œ êµ¬ì¶•í•œ í´ë˜ìŠ¤ ë° í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnA96wmR44is"
   },
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    # # ì‚¬ìš©í•  device ì •ì˜\n",
    "    # device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    # print(f'âš¡ ì‚¬ìš© ë””ë°”ì´ìŠ¤ : {device} | torch ë²„ì „ : {torch.__version__}')\n",
    "\n",
    "    # # ì‚¬ìš©í•  ëª¨ë¸ê³¼ tokenizer ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    # generate_model , tokenizer = load_tokenizer_and_model_for_train(config,device)\n",
    "    # print('âœ… tokenizer ìŠ¤í˜ì…œ í† í° :', tokenizer.special_tokens_map)\n",
    "\n",
    "    # # í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    # preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token']) # decoder_start_token: str, eos_token: str\n",
    "    # data_path = config['general']['data_path']\n",
    "    # train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config,preprocessor, data_path, tokenizer)\n",
    "\n",
    "    # # Trainer í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    # trainer = load_trainer_for_train(config, generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset)\n",
    "    # # ì €ì¥ëœ checkpoint ì´í›„ë¶€í„° ì‹¤í–‰ (ì¤‘ê°„ì— í•™ìŠµì´ ì¤‘ë‹¨ë¼ë„ ë¬¸ì œ ì—†ë„ë¡ í•˜ê¸° ìœ„í•¨)\n",
    "    # trainer.train()\n",
    "\n",
    "    # best / last ckpt ìë™ ì°¾ê¸°\n",
    "    best_ckpt, last_ckpt = get_best_and_last_checkpoints(config)\n",
    "\n",
    "    # ë‘ ê°œ ì²´í¬í¬ì¸íŠ¸ í‰ê°€ â†’ DataFrame ë¹„êµ\n",
    "    all_results = []\n",
    "    for name, ckpt in [(\"best\", best_ckpt), (\"last\", last_ckpt)]:\n",
    "        metrics = eval_checkpoint(ckpt, config, tokenizer, val_inputs_dataset)\n",
    "        all_results.append({\n",
    "            \"type\": name,\n",
    "            \"checkpoint\": os.path.basename(ckpt),\n",
    "            **{k: v for k, v in metrics.items() if k.startswith(\"eval_\")},\n",
    "        })\n",
    "    df = pd.DataFrame(all_results)\n",
    "    display(df.round(4))\n",
    "\n",
    "    # ì‹¤í—˜ ë¡œê·¸ ì‘ì„±\n",
    "    exp_df = log_experiment_result(\n",
    "        config,\n",
    "        metrics,\n",
    "        ckpt_info={\"which\": \"best\", \"ckpt\": best_ckpt},\n",
    "        csv_path=\"../outputs/exp_log.csv\",\n",
    "    )\n",
    "\n",
    "    # wandb ì¢…ë£Œ\n",
    "    # wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1DMS60wL-Dhv",
    "outputId": "cbb6aba7-18ff-4d12-b9e7-2a2ef31d94d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ì²´í¬í¬ì¸íŠ¸ íƒìƒ‰ ì¤‘...\n",
      "- best checkpoint : ../outputs/checkpoints/checkpoint-1750\n",
      "- last_ckpt : ../outputs/checkpoints/checkpoint-2250\n",
      "\n",
      "=== Evaluate ../outputs/checkpoints/checkpoint-1750 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:   #Person1#ì€ ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ \n",
      "GOLD: #Person2#ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2#ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                              \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "{'eval_loss': 0.5997087955474854, 'eval_rouge-1': 0.16493341416565194, 'eval_rouge-2': 0.05019222142976799, 'eval_rouge-l': 0.16075778271732963, 'eval_runtime': 5.0832, 'eval_samples_per_second': 98.166, 'eval_steps_per_second': 3.148}\n",
      "\n",
      "=== Evaluate ../outputs/checkpoints/checkpoint-2250 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:   #Person1#ì€ ê°ê¸°ì— ê±¸ë ¸ê³ ,  #Person2# \n",
      "GOLD: #Person2#ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2#ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                              \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "{'eval_loss': 0.5969681143760681, 'eval_rouge-1': 0.15465663635945834, 'eval_rouge-2': 0.042542628412776784, 'eval_rouge-l': 0.14892862902645612, 'eval_runtime': 5.0999, 'eval_samples_per_second': 97.845, 'eval_steps_per_second': 3.137}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_rouge-1</th>\n",
       "      <th>eval_rouge-2</th>\n",
       "      <th>eval_rouge-l</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best</td>\n",
       "      <td>checkpoint-1750</td>\n",
       "      <td>0.5997</td>\n",
       "      <td>0.1649</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>5.0832</td>\n",
       "      <td>98.166</td>\n",
       "      <td>3.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last</td>\n",
       "      <td>checkpoint-2250</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.1489</td>\n",
       "      <td>5.0999</td>\n",
       "      <td>97.845</td>\n",
       "      <td>3.137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type       checkpoint  eval_loss  eval_rouge-1  eval_rouge-2  eval_rouge-l  \\\n",
       "0  best  checkpoint-1750     0.5997        0.1649        0.0502        0.1608   \n",
       "1  last  checkpoint-2250     0.5970        0.1547        0.0425        0.1489   \n",
       "\n",
       "   eval_runtime  eval_samples_per_second  eval_steps_per_second  \n",
       "0        5.0832                   98.166                  3.148  \n",
       "1        5.0999                   97.845                  3.137  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ ì‹¤í—˜ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: ../outputs/exp_log.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(loaded_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFtWqowCGzEc"
   },
   "source": [
    "### ëª¨ë¸ ì¶”ë¡ \n",
    ">- test dataë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "lV1Do7nlTylG"
   },
   "outputs": [],
   "source": [
    "# tokenization ê³¼ì •ê¹Œì§€ ì§„í–‰ëœ test ë°ì´í„° ì¶œë ¥\n",
    "def prepare_test_dataset(config,preprocessor, tokenizer):\n",
    "    \n",
    "    test_file_path = os.path.join(config['general']['data_path'], 'raw', 'test.csv')\n",
    "\n",
    "    test_data = preprocessor.make_set_as_df(test_file_path,is_train=False)\n",
    "    test_id = test_data['fname']\n",
    "    encoder_input_test , decoder_input_test = preprocessor.make_input(test_data,is_test=True)\n",
    "    print('\\nâœ… test ë°ì´í„° ë¡œë“œ ì™„ë£Œ!')\n",
    "\n",
    "    test_tokenized_encoder_inputs = tokenizer(encoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,)\n",
    "    test_tokenized_decoder_inputs = tokenizer(decoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False,)\n",
    "\n",
    "    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n",
    "    print('\\nâœ… test ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!')\n",
    "\n",
    "    return test_data, test_encoder_inputs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "eb49bLULT3aS"
   },
   "outputs": [],
   "source": [
    "# ì¶”ë¡ ì„ ìœ„í•œ tokenizerì™€ í•™ìŠµì‹œí‚¨ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "def load_tokenizer_and_model_for_test(config,device):\n",
    "    model_name = config['general']['model_name']\n",
    "    ckt_path = config['inference']['ckt_path']\n",
    "    print('\\nğŸ¤– ëª¨ë¸ëª… :', model_name)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    # ìë™ íƒìƒ‰ëœ best checkpointë¥¼ ëª¨ë¸ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    best_ckpt, last_ckpt = get_best_and_last_checkpoints(config)\n",
    "    generate_model = BartForConditionalGeneration.from_pretrained(best_ckpt)\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))\n",
    "    generate_model.to(device)\n",
    "    print('ğŸ§  ìµœì¢… ëª¨ë¸ :', best_ckpt)\n",
    "    print('âœ… tokenizer & model ë¡œë“œ ì™„ë£Œ!')\n",
    "\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "Axzu9rsoGLgJ"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ì´ ìƒì„±í•œ ìš”ì•½ë¬¸ì˜ ì¶œë ¥ ê²°ê³¼ ë³´ê¸°\n",
    "def inference(config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print(f'âš¡ ì‚¬ìš© ë””ë°”ì´ìŠ¤ : {device} | torch ë²„ì „ : {torch.__version__}')\n",
    "    \n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_test(config,device)\n",
    "\n",
    "    data_path = config['general']['data_path']\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
    "\n",
    "    test_data, test_encoder_inputs_dataset = prepare_test_dataset(config,preprocessor, tokenizer)\n",
    "    dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=config['inference']['batch_size'])\n",
    "\n",
    "    summary = []\n",
    "    text_ids = []\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataloader):\n",
    "            text_ids.extend(item['ID'])\n",
    "            generated_ids = generate_model.generate(input_ids=item['input_ids'].to('cuda:0'),\n",
    "                            no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                            early_stopping=config['inference']['early_stopping'],\n",
    "                            max_length=config['inference']['generate_max_length'],\n",
    "                            num_beams=config['inference']['num_beams'],\n",
    "                        )\n",
    "            for ids in generated_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "\n",
    "    # ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•˜ì—¬ ë…¸ì´ì¦ˆì— í•´ë‹¹ë˜ëŠ” ìŠ¤í˜ì…œ í† í° ì œê±°\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    preprocessed_summary = summary.copy()\n",
    "    for token in remove_tokens:\n",
    "        preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": test_data['fname'],\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    result_path = config['inference']['result_path']\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    save_name = \"output_baseline_v1.csv\"                                # ë²„ì „ê´€ë¦¬\n",
    "    output.to_csv(os.path.join(result_path, save_name), index=False)         \n",
    "    print(f\"ğŸ’¾ ì¶”ë¡  ê²°ê³¼ ì €ì¥ ì™„ë£Œ : {result_path}{save_name}\")\n",
    "\n",
    "    print(\"\\nğŸ’¬ testë¬¸ ìš”ì•½ ê²°ê³¼\")\n",
    "    print(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "-pJ1ZXf-5V50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ ì‚¬ìš© ë””ë°”ì´ìŠ¤ : cuda:0 | torch ë²„ì „ : 2.1.0\n",
      "\n",
      "ğŸ¤– ëª¨ë¸ëª… : digit82/kobart-summarization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ì²´í¬í¬ì¸íŠ¸ íƒìƒ‰ ì¤‘...\n",
      "- best checkpoint : ../outputs/checkpoints/checkpoint-1750\n",
      "- last_ckpt : ../outputs/checkpoints/checkpoint-2250\n",
      "ğŸ§  ìµœì¢… ëª¨ë¸ : ../outputs/checkpoints/checkpoint-1750\n",
      "âœ… tokenizer & model ë¡œë“œ ì™„ë£Œ!\n",
      "\n",
      "âœ… test ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\n",
      "\n",
      "âœ… test ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:22<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ ì¶”ë¡  ê²°ê³¼ ì €ì¥ ì™„ë£Œ : ../outputs/prediction/output_baseline_v1.csv\n",
      "\n",
      "ğŸ’¬ testë¬¸ ìš”ì•½ ê²°ê³¼\n",
      "        fname                                            summary\n",
      "0      test_0   #Person1# ì€ Ms. Dawsonì—ê²Œ ì‚¬ë‚´ ë©”ëª¨ë¥¼ ì‘ì„±í•˜ê³  ë°°í¬í•´ë‹¬ë¼ê³  ìš”...\n",
      "1      test_1    Carrefour êµì°¨ë¡œ ê·¼ì²˜ì—ì„œ êµí†µì²´ì¦ì´ ê³„ì†ë˜ì—ˆê³ , #Person1# ì€ ...\n",
      "2      test_2   #Person1# ì€ Kateì—ê²Œ Mashaì™€ Heroê°€ ë‘ ë‹¬ ë™ì•ˆ ë³„ê±° ì¤‘ì´ë©°...\n",
      "3      test_3    Brianì€ #Person1# ì—ê²Œ ìì‹ ì˜ ìƒì¼ì„ ì¶•í•˜í•˜ê¸° ìœ„í•´ íŒŒí‹°ì— ì™”ë‹¤ê³  ...\n",
      "4      test_4   #Person1# ê³¼ #Person2# ëŠ” ì˜¬ë¦¼í”½ ê³µì›ì˜ í¬ê¸°ì— ëŒ€í•´ ì´ì•¼ê¸°í•©ë‹ˆë‹¤...\n",
      "..        ...                                                ...\n",
      "494  test_495    Jackì€ Charlieì—ê²Œ ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ê²Œì„ì„ ì œì•ˆí•˜ê³ , ê·¸ë…€ëŠ” ìˆ™ì œë¥¼ ë¨¼ì €...\n",
      "495  test_496   #Person2# ëŠ” #Person1# ì—ê²Œ ì‹œê³¨ ìŒì•…ì— ê´€ì‹¬ì„ ê°–ê²Œ ëœ ê³„ê¸°ì™€ ...\n",
      "496  test_497    AliceëŠ” ì„¸íƒê¸°ì— ë¹„ëˆ„ê°€ ë“¤ì–´ ìˆì§€ ì•Šì•„ ë¶ˆí¸í•¨ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. #Pers...\n",
      "497  test_498    SteveëŠ” Matthewì—ê²Œ ì„ëŒ€ë¥¼ ê°±ì‹ í•˜ê³  ì‹¶ì§€ ì•Šë‹¤ê³  ë§í•˜ë©°, Mrs. T...\n",
      "498  test_499    FrankëŠ” Betsyì—ê²Œ ìŠ¹ì§„ ì†Œì‹ì„ ì „í•˜ë©°, íŒŒí‹°ì— 150ëª…ì´ ì°¸ì„í•  ê²ƒì´ë¼...\n",
      "\n",
      "[499 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ì¶”ë¡  ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    output = inference(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OsPmLfhbzZqS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ê²°ì¸¡ì¹˜ ë° ë°ì´í„°íƒ€ì… í™•ì¸\n",
      "- shape: (499, 2)\n",
      "\n",
      "- null check:\n",
      " fname      0\n",
      "summary    0\n",
      "dtype: int64\n",
      "\n",
      "- dtypes:\n",
      " fname      object\n",
      "summary    object\n",
      "dtype: object\n",
      "\n",
      "- duplicated id: 0\n",
      "\n",
      "ğŸ”ìš”ì•½ ê¸¸ì´ ì´ìƒì¹˜ í™•ì¸\n",
      "count    499.000000\n",
      "mean     105.683367\n",
      "std       19.371654\n",
      "min       66.000000\n",
      "25%       91.000000\n",
      "50%      103.000000\n",
      "75%      117.000000\n",
      "max      186.000000\n",
      "Name: summary_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ì œì¶œ ì „ í™•ì¸\n",
    "print(\"ğŸ” ê²°ì¸¡ì¹˜ ë° ë°ì´í„°íƒ€ì… í™•ì¸\")\n",
    "print(\"- shape:\", output.shape)\n",
    "print(\"\\n- null check:\\n\", output.isnull().sum())\n",
    "print(\"\\n- dtypes:\\n\", output.dtypes)\n",
    "print(\"\\n- duplicated id:\", output['fname'].duplicated().sum())\n",
    "\n",
    "print(\"\\nğŸ”ìš”ì•½ ê¸¸ì´ ì´ìƒì¹˜ í™•ì¸\")\n",
    "output_summary_length = output.copy()\n",
    "output_summary_length['summary_length'] = output_summary_length['summary'].str.len()\n",
    "print(output_summary_length['summary_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ì‹¤í—˜ ë¡œê·¸\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>warmup_ratio</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_rouge_l</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>which</th>\n",
       "      <th>ckpt</th>\n",
       "      <th>lb_rouge_1</th>\n",
       "      <th>lb_rouge_2</th>\n",
       "      <th>lb_rouge_l</th>\n",
       "      <th>lb_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-28 18:01:14</td>\n",
       "      <td>baseline_v1</td>\n",
       "      <td>digit82/kobart-summarization</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148929</td>\n",
       "      <td>5.0999</td>\n",
       "      <td>97.845</td>\n",
       "      <td>3.137</td>\n",
       "      <td>best</td>\n",
       "      <td>../outputs/checkpoints/checkpoint-1750</td>\n",
       "      <td>0.5634</td>\n",
       "      <td>0.3668</td>\n",
       "      <td>0.4819</td>\n",
       "      <td>47.0683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp     exp_name                    model_name  \\\n",
       "0  2025-11-28 18:01:14  baseline_v1  digit82/kobart-summarization   \n",
       "\n",
       "   num_train_epochs  learning_rate  per_device_train_batch_size  \\\n",
       "0                20        0.00001                           50   \n",
       "\n",
       "   per_device_eval_batch_size  warmup_ratio  weight_decay  \\\n",
       "0                          32           0.1          0.01   \n",
       "\n",
       "   gradient_accumulation_steps  ...  eval_rouge_l eval_runtime  \\\n",
       "0                            1  ...      0.148929       5.0999   \n",
       "\n",
       "  eval_samples_per_second  eval_steps_per_second  which  \\\n",
       "0                  97.845                  3.137   best   \n",
       "\n",
       "                                     ckpt  lb_rouge_1  lb_rouge_2  lb_rouge_l  \\\n",
       "0  ../outputs/checkpoints/checkpoint-1750      0.5634      0.3668      0.4819   \n",
       "\n",
       "   lb_final  \n",
       "0   47.0683  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ì œì¶œ í›„ LB ì ìˆ˜ > ì‹¤í—˜ ë¡œê·¸ì— ê¸°ë¡\n",
    "exp_log = pd.read_csv(\"../outputs/exp_log.csv\")\n",
    "print(\"ğŸ“ ì‹¤í—˜ ë¡œê·¸\")\n",
    "display(exp_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_rouge_1</th>\n",
       "      <th>eval_rouge_2</th>\n",
       "      <th>eval_rouge_l</th>\n",
       "      <th>lb_rouge_1</th>\n",
       "      <th>lb_rouge_2</th>\n",
       "      <th>lb_rouge_l</th>\n",
       "      <th>lb_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-28 18:01:14</td>\n",
       "      <td>baseline_v1</td>\n",
       "      <td>0.596968</td>\n",
       "      <td>0.154657</td>\n",
       "      <td>0.042543</td>\n",
       "      <td>0.148929</td>\n",
       "      <td>0.5634</td>\n",
       "      <td>0.3668</td>\n",
       "      <td>0.4819</td>\n",
       "      <td>47.0683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp     exp_name  eval_loss  eval_rouge_1  eval_rouge_2  \\\n",
       "0  2025-11-28 18:01:14  baseline_v1   0.596968      0.154657      0.042543   \n",
       "\n",
       "   eval_rouge_l  lb_rouge_1  lb_rouge_2  lb_rouge_l  lb_final  \n",
       "0      0.148929      0.5634      0.3668      0.4819   47.0683  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ì ìˆ˜ë§Œ ë³´ê¸°\n",
    "display(exp_log[[\"timestamp\", \"exp_name\", \"eval_loss\", \"eval_rouge_1\", \"eval_rouge_2\", \"eval_rouge_l\", \"lb_rouge_1\", \"lb_rouge_2\", \"lb_rouge_l\", \"lb_final\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²˜ë¦¬\n",
    "# ë°ì´í„° ì¦ê°•, hard case ë¶„ì„, error patternì— ë”°ë¥¸ rule ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solar + baseline ì¡°í•©\n",
    "#     (1) ì—ëŸ¬ ì¼€ì´ìŠ¤ì— í•œí•´ Solarë¡œ í›„ì²˜ë¦¬\n",
    "#     (2) baseline ìš”ì•½ì´ ë„ˆë¬´ ì§§ì„ ë•Œë§Œ Solar ì¬ìš”ì•½"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "NLP venv",
   "language": "python",
   "name": "nlp-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "083ea69907bb48d4a8fff919bac51aad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08d05bc20a96432badd459e1ffaf868e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13651c09564a4337b8274c1cb436faa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14f6c91d6c634379b498586c51e606e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21d2e54b5a0a4f79973a512105da43eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2307c6dcbe0141acb5e61baae19cade7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "285007b45236478ca147c6df752c8da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a190bda0b72407e9a953cd2104dd3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fd3d7bbcd6948d8904d33001f95ea03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3645438ace1f4596a8dbc157b48c1521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14f6c91d6c634379b498586c51e606e0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_08d05bc20a96432badd459e1ffaf868e",
      "value": " 295/295 [00:00&lt;00:00, 21.3kB/s]"
     }
    },
    "3a04e871b74b45d7bf02fd33bb103577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bcd6b6b956347b29e1efa20a1d00542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c284a826f6843f6aa47eacad478ac30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_affff1d8a89e4c14955d1b2aa39ff1ab",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_13651c09564a4337b8274c1cb436faa5",
      "value": "tokenizer.json: 100%"
     }
    },
    "45187decb58b4ad39ad532259c6277e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4747b668e2fa4ab58a449446f80030f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52095cc7087243ac916055e569fd22f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c18f0e3bc35e44d9915c3f84cd282a26",
      "max": 109,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a04e871b74b45d7bf02fd33bb103577",
      "value": 109
     }
    },
    "58001a60eacc44d5b38a68648adccde4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58c794fb7ce543a39fdf66d757f6eeab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f5fde5b0ac840a18bd5cc380e564ff6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_45187decb58b4ad39ad532259c6277e5",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "5dfcf310ca9e4e2794076098a5d69cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c284a826f6843f6aa47eacad478ac30",
       "IPY_MODEL_6caedd60c6b747469c82930be1f95d6d",
       "IPY_MODEL_64f2218f899d446393cfea44f206f0a6"
      ],
      "layout": "IPY_MODEL_d068f541df3f438dbd5138863e64b2f2"
     }
    },
    "64f2218f899d446393cfea44f206f0a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d22fbc2c5dbf422399e496c9b500025a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_775d8bbeceac4e2da4f21ab6235c89ed",
      "value": " 682k/682k [00:00&lt;00:00, 5.40MB/s]"
     }
    },
    "6caedd60c6b747469c82930be1f95d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bcd6b6b956347b29e1efa20a1d00542",
      "max": 682133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fd3d7bbcd6948d8904d33001f95ea03",
      "value": 682133
     }
    },
    "6f5fde5b0ac840a18bd5cc380e564ff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775d8bbeceac4e2da4f21ab6235c89ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a6464a355f7464c989033965d418a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2307c6dcbe0141acb5e61baae19cade7",
      "max": 295,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4747b668e2fa4ab58a449446f80030f5",
      "value": 295
     }
    },
    "a15af9e8158f4903b9189f3d322a5ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac00d6c2cf974b33a628acb3f1471316",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_285007b45236478ca147c6df752c8da4",
      "value": " 109/109 [00:00&lt;00:00, 9.44kB/s]"
     }
    },
    "ac00d6c2cf974b33a628acb3f1471316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "affff1d8a89e4c14955d1b2aa39ff1ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18f0e3bc35e44d9915c3f84cd282a26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d068f541df3f438dbd5138863e64b2f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d22fbc2c5dbf422399e496c9b500025a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de1a3f7701c243839fe03b930a9b9e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebc22683058a4f229c5588e52fc93536",
       "IPY_MODEL_52095cc7087243ac916055e569fd22f3",
       "IPY_MODEL_a15af9e8158f4903b9189f3d322a5ef3"
      ],
      "layout": "IPY_MODEL_21d2e54b5a0a4f79973a512105da43eb"
     }
    },
    "e920dbc173c045d1a32143349f1dff8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58c794fb7ce543a39fdf66d757f6eeab",
       "IPY_MODEL_8a6464a355f7464c989033965d418a8a",
       "IPY_MODEL_3645438ace1f4596a8dbc157b48c1521"
      ],
      "layout": "IPY_MODEL_58001a60eacc44d5b38a68648adccde4"
     }
    },
    "ebc22683058a4f229c5588e52fc93536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_083ea69907bb48d4a8fff919bac51aad",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2a190bda0b72407e9a953cd2104dd3b2",
      "value": "special_tokens_map.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
