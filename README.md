<!-- Header -->
<div align="center">

![header](https://capsule-render.vercel.app/api?type=rounded&height=170&text=Dialogue%20Summarization&desc=%EC%9D%BC%EC%83%81%20%EB%8C%80%ED%99%94%20%EC%9A%94%EC%95%BD%20NLP%20%EB%8C%80%ED%9A%8C%20%EC%84%A0%ED%98%95%20%EB%AA%A8%EB%8D%B8&fontSize=35&descSize=16&descAlignY=65&color=gradient&fontColor=ffffff&animation=fadeIn)

<h3>ğŸ—£ï¸ KoBART ê¸°ë°˜ ì¼ìƒ ëŒ€í™” ìš”ì•½ ëª¨ë¸ Â· Dialogue Summarization Competition ğŸ—£ï¸</h3>

<!-- ì›í•˜ë©´ repo ì£¼ì†Œë¡œ ë°”ê¿”ë„ ë¨
[![GitHub stars](https://img.shields.io/github/stars/USER/REPO?style=social)](https://github.com/USER/REPO)
[![GitHub forks](https://img.shields.io/github/forks/USER/REPO?style=social)](https://github.com/USER/REPO)
-->

</div>

---

## ğŸ’» í”„ë¡œì íŠ¸ ì†Œê°œ

### ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” **ì¼ìƒ ëŒ€í™”(dialogue)ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ í•œ ë¬¸ì¥ ìš”ì•½(summary)ì„ ìƒì„±í•˜ëŠ” NLP ëª¨ë¸**ì„ êµ¬ì¶•í•œ ëŒ€íšŒìš© ë¦¬í¬ì§€í† ë¦¬ì…ë‹ˆë‹¤.

- **Task**: Dialogue Summarization (Abstractive Summarization)  
- **Model**: `digit82/kobart-summarization` (KoBART ê¸°ë°˜ í•œêµ­ì–´ ìš”ì•½ ëª¨ë¸)  
- **Goal**: ì¼ìƒ ëŒ€í™” ë¡œê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ, **í•µì‹¬ ë‚´ìš©ì„ 1ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½í•˜ëŠ” ëª¨ë¸** ë§Œë“¤ê¸°  
- **Metric**: ROUGE-1 / ROUGE-2 / ROUGE-L F1 í‰ê·   

ëŒ€íšŒì—ì„œ ì œê³µëœ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì„ ì‹œì‘ì ìœ¼ë¡œ,  
**EDA â†’ ì „ì²˜ë¦¬ ì „ëµ â†’ KoBART íŒŒì¸íŠœë‹ â†’ ì‹¤í—˜Â·Ablation**ê¹Œì§€ ì „ì²´ ê³¼ì •ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

---

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

> ì´ ë¦¬í¬ì§€í† ë¦¬ëŠ” **ìµœì¢… ê²°ê³¼ ì¬í˜„ì— í•„ìš”í•œ í•µì‹¬ íŒŒì¼ë§Œ ì •ë¦¬í•˜ì—¬ ì—…ë¡œë“œ**ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

```bash
nlp-competition
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml                    # ê²½ë¡œ, ëª¨ë¸ëª…, í•™ìŠµ/ì¶”ë¡  ì„¤ì •
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                           # ëŒ€íšŒ ì œê³µ ì›ë³¸ ë°ì´í„° (train/dev/test) ìœ„ì¹˜
â”‚   â””â”€â”€ processed/                     # ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ê²½ë¡œ
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda/
â”‚   â”‚   â””â”€â”€ eda_v2_input_only.ipynb    # ë°ì´í„° EDA
â”‚   â”œâ”€â”€ 02_preprocessing/
â”‚   â”‚   â””â”€â”€ preprocessing_v2_input_only.ipynb   # ìµœì¢… ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ 03_modeling/
â”‚   â”‚   â””â”€â”€ modeling_kobart.ipynb      # KoBART í•™ìŠµ/ê²€ì¦
â”‚   â”œâ”€â”€ baseline.ipynb                 # ëŒ€íšŒ ë² ì´ìŠ¤ë¼ì¸ ì¬í˜„
â”‚   â””â”€â”€ baseline_solar.ipynb           # Solar ê¸°ë°˜ í›„ì²˜ë¦¬/ì‹¤í—˜ìš© ë…¸íŠ¸ë¶
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ prediction/
â”‚   â”‚   â”œâ”€â”€ output_preprocessed_v2_input_only.csv
â”‚   â”‚   â””â”€â”€ output_preprocessed_v2_input_only_wd0.01_ls0.1.csv  # ìµœì¢… ì œì¶œ íŒŒì¼
â”‚   â””â”€â”€ exp_log.csv                    # ì£¼ìš” ì‹¤í—˜ ê¸°ë¡ (dev/LB ê²°ê³¼ ìš”ì•½)
â”‚
â”œâ”€â”€ src/                               # (ì„ íƒ) ì¶”í›„ .py ì½”ë“œë¡œ ì •ë¦¬í•  ê³µê°„
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

ğŸ§ª ëŒ€íšŒ & ë°ì´í„° ìš”ì•½
ğŸ¯ ëŒ€íšŒ ì •ë³´

ëŒ€íšŒ ì´ë¦„: Dialogue Summarization | ì¼ìƒ ëŒ€í™” ìš”ì•½

ëª©í‘œ: ì¼ìƒ ëŒ€í™”ë¥¼ ì…ë ¥ë°›ì•„, ëŒ€í™”ì˜ í•µì‹¬ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ëª¨ë¸ êµ¬ì¶•

í‰ê°€ ì§€í‘œ:

ROUGE-1 F1

ROUGE-2 F1

ROUGE-L F1
â†’ ì„¸ ì ìˆ˜ì˜ í‰ê· ìœ¼ë¡œ ìµœì¢… í‰ê°€

ğŸ§¾ ë°ì´í„° êµ¬ì„±

train.csv: 12,410ê°œ (fname, dialogue, summary, topic)

dev.csv: 498ê°œ

test.csv: 499ê°œ (summary ì—†ìŒ)

ê° ìƒ˜í”Œì€ ì•„ë˜ì™€ ê°™ì€ êµ¬ì¡°ë¥¼ ê°€ì§:

fname,dialogue,summary,topic
train_0,"#Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mr. Smith. ì €ëŠ” Dr. Hawkinsì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ë¬´ìŠ¨ ì¼ë¡œ ì˜¤ì…¨ì–´ìš”? 
#Person2#: ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ë ¤ê³  ì™”ì–´ìš”.
...
#Person1#: ë‹´ë°°ê°€ íì•”í•˜ê³  ì‹¬ì¥ë³‘ì˜ ì£¼ëœ ì›ì¸ì¸ ê±° ì•„ì‹œì£ ? ëŠìœ¼ì…”ì•¼ í•´ìš”.
#Person2#: ë„¤, ê³ ë§™ìŠµë‹ˆë‹¤, ì˜ì‚¬ ì„ ìƒë‹˜.",
"Mr. SmithëŠ” ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ëŸ¬ ì™€ì„œ ë§¤ë…„ ê²€ì§„ í•„ìš”ì„±ê³¼ ê¸ˆì—° ê´€ë ¨ ë„ì›€ì„ ì•ˆë‚´ë°›ëŠ”ë‹¤.",ê±´ê°•ê²€ì§„

ğŸ” EDA & ì „ì²˜ë¦¬ ì „ëµ
1ï¸âƒ£ EDA í•µì‹¬ ì¸ì‚¬ì´íŠ¸

Dialogue ê¸¸ì´

í‰ê· : ì•½ 320â€“360 tokens

Long-tail ë¶„í¬: ë§¤ìš° ê¸´ ëŒ€í™” ë‹¤ìˆ˜ â†’ truncation ì‹œ ì •ë³´ ì†ì‹¤ ìœ„í—˜

Summary ê¸¸ì´

í‰ê· : 100â€“110ì

ê±°ì˜ ëª¨ë‘ 1ë¬¸ì¥ ìš”ì•½, ë¬¸ì²´ë„ ì¼ì • (â€œ~ë‹¤.â€, â€œ~í–ˆë‹¤.â€)

Topic

topic ë¬¸ìì—´ì´ summaryì— ì§ì ‘ ë“±ì¥í•˜ëŠ” ë¹„ìœ¨ì€ ë‚®ìŒ(10â€“20%)

ë‹¤ë§Œ ì˜ë¯¸ì ìœ¼ë¡œëŠ” summaryì™€ ë†’ì€ ê´€ë ¨ â†’ â€œë°©í–¥ì„±â€ ì •ë„ì˜ ì—­í• 

Noise

ã…‹ã…‹ã…‹, ã…ã…, ã… ã… , ì•„â€¦, ìŒâ€¦ ë“± ê°ì •/ì¡ë‹´ì„± í† í° ë‹¤ìˆ˜

summaryì—ëŠ” ê±°ì˜ ë°˜ì˜ë˜ì§€ ì•ŠìŒ â†’ ê³µê²©ì ì¸ ì…ë ¥ ì „ì²˜ë¦¬ í›„ë³´

2ï¸âƒ£ ì „ì²˜ë¦¬ ë²„ì „ ì‹¤í—˜
ë²„ì „	ë‚´ìš©	ê²°ê³¼
v1	baseline ì „ì²˜ë¦¬	ê¸°ì¤€ ì ìˆ˜
v2_full	ì…ë ¥ + ì¶œë ¥ ëª¨ë‘ ì „ì²˜ë¦¬	ì¶œë ¥ê¹Œì§€ ê±´ë“œë¦¬ë©´ label bias ë°œìƒ, íš¨ê³¼ ì—†ìŒ
v2_input_only	ì…ë ¥ë§Œ ê³µê²©ì ìœ¼ë¡œ ì •ì œ	LB +0.5pt ìˆ˜ì¤€ í–¥ìƒ (ì±„íƒ)
v3â€“v6	truncation, topic prefix, ê¸¸ì´/overlap filtering ë“±	ë°ì´í„° ë¶„í¬ ì™œê³¡Â·ì •ë³´ ì†ì‹¤ë¡œ ëŒ€ë¶€ë¶„ ì„±ëŠ¥ ì €í•˜

ğŸ“Œ ê²°ë¡ 
â†’ ì…ë ¥(dialogue)ì€ ê°•í•˜ê²Œ ì •ì œ, ì¶œë ¥(summary)ì€ ìµœëŒ€í•œ ê±´ë“œë¦¬ì§€ ì•ŠëŠ” ì „ëµì´ ìµœì„ 
â†’ ì´ í”„ë¡œì íŠ¸ì˜ ìµœì¢… ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì€ Preprocess_v2_input_only ì…ë‹ˆë‹¤.

ğŸ¤– ëª¨ë¸ë§ (KoBART Fine-tuning)
âš™ ì‚¬ìš© ëª¨ë¸

digit82/kobart-summarization

êµ¬ì¡°: Encoderâ€“Decoder (BART ê³„ì—´)

í† í¬ë‚˜ì´ì €:

encoder_max_len = 512

decoder_max_len = 100

íŠ¹ìˆ˜ í† í° ë“±ë¡: #Person1#, #PhoneNumber#, #Address# ë“±

ğŸ§© í•™ìŠµ ì„¤ì • (ìµœì¢… Best ì„¤ì •)
í•­ëª©	ê°’
Epochs	20
Learning rate	1e-5
Train batch size	50
Eval batch size	32
Weight decay	0.01
Label smoothing	0.1
Warmup ratio	0.1
Scheduler	cosine
Optimizer	AdamW (adamw_torch)
Early stopping	patience = 3 (metric: eval_rouge_l)
Seed	42
ğŸ’¡ í•µì‹¬ íŠœë‹ í¬ì¸íŠ¸

Label smoothing = 0.1

ìš”ì•½ì€ â€œì •ë‹µì´ ì—¬ëŸ¬ í‘œí˜„ìœ¼ë¡œ ì¡´ì¬â€í•˜ëŠ” íƒœìŠ¤í¬ â†’ overconfidence ë°©ì§€ì— íš¨ê³¼ì 

dev & LB ëª¨ë‘ì—ì„œ ê°€ì¥ ì•ˆì •ì ì¸ í–¥ìƒ

Weight decay = 0.01

KoBART íŒŒë¼ë¯¸í„°ì˜ ê³¼ì í•©ì„ ì–µì œí•´ ì¼ë°˜í™” ì„±ëŠ¥ ê°œì„ 

ì…ë ¥ ì „ì²˜ë¦¬ v2_input_only

ë…¸ì´ì¦ˆ ì œê±° + topic ëˆ„ì¶œ ë°©ì§€ â†’ encoder representation í’ˆì§ˆ í–¥ìƒ

ğŸ“Š ì„±ëŠ¥ ê²°ê³¼
âœ… ì£¼ìš” ì‹¤í—˜ ë¹„êµ
ì‹¤í—˜ëª…	ì „ì²˜ë¦¬	ì£¼ìš” ì„¤ì •	Dev ROUGE-L	LB ìµœì¢… ì ìˆ˜
baseline_v1	baseline	ê¸°ë³¸ ì„¤ì •	~0.27ëŒ€	47.06
v2_input_only	ì…ë ¥ë§Œ ì •ì œ	ê¸°ë³¸ ì„¤ì •	0.282	47.6004
v2_input_only + WD 0.01 + LS 0.1	ì…ë ¥ë§Œ ì •ì œ	LS=0.1, WD=0.01	0.2978	47.8581 (ìµœì¢…)

ğŸ“Œ ì •ë¦¬
â†’ ì„±ëŠ¥ í–¥ìƒì— ê°€ì¥ í¬ê²Œ ê¸°ì—¬í•œ ìš”ì†ŒëŠ”

ì…ë ¥ ì „ì²˜ë¦¬(v2_input_only)

Label smoothing 0.1

Weight decay 0.01 ì´ì—ˆìŠµë‹ˆë‹¤.

ğŸ§­ ì „ì²´ íŒŒì´í”„ë¼ì¸
Raw CSV (train/dev/test)
        â†“
        â†“  [01_eda/eda_v2_input_only.ipynb]
    EDA ë¶„ì„
        â†“
        â†“  [02_preprocessing/preprocessing_v2_input_only.ipynb]
Preprocess_v2_input_only
  (noise ì œê±° + ëˆ„ì¶œ ë°©ì§€)
        â†“
        â†“  [03_modeling/modeling_kobart.ipynb]
KoBART Fine-tuning
  (LS 0.1, WD 0.01, 20 epochs)
        â†“
Best checkpoint ì„ íƒ (eval_rouge_l ê¸°ì¤€)
        â†“
Beam Search (num_beams=4, max_len=100)
        â†“
outputs/prediction/output_preprocessed_v2_input_only_wd0.01_ls0.1.csv

ğŸ›  ì‚¬ìš© ë°©ë²• (How to Run)

âš ï¸ ëŒ€íšŒ ë°ì´í„°ëŠ” ê³µê°œ ì €ì¥ì†Œì— í¬í•¨ë˜ì–´ ìˆì§€ ì•Šìœ¼ë¯€ë¡œ,
ë°˜ë“œì‹œ ê°œë³„ì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ í›„ data/raw/ ë””ë ‰í† ë¦¬ì— ìœ„ì¹˜ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.

1ï¸âƒ£ ë°ì´í„° ì¤€ë¹„
data/raw/train.csv
data/raw/dev.csv
data/raw/test.csv
data/raw/sample_submission.csv

2ï¸âƒ£ EDA & ì „ì²˜ë¦¬

EDA:
ğŸ‘‰ notebooks/01_eda/eda_v2_input_only.ipynb

ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:
ğŸ‘‰ notebooks/02_preprocessing/preprocessing_v2_input_only.ipynb

3ï¸âƒ£ í•™ìŠµ & í‰ê°€

KoBART í•™ìŠµ/ê²€ì¦:
ğŸ‘‰ notebooks/03_modeling/modeling_kobart.ipynb

ë…¸íŠ¸ë¶ì—ì„œ config.yamlì„ ê¸°ë°˜ìœ¼ë¡œ ê²½ë¡œ/í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë¡œë“œí•˜ì—¬ í•™ìŠµì„ ì¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

4ï¸âƒ£ ì¶”ë¡  & ì œì¶œ íŒŒì¼ ìƒì„±

ìµœì¢… ì œì¶œ íŒŒì¼:

outputs/prediction/output_preprocessed_v2_input_only_wd0.01_ls0.1.csv

Baselineê³¼ ë¹„êµìš©:

outputs/prediction/output_preprocessed_v2_input_only.csv

ğŸ§  íšŒê³  & í–¥í›„ ê°œì„  ì•„ì´ë””ì–´
âœ¨ ì´ë²ˆ ì‹¤í—˜ì—ì„œ ë°°ìš´ ì 

ì…ë ¥ ì „ì²˜ë¦¬ì˜ í˜

ê°ì •/ì¡ë‹´ì„± í† í° ì œê±°ë§Œìœ¼ë¡œë„ ëª¨ë¸ì´ â€œí•µì‹¬ ë°œí™”â€ì— ë” ì§‘ì¤‘í•˜ê²Œ ë¨.

Label smoothingì€ ìš”ì•½ íƒœìŠ¤í¬ì— íŠ¹íˆ ì˜ ë§ëŠ”ë‹¤

ì •ë‹µ ë¬¸ì¥ì´ í•˜ë‚˜ë¡œ ê³ ì •ë˜ì§€ ì•ŠëŠ” íƒœìŠ¤í¬ì¼ìˆ˜ë¡,
overconfidenceë¥¼ ë‚®ì¶°ì£¼ëŠ” regularizationì´ íš¨ê³¼ì .

Decoding íŠœë‹ë³´ë‹¤ ëª¨ë¸/ì „ì²˜ë¦¬ ì„¤ê³„ê°€ ìš°ì„ ìˆœìœ„

length penalty, repetition penalty ë“±ì„ í¬ê²Œ ë°”ê¿”ë„
ëª¨ë¸ í‘œí˜„ë ¥ì´ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ì„±ëŠ¥ ìƒí•œì„ ë„˜ê¸° ì–´ë ¤ì›€.

ğŸ”® í–¥í›„ ê°œì„  ì•„ì´ë””ì–´

QLoRA / PEFT ê¸°ë°˜ íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  íŠœë‹ ì‹œë„

Topic ì •ë³´ë¥¼ ë” ì •êµí•˜ê²Œ í™œìš©í•˜ëŠ” ì»¨ë””ì…”ë‹ ì „ëµ (prefix tuning ë“±)

â€œí•œ ë¬¸ì¥ ìš”ì•½â€ ì œì•½ì„ ëª…ì‹œì ìœ¼ë¡œ ë°˜ì˜í•˜ëŠ” decoding ê·œì¹™ ì„¤ê³„

Hard case (ì‹¤ìˆ˜ ë§ì€ ìƒ˜í”Œ) ì¤‘ì‹¬ ì—ëŸ¬ ë¶„ì„ + ê·œì¹™ ê¸°ë°˜ í›„ì²˜ë¦¬ ê°•í™”

ğŸ™‹â€â™€ï¸ íŒ€ & ë¸Œëœì¹˜ ì „ëµ

ì´ ë¦¬í¬ì§€í† ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë¸Œëœì¹˜ ì „ëµìœ¼ë¡œ ê´€ë¦¬ë©ë‹ˆë‹¤.

main : ìµœì¢… ì •ë¦¬ëœ ì½”ë“œ & ê²°ê³¼ë§Œ ë°˜ì˜í•˜ëŠ” ì•ˆì • ë¸Œëœì¹˜

dev : ì‹¤í—˜ ì¬í˜„ì„ ìœ„í•œ í•µì‹¬ íŒŒì¼ (EDA/ì „ì²˜ë¦¬/ëª¨ë¸ë§ ë…¸íŠ¸ë¶, config ë“±)

yekyung-dev : ê°œì¸ ì‹¤í—˜, ë¡œê·¸, ì‹¤í—˜ìš© ì½”ë“œ(ì´ˆì•ˆ) ì €ì¥ìš© ë¸Œëœì¹˜

í˜‘ì—… ê³¼ì •ì—ì„œ ë‚˜ì˜¨ ëª¨ë“  ì‹¤í—˜ì€ yekyung-dev â†’ dev â†’ main ìˆœìœ¼ë¡œ ì •ë¦¬Â·ì••ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤.

ğŸ“« Contact

í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì˜ ë˜ëŠ” í”¼ë“œë°±ì€
ğŸ‘‰ GitHub Issue ë˜ëŠ” Pull Requestë¡œ ë‚¨ê²¨ ì£¼ì„¸ìš”.
