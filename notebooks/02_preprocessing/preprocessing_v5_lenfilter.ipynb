{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ë²„ì „ê´€ë¦¬\n",
    "# v1 : ì „ì²˜ë¦¬ v1\n",
    "# v2_full : ì „ì²˜ë¦¬ v2\n",
    "# v2_input_only : ì „ì²˜ë¦¬ v2 | dialogueëŠ” ê³µê²©ì , summaryëŠ” ë°©ì–´ì ìœ¼ë¡œ ì „ì²˜ë¦¬\n",
    "    # ì œì¼ ë†’ì€ LB ì ìˆ˜ ê¸°ë¡\n",
    "    # ì…ë ¥ ì „ì²˜ë¦¬ëŠ” representation learningì— ê¸ì •ì  ì˜í–¥\n",
    "    # ì¶œë ¥ ì „ì²˜ë¦¬ëŠ” label noiseê°€ ì•„ë‹ˆë¼ label biasë¥¼ ë§Œë“¤ê¸° ë•Œë¬¸ì— ì˜¤íˆë ¤ í•´ë¡œì›€\n",
    "# v3 : Trunication(ëŒ€í™” ê¸¸ì´ ìµœì í™”)\n",
    "    # v2_input_onlyë³´ë‹¤ ë–¨ì–´ì§. ì„œë¸Œìš©ìœ¼ë¡œë§Œ ë‘ê¸°.\n",
    "# v4 : Topic prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU ë©”ëª¨ë¦¬ ì”ëŸ‰ í™•ì¸í•˜ê¸°\n",
      "Thu Dec  4 08:05:54 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  | 00000000:4C:00.0 Off |                  N/A |\n",
      "| 39%   34C    P8              18W / 350W |   1810MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "print(\"âœ… GPU ë©”ëª¨ë¦¬ ì”ëŸ‰ í™•ì¸í•˜ê¸°\")\n",
    "!nvidia-smi\n",
    "\n",
    "# ps -ef | grep -i python\n",
    "# kill 450164 452546 454581 458861 458879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "protect_error = input(\"ğŸŒŸ GPU ë©”ëª¨ë¦¬ & ë²„ì „ í™•ì¸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbZ7SU9P2TYN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /data/ephemeral/home/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "from pathlib import Path\n",
    "from transformers import BartForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from datetime import datetime\n",
    "\n",
    "import wandb\n",
    "wandb.login(key=\"\")                     # API KEY ì…ë ¥\n",
    "\n",
    "# # wandb êº¼ë‘ê¸°\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qq46k6_CNQn"
   },
   "source": [
    "### Config ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "referenced_widgets": [
      "e920dbc173c045d1a32143349f1dff8e",
      "58c794fb7ce543a39fdf66d757f6eeab",
      "8a6464a355f7464c989033965d418a8a",
      "3645438ace1f4596a8dbc157b48c1521",
      "58001a60eacc44d5b38a68648adccde4",
      "6f5fde5b0ac840a18bd5cc380e564ff6",
      "45187decb58b4ad39ad532259c6277e5",
      "2307c6dcbe0141acb5e61baae19cade7",
      "4747b668e2fa4ab58a449446f80030f5",
      "14f6c91d6c634379b498586c51e606e0",
      "08d05bc20a96432badd459e1ffaf868e",
      "5dfcf310ca9e4e2794076098a5d69cea",
      "3c284a826f6843f6aa47eacad478ac30",
      "6caedd60c6b747469c82930be1f95d6d",
      "64f2218f899d446393cfea44f206f0a6",
      "d068f541df3f438dbd5138863e64b2f2",
      "affff1d8a89e4c14955d1b2aa39ff1ab",
      "13651c09564a4337b8274c1cb436faa5",
      "3bcd6b6b956347b29e1efa20a1d00542",
      "2fd3d7bbcd6948d8904d33001f95ea03",
      "d22fbc2c5dbf422399e496c9b500025a",
      "775d8bbeceac4e2da4f21ab6235c89ed",
      "de1a3f7701c243839fe03b930a9b9e30",
      "ebc22683058a4f229c5588e52fc93536",
      "52095cc7087243ac916055e569fd22f3",
      "a15af9e8158f4903b9189f3d322a5ef3",
      "21d2e54b5a0a4f79973a512105da43eb",
      "083ea69907bb48d4a8fff919bac51aad",
      "2a190bda0b72407e9a953cd2104dd3b2",
      "c18f0e3bc35e44d9915c3f84cd282a26",
      "3a04e871b74b45d7bf02fd33bb103577",
      "ac00d6c2cf974b33a628acb3f1471316",
      "285007b45236478ca147c6df752c8da4"
     ]
    },
    "id": "gZOE9TInCQHJ",
    "outputId": "8ce58487-6199-408c-cb37-49af1e218bc2"
   },
   "outputs": [],
   "source": [
    "# config ì„¤ì •ì— tokenizer ëª¨ë“ˆì´ ì‚¬ìš©ë˜ë¯€ë¡œ ë¯¸ë¦¬ tokenizerë¥¼ ì •ì˜í•´ì¤ë‹ˆë‹¤.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "5vsACJI7CVb8"
   },
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"../data/\",\n",
    "        \"data_raw_path\": \"../data/raw/\",\n",
    "        \"version\": \"v5\",                                                        # ë²„ì „ê´€ë¦¬\n",
    "        \"model_name\": \"digit82/kobart-summarization\",\n",
    "        \"output_dir\": \"../outputs/checkpoints/\"                                 \n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 512,\n",
    "        \"decoder_max_len\": 100,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#',\n",
    "                           '#PhoneNumber#', '#Address#', '#PassportNumber#']    # íŠ¹ì • ë‹¨ì–´ë“¤ì´ ë¶„í•´ë˜ì§€ ì•Šë„ë¡ í•˜ê¸° ìœ„í•¨\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 20,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"per_device_train_batch_size\": 50,\n",
    "        \"per_device_eval_batch_size\": 32,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine',\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 5,\n",
    "        \"fp16\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 100,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "        # \"report_to\": \"none\"  \n",
    "        \"report_to\": \"wandb\"                                                        # wandb ì‚¬ìš© ì˜µì…˜\n",
    "    },\n",
    "    \"wandb\": {\n",
    "        # \"entity\": \"bubblekid43\",                                                   \n",
    "        \"project\": \"NLP-private\",                                                   \n",
    "        \"name\": \"preprocessed_v5_lenfilter\"                                                       # ë²„ì „ê´€ë¦¬\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"../outputs/checkpoints/\",                                      \n",
    "        \"result_path\": \"../outputs/prediction/\",\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 100,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\" : 32,\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\",\n",
    "                          f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]       # ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì •ì˜\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "REJybO5UCabF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ config ì €ì¥ ì™„ë£Œ : ../configs/config_preprocessed_v5_lenfilter.yaml\n",
      "\n",
      "ğŸ” config êµ¬ì„± ì •ë³´ í™•ì¸\n",
      "{'general': {'data_path': '../data/', 'data_raw_path': '../data/raw/', 'model_name': 'digit82/kobart-summarization', 'output_dir': '../outputs/checkpoints/', 'version': 'v5'}, 'inference': {'batch_size': 32, 'ckt_path': '../outputs/checkpoints/', 'early_stopping': True, 'generate_max_length': 100, 'no_repeat_ngram_size': 2, 'num_beams': 4, 'remove_tokens': ['<usr>', '<s>', '</s>', '<pad>'], 'result_path': '../outputs/prediction/'}, 'tokenizer': {'bos_token': '<s>', 'decoder_max_len': 100, 'encoder_max_len': 512, 'eos_token': '</s>', 'special_tokens': ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#']}, 'training': {'do_eval': True, 'do_train': True, 'early_stopping_patience': 3, 'early_stopping_threshold': 0.001, 'evaluation_strategy': 'epoch', 'fp16': True, 'generation_max_length': 100, 'gradient_accumulation_steps': 1, 'learning_rate': 1e-05, 'load_best_model_at_end': True, 'logging_dir': './logs', 'logging_strategy': 'epoch', 'lr_scheduler_type': 'cosine', 'num_train_epochs': 20, 'optim': 'adamw_torch', 'overwrite_output_dir': True, 'per_device_eval_batch_size': 32, 'per_device_train_batch_size': 50, 'predict_with_generate': True, 'report_to': 'wandb', 'save_strategy': 'epoch', 'save_total_limit': 5, 'seed': 42, 'warmup_ratio': 0.1, 'weight_decay': 0.01}, 'wandb': {'name': 'preprocessed_v5_lenfilter', 'project': 'NLP-private'}}\n"
     ]
    }
   ],
   "source": [
    "# ë²„ì „ê´€ë¦¬\n",
    "exp_name = config_data[\"wandb\"][\"name\"]\n",
    "version_name = config_data[\"general\"][\"version\"]\n",
    "\n",
    "# ëª¨ë¸ì˜ êµ¬ì„± ì •ë³´ë¥¼ YAML íŒŒì¼ë¡œ ì €ì¥\n",
    "config_path = f\"../configs/config_{exp_name}.yaml\"\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)\n",
    "print(f\"ğŸ’¾ config ì €ì¥ ì™„ë£Œ : {config_path}\")\n",
    "\n",
    "# ì €ì¥ëœ config íŒŒì¼ ë¶ˆëŸ¬ì™€ì„œ ë‚´ìš© í™•ì¸\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "print(\"\\nğŸ” config êµ¬ì„± ì •ë³´ í™•ì¸\")\n",
    "print(loaded_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2zt0b-8ogCL"
   },
   "source": [
    "### ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "QFHIE2G04y-K",
    "outputId": "19312d21-f5bf-495f-c626-cc17b82024a4"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„° ê²½ë¡œ ì •ì˜\n",
    "data_path = Path(loaded_config['general']['data_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train_df.head()\n",
      "     fname                                           dialogue  \\\n",
      "0  train_0  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mr. Smith. ì €ëŠ” Dr. Hawkinsì…ë‹ˆë‹¤...   \n",
      "1  train_1  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mrs. Parker. ì˜ ì§€ë‚´ì…¨ë‚˜ìš”?\\n#Pers...   \n",
      "2  train_2  #Person1#: ì €ê¸°ìš”, ì—´ì‡  ì„¸íŠ¸ ë³¸ ì  ìˆì–´ìš”?\\n#Person2#: ì–´ë–¤ ...   \n",
      "3  train_3  #Person1#: ë„ˆ ì—¬ìì¹œêµ¬ ìˆëŠ” ê±° ì™œ ë§ ì•ˆ í–ˆì–´?\\n#Person2#: ë¯¸...   \n",
      "4  train_4  #Person1#: ì•ˆë…•, ì˜¤ëŠ˜ ë„ˆë¬´ ë©‹ì ¸ ë³´ì´ë„¤ìš”. ì €ë‘ ì¶¤ í•œ ê³¡ ì¶”ì‹¤ë˜ìš”?\\n...   \n",
      "\n",
      "                                             summary      topic  \n",
      "0  Mr. SmithëŠ” Dr. Hawkinsì—ê²Œ ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ëŸ¬ ì™€ì„œ, ë§¤ë…„ ê²€ì§„ í•„...       ê±´ê°•ê²€ì§„  \n",
      "1  Mrs. Parkerê°€ Rickyì™€ í•¨ê»˜ ë°±ì‹  ì ‘ì¢…ì„ ìœ„í•´ ë°©ë¬¸í•˜ì˜€ê³ , Dr. Pe...      ë°±ì‹  ì ‘ì¢…  \n",
      "2  #Person1#ì€ ì—´ì‡  ì„¸íŠ¸ë¥¼ ìƒì–´ë²„ë¦¬ê³  #Person2#ì—ê²Œ ì°¾ëŠ” ê²ƒì„ ë„ì™€ë‹¬ë¼...      ì—´ì‡  ë¶„ì‹¤  \n",
      "3  #Person1#ì€ #Person2#ê°€ ì—¬ìì¹œêµ¬ê°€ ìˆê³  ê²°í˜¼í•  ì˜ˆì •ì´ë¼ëŠ” ì‚¬ì‹¤ì„ ë§...  ì—¬ìì¹œêµ¬ì™€ì˜ ê²°í˜¼  \n",
      "4  Malikì€ Wenê³¼ Nikkiì—ê²Œ ì¶¤ì„ ì œì•ˆí•˜ê³ , Wenì€ ë°œì„ ë°ŸëŠ” ê²ƒì„ ê°ìˆ˜í•˜...       ì¶¤ ì œì•ˆ  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>#Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mr. Smith. ì €ëŠ” Dr. Hawkinsì…ë‹ˆë‹¤...</td>\n",
       "      <td>Mr. SmithëŠ” Dr. Hawkinsì—ê²Œ ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ëŸ¬ ì™€ì„œ, ë§¤ë…„ ê²€ì§„ í•„...</td>\n",
       "      <td>ê±´ê°•ê²€ì§„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>#Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mrs. Parker. ì˜ ì§€ë‚´ì…¨ë‚˜ìš”?\\n#Pers...</td>\n",
       "      <td>Mrs. Parkerê°€ Rickyì™€ í•¨ê»˜ ë°±ì‹  ì ‘ì¢…ì„ ìœ„í•´ ë°©ë¬¸í•˜ì˜€ê³ , Dr. Pe...</td>\n",
       "      <td>ë°±ì‹  ì ‘ì¢…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>#Person1#: ì €ê¸°ìš”, ì—´ì‡  ì„¸íŠ¸ ë³¸ ì  ìˆì–´ìš”?\\n#Person2#: ì–´ë–¤ ...</td>\n",
       "      <td>#Person1#ì€ ì—´ì‡  ì„¸íŠ¸ë¥¼ ìƒì–´ë²„ë¦¬ê³  #Person2#ì—ê²Œ ì°¾ëŠ” ê²ƒì„ ë„ì™€ë‹¬ë¼...</td>\n",
       "      <td>ì—´ì‡  ë¶„ì‹¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>#Person1#: ë„ˆ ì—¬ìì¹œêµ¬ ìˆëŠ” ê±° ì™œ ë§ ì•ˆ í–ˆì–´?\\n#Person2#: ë¯¸...</td>\n",
       "      <td>#Person1#ì€ #Person2#ê°€ ì—¬ìì¹œêµ¬ê°€ ìˆê³  ê²°í˜¼í•  ì˜ˆì •ì´ë¼ëŠ” ì‚¬ì‹¤ì„ ë§...</td>\n",
       "      <td>ì—¬ìì¹œêµ¬ì™€ì˜ ê²°í˜¼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>#Person1#: ì•ˆë…•, ì˜¤ëŠ˜ ë„ˆë¬´ ë©‹ì ¸ ë³´ì´ë„¤ìš”. ì €ë‘ ì¶¤ í•œ ê³¡ ì¶”ì‹¤ë˜ìš”?\\n...</td>\n",
       "      <td>Malikì€ Wenê³¼ Nikkiì—ê²Œ ì¶¤ì„ ì œì•ˆí•˜ê³ , Wenì€ ë°œì„ ë°ŸëŠ” ê²ƒì„ ê°ìˆ˜í•˜...</td>\n",
       "      <td>ì¶¤ ì œì•ˆ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fname                                           dialogue  \\\n",
       "0  train_0  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mr. Smith. ì €ëŠ” Dr. Hawkinsì…ë‹ˆë‹¤...   \n",
       "1  train_1  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mrs. Parker. ì˜ ì§€ë‚´ì…¨ë‚˜ìš”?\\n#Pers...   \n",
       "2  train_2  #Person1#: ì €ê¸°ìš”, ì—´ì‡  ì„¸íŠ¸ ë³¸ ì  ìˆì–´ìš”?\\n#Person2#: ì–´ë–¤ ...   \n",
       "3  train_3  #Person1#: ë„ˆ ì—¬ìì¹œêµ¬ ìˆëŠ” ê±° ì™œ ë§ ì•ˆ í–ˆì–´?\\n#Person2#: ë¯¸...   \n",
       "4  train_4  #Person1#: ì•ˆë…•, ì˜¤ëŠ˜ ë„ˆë¬´ ë©‹ì ¸ ë³´ì´ë„¤ìš”. ì €ë‘ ì¶¤ í•œ ê³¡ ì¶”ì‹¤ë˜ìš”?\\n...   \n",
       "\n",
       "                                             summary      topic  \n",
       "0  Mr. SmithëŠ” Dr. Hawkinsì—ê²Œ ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ëŸ¬ ì™€ì„œ, ë§¤ë…„ ê²€ì§„ í•„...       ê±´ê°•ê²€ì§„  \n",
       "1  Mrs. Parkerê°€ Rickyì™€ í•¨ê»˜ ë°±ì‹  ì ‘ì¢…ì„ ìœ„í•´ ë°©ë¬¸í•˜ì˜€ê³ , Dr. Pe...      ë°±ì‹  ì ‘ì¢…  \n",
       "2  #Person1#ì€ ì—´ì‡  ì„¸íŠ¸ë¥¼ ìƒì–´ë²„ë¦¬ê³  #Person2#ì—ê²Œ ì°¾ëŠ” ê²ƒì„ ë„ì™€ë‹¬ë¼...      ì—´ì‡  ë¶„ì‹¤  \n",
       "3  #Person1#ì€ #Person2#ê°€ ì—¬ìì¹œêµ¬ê°€ ìˆê³  ê²°í˜¼í•  ì˜ˆì •ì´ë¼ëŠ” ì‚¬ì‹¤ì„ ë§...  ì—¬ìì¹œêµ¬ì™€ì˜ ê²°í˜¼  \n",
       "4  Malikì€ Wenê³¼ Nikkiì—ê²Œ ì¶¤ì„ ì œì•ˆí•˜ê³ , Wenì€ ë°œì„ ë°ŸëŠ” ê²ƒì„ ê°ìˆ˜í•˜...       ì¶¤ ì œì•ˆ  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train data\n",
    "train_df = pd.read_csv(data_path / 'raw' / 'train.csv')\n",
    "print('âœ… train_df.head()')\n",
    "print(train_df.head())\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "FAGaYvNZ09Sq",
    "outputId": "bf8bf286-19e7-469d-ffae-41e6ad795ae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… val_df.head()\n",
      "   fname                                           dialogue  \\\n",
      "0  dev_0  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸ìš”?\\n#Person2#: ìš”ì¦˜ ...   \n",
      "1  dev_1  #Person1#: ì•¼ Jimmy, ì˜¤ëŠ˜ ì¢€ ì´ë”° ìš´ë™í•˜ëŸ¬ ê°€ì.\\n#Person2...   \n",
      "2  dev_2  #Person1#: ë‚˜ ì§„ì§œ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ ì¢€ ê·¸ë§Œ ë¨¹ì–´ì•¼ê² ì–´. \\n#Per...   \n",
      "3  dev_3  #Person1#: ë„ˆ UFO ë¯¿ì–´?\\n#Person2#: ë‹¹ì—°í•˜ì§€, ìˆëŠ” ê±° ì•„ëƒ...   \n",
      "4  dev_4  #Person1#: ì˜¤ëŠ˜ í•™êµ ê°”ì–´?\\n#Person2#: ë‹¹ì—°íˆ ê°”ì§€. ë„ˆëŠ”?\\n...   \n",
      "\n",
      "                                             summary      topic  \n",
      "0  #Person2#ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2#ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜...      ì˜ì‚¬ ìƒë‹´  \n",
      "1   #Person1#ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.      ìš´ë™ ê³„íš  \n",
      "2  #Person1#ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2#...     ê±´ê°•í•œ ì‹ë‹¨  \n",
      "3  #Person2#ëŠ” UFOë¥¼ ë¯¿ê³  ê¿ˆì—ì„œ ë³¼ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤. #Person1#ì€ ...   UFOì™€ ì™¸ê³„ì¸  \n",
      "4  #Person1#ì€ ì˜¤ëŠ˜ í•™êµì— ê°€ì§€ ì•Šì•˜ê³ , #Person2#ëŠ” ë‚´ì¼ í•™êµ ëŒ€ì‹  ...  í•™êµì™€ ì£¼ë§ ê³„íš  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_0</td>\n",
       "      <td>#Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸ìš”?\\n#Person2#: ìš”ì¦˜ ...</td>\n",
       "      <td>#Person2#ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2#ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜...</td>\n",
       "      <td>ì˜ì‚¬ ìƒë‹´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_1</td>\n",
       "      <td>#Person1#: ì•¼ Jimmy, ì˜¤ëŠ˜ ì¢€ ì´ë”° ìš´ë™í•˜ëŸ¬ ê°€ì.\\n#Person2...</td>\n",
       "      <td>#Person1#ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.</td>\n",
       "      <td>ìš´ë™ ê³„íš</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_2</td>\n",
       "      <td>#Person1#: ë‚˜ ì§„ì§œ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ ì¢€ ê·¸ë§Œ ë¨¹ì–´ì•¼ê² ì–´. \\n#Per...</td>\n",
       "      <td>#Person1#ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2#...</td>\n",
       "      <td>ê±´ê°•í•œ ì‹ë‹¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_3</td>\n",
       "      <td>#Person1#: ë„ˆ UFO ë¯¿ì–´?\\n#Person2#: ë‹¹ì—°í•˜ì§€, ìˆëŠ” ê±° ì•„ëƒ...</td>\n",
       "      <td>#Person2#ëŠ” UFOë¥¼ ë¯¿ê³  ê¿ˆì—ì„œ ë³¼ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤. #Person1#ì€ ...</td>\n",
       "      <td>UFOì™€ ì™¸ê³„ì¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev_4</td>\n",
       "      <td>#Person1#: ì˜¤ëŠ˜ í•™êµ ê°”ì–´?\\n#Person2#: ë‹¹ì—°íˆ ê°”ì§€. ë„ˆëŠ”?\\n...</td>\n",
       "      <td>#Person1#ì€ ì˜¤ëŠ˜ í•™êµì— ê°€ì§€ ì•Šì•˜ê³ , #Person2#ëŠ” ë‚´ì¼ í•™êµ ëŒ€ì‹  ...</td>\n",
       "      <td>í•™êµì™€ ì£¼ë§ ê³„íš</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fname                                           dialogue  \\\n",
       "0  dev_0  #Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸ìš”?\\n#Person2#: ìš”ì¦˜ ...   \n",
       "1  dev_1  #Person1#: ì•¼ Jimmy, ì˜¤ëŠ˜ ì¢€ ì´ë”° ìš´ë™í•˜ëŸ¬ ê°€ì.\\n#Person2...   \n",
       "2  dev_2  #Person1#: ë‚˜ ì§„ì§œ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ ì¢€ ê·¸ë§Œ ë¨¹ì–´ì•¼ê² ì–´. \\n#Per...   \n",
       "3  dev_3  #Person1#: ë„ˆ UFO ë¯¿ì–´?\\n#Person2#: ë‹¹ì—°í•˜ì§€, ìˆëŠ” ê±° ì•„ëƒ...   \n",
       "4  dev_4  #Person1#: ì˜¤ëŠ˜ í•™êµ ê°”ì–´?\\n#Person2#: ë‹¹ì—°íˆ ê°”ì§€. ë„ˆëŠ”?\\n...   \n",
       "\n",
       "                                             summary      topic  \n",
       "0  #Person2#ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2#ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜...      ì˜ì‚¬ ìƒë‹´  \n",
       "1   #Person1#ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.      ìš´ë™ ê³„íš  \n",
       "2  #Person1#ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2#...     ê±´ê°•í•œ ì‹ë‹¨  \n",
       "3  #Person2#ëŠ” UFOë¥¼ ë¯¿ê³  ê¿ˆì—ì„œ ë³¼ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤. #Person1#ì€ ...   UFOì™€ ì™¸ê³„ì¸  \n",
       "4  #Person1#ì€ ì˜¤ëŠ˜ í•™êµì— ê°€ì§€ ì•Šì•˜ê³ , #Person2#ëŠ” ë‚´ì¼ í•™êµ ëŒ€ì‹  ...  í•™êµì™€ ì£¼ë§ ê³„íš  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# validation data\n",
    "val_df = pd.read_csv(data_path / 'raw' / 'dev.csv')\n",
    "print('âœ… val_df.head()')\n",
    "print(val_df.head())\n",
    "display(val_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… test_df: (499, 2)\n",
      "    fname                                           dialogue\n",
      "0  test_0  #Person1#: Ms. Dawson, ë°›ì•„ì“°ê¸° ì¢€ ë¶€íƒë“œë ¤ì•¼ê² ì–´ìš”. \\n#Per...\n",
      "1  test_1  #Person1#: ë“œë””ì–´ ì™”ë„¤! ë­ê°€ ì´ë ‡ê²Œ ì˜¤ë˜ ê±¸ë ¸ì–´?\\n#Person2#: ...\n",
      "2  test_2  #Person1#: Kate, ì—¬ê¸°ì„œ ì¼ì–´ë‚œ ì¼ì„ ë¯¿ê¸° í˜ë“¤ ê±°ì•¼.\\n#Person...\n",
      "3  test_3  #Person1#: ìƒì¼ ì¶•í•˜í•´, ì´ê±° ë„ˆë¥¼ ìœ„í•œ ì„ ë¬¼ì´ì•¼, Brian.\\n#Per...\n",
      "4  test_4  #Person1#: ì´ ì˜¬ë¦¼í”½ ê³µì› ì •ë§ í¬ë‹¤! \\n#Person2#: ë§ì•„. ì§€ê¸ˆ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>#Person1#: Ms. Dawson, ë°›ì•„ì“°ê¸° ì¢€ ë¶€íƒë“œë ¤ì•¼ê² ì–´ìš”. \\n#Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person1#: ë“œë””ì–´ ì™”ë„¤! ë­ê°€ ì´ë ‡ê²Œ ì˜¤ë˜ ê±¸ë ¸ì–´?\\n#Person2#: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>#Person1#: Kate, ì—¬ê¸°ì„œ ì¼ì–´ë‚œ ì¼ì„ ë¯¿ê¸° í˜ë“¤ ê±°ì•¼.\\n#Person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>#Person1#: ìƒì¼ ì¶•í•˜í•´, ì´ê±° ë„ˆë¥¼ ìœ„í•œ ì„ ë¬¼ì´ì•¼, Brian.\\n#Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person1#: ì´ ì˜¬ë¦¼í”½ ê³µì› ì •ë§ í¬ë‹¤! \\n#Person2#: ë§ì•„. ì§€ê¸ˆ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fname                                           dialogue\n",
       "0  test_0  #Person1#: Ms. Dawson, ë°›ì•„ì“°ê¸° ì¢€ ë¶€íƒë“œë ¤ì•¼ê² ì–´ìš”. \\n#Per...\n",
       "1  test_1  #Person1#: ë“œë””ì–´ ì™”ë„¤! ë­ê°€ ì´ë ‡ê²Œ ì˜¤ë˜ ê±¸ë ¸ì–´?\\n#Person2#: ...\n",
       "2  test_2  #Person1#: Kate, ì—¬ê¸°ì„œ ì¼ì–´ë‚œ ì¼ì„ ë¯¿ê¸° í˜ë“¤ ê±°ì•¼.\\n#Person...\n",
       "3  test_3  #Person1#: ìƒì¼ ì¶•í•˜í•´, ì´ê±° ë„ˆë¥¼ ìœ„í•œ ì„ ë¬¼ì´ì•¼, Brian.\\n#Per...\n",
       "4  test_4  #Person1#: ì´ ì˜¬ë¦¼í”½ ê³µì› ì •ë§ í¬ë‹¤! \\n#Person2#: ë§ì•„. ì§€ê¸ˆ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test data\n",
    "test_df = pd.read_csv(data_path / 'raw' / 'test.csv')\n",
    "print('âœ… test_df:', test_df.shape)\n",
    "print(test_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IIaIrpH4kWo"
   },
   "source": [
    "### ë°ì´í„° ê°€ê³µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ì „ì²˜ë¦¬ ìœ í‹¸ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Preprocess_v1ìš© ìœ í‹¸ ===== #\n",
    "\n",
    "# 1) íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™” (..., !!, ??? ë“±)\n",
    "def normalize_special_chars(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # ... ë˜ëŠ” ....... â†’ ...\n",
    "    text = re.sub(r\"\\.{3,}\", \"...\", text)\n",
    "    # !!!, !!!! â†’ !\n",
    "    text = re.sub(r\"!{2,}\", \"!\", text)\n",
    "    # ???, ???? â†’ ?\n",
    "    text = re.sub(r\"\\?{2,}\", \"?\", text)\n",
    "    # ~~, ~~~ â†’ ~\n",
    "    text = re.sub(r\"~{2,}\", \"~\", text)\n",
    "    return text\n",
    "\n",
    "# 2) ê³µë°±/ê°œí–‰ ì •ê·œí™”\n",
    "def normalize_spaces_and_newlines(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # ê°œë³„ ì¤„ ì²˜ë¦¬: ì–‘ë ê³µë°± ì œê±° + ì¤‘ë³µ ê³µë°± ì œê±°\n",
    "    lines = text.split(\"\\n\")\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        line = re.sub(r\"\\s{2,}\", \" \", line)  # ì¤‘ë³µ ê³µë°± â†’ í•œ ì¹¸\n",
    "        if line:  # ì™„ì „ ë¹ˆ ì¤„ì€ ì œê±°\n",
    "            new_lines.append(line)\n",
    "    return \"\\n\".join(new_lines)\n",
    "\n",
    "# 3) Tier1 ë…¸ì´ì¦ˆ ì¶•ì•½ (ã…‹,ã…,ã… ,ã…œ, ì–´/ì•„/ìŒ ë°˜ë³µ ë“±)\n",
    "def compress_tier1_noise(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    # ã…‹ã…‹ã…‹ã…‹, ã…ã…ã…ã… â†’ ã…‹ã…‹ / ã…ã…\n",
    "    text = re.sub(r\"[ã…‹]{2,}\", \"ã…‹ã…‹\", text)\n",
    "    text = re.sub(r\"[ã…]{2,}\", \"ã…ã…\", text)\n",
    "\n",
    "    # ã… ã… ã… ã… , ã…œã…œã…œ â†’ ã… ã… \n",
    "    text = re.sub(r\"[ã… ã…œ]{2,}\", \"ã… ã… \", text)\n",
    "\n",
    "    # ì–´ì–´ì–´ì–´, ì•„ì•„ì•„ì•„, ìœ¼ìœ¼ìœ¼ â†’ ì–´ / ì•„ / ìŒ ìœ¼ë¡œ ì¶•ì•½\n",
    "    def _compress_filler_token(token: str) -> str:\n",
    "        # ì–´/ì•„/ìŒ/ìœ¼ + ë°˜ë³µ + ì•½ê°„ì˜ íŠ¹ìˆ˜ë¬¸ì\n",
    "        if re.fullmatch(r\"[ì•„ì–´ìœ¼ìŒ]+[\\.â€¦!?~]*\", token):\n",
    "            # 'ìŒ', 'ìœ¼' ê³„ì—´ì€ 'ìŒ'ìœ¼ë¡œ í†µì¼\n",
    "            if \"ìŒ\" in token or \"ìœ¼\" in token:\n",
    "                return \"ìŒ\"\n",
    "            # 'ì•„'ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ 'ì•„', ì•„ë‹ˆë©´ 'ì–´'\n",
    "            if \"ì•„\" in token:\n",
    "                return \"ì•„\"\n",
    "            return \"ì–´\"\n",
    "        return token\n",
    "\n",
    "    tokens = text.split(\" \")\n",
    "    tokens = [_compress_filler_token(tok) for tok in tokens]\n",
    "    text = \" \".join(tokens)\n",
    "\n",
    "    return text\n",
    "\n",
    "# 4) í™”ì íƒœê·¸ ì •ê·œí™” + 1/2ë¡œ ë§¤í•‘\n",
    "SPEAKER_TAG_PATTERN = re.compile(r\"^(#Person(\\d+)#):\")\n",
    "\n",
    "def normalize_speaker_tags(dialogue: str, summary: str | None = None):\n",
    "    \"\"\"\n",
    "    - dialogueë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ìŠ¤ìº”í•˜ë©´ì„œ\n",
    "    - ë“±ì¥í•˜ëŠ” í™”ì íƒœê·¸(#Person3#, #Person4# ë“±)ë¥¼\n",
    "      #Person1#, #Person2# ë‘ ê°œë¡œë§Œ ë§¤í•‘\n",
    "    - ê°™ì€ ìƒ˜í”Œ ë‚´ì—ì„œëŠ” dialogue/summary ëª¨ë‘ ì¼ê´€ëœ ë§¤í•‘ ì‚¬ìš©\n",
    "    \"\"\"\n",
    "    if not isinstance(dialogue, str):\n",
    "        return dialogue, summary\n",
    "\n",
    "    # 1) dialogueì—ì„œ í™”ì ë“±ì¥ ìˆœì„œì— ë”°ë¼ ë§¤í•‘ ìƒì„±\n",
    "    lines = dialogue.split(\"\\n\")\n",
    "    orig_to_norm = {}\n",
    "    next_slot = 1  # 1 â†’ #Person1#, 2 â†’ #Person2#\n",
    "\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        m = SPEAKER_TAG_PATTERN.match(line.strip())\n",
    "        if m:\n",
    "            full_tag = m.group(1)   # \"#PersonX#\"\n",
    "            spk_id = m.group(2)     # \"3\", \"4\", ...\n",
    "\n",
    "            if full_tag not in orig_to_norm:\n",
    "                if next_slot == 1:\n",
    "                    orig_to_norm[full_tag] = \"#Person1#\"\n",
    "                    next_slot = 2\n",
    "                elif next_slot == 2:\n",
    "                    orig_to_norm[full_tag] = \"#Person2#\"\n",
    "                    next_slot = 3\n",
    "                else:\n",
    "                    # ì„¸ ë²ˆì§¸ ì´í›„ í™”ìëŠ” ì „ë¶€ #Person2#ë¡œ í•©ì¹˜ê¸°\n",
    "                    orig_to_norm[full_tag] = \"#Person2#\"\n",
    "\n",
    "            norm_tag = orig_to_norm[full_tag]\n",
    "            # \"#PersonX#:\" â†’ \"#PersonY#:\"\n",
    "            line = re.sub(r\"^#Person\\d+#\", norm_tag, line.strip())\n",
    "        new_lines.append(line)\n",
    "\n",
    "    new_dialogue = \"\\n\".join(new_lines)\n",
    "\n",
    "    # 2) summaryì—ë„ ë™ì¼ ë§¤í•‘ ì ìš© (í˜¹ì‹œ ëª¨ë¥¼ #Person3# ë“±ì¥ ì¼€ì´ìŠ¤ ëŒ€ë¹„)\n",
    "    new_summary = summary\n",
    "    if isinstance(summary, str) and orig_to_norm:\n",
    "        for full_tag, norm_tag in orig_to_norm.items():\n",
    "            new_summary = new_summary.replace(full_tag, norm_tag)\n",
    "\n",
    "    return new_dialogue, new_summary\n",
    "\n",
    "# 5) leading filler ì œê±° (#PersonX#: ë„¤, / ì•„, / ì‘, / ìŒ ë“±)\n",
    "LEADING_FILLERS = (\"ë„¤\", \"ì•„\", \"ì‘\", \"ìŒ\", \"ì–´\", \"ê·¸ë˜\")\n",
    "\n",
    "def remove_leading_filler_after_tag(dialogue: str) -> str:\n",
    "    if not isinstance(dialogue, str):\n",
    "        return dialogue\n",
    "\n",
    "    lines = dialogue.split(\"\\n\")\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        # íŒ¨í„´: \"#PersonX#: ë„¤, ...\" â†’ \"#PersonX#: ...\"\n",
    "        pattern = r\"^(#Person\\d+#:\\s*)(%s)[,]?\\s*\" % \"|\".join(LEADING_FILLERS)\n",
    "        line = re.sub(pattern, r\"\\1\", line)\n",
    "        new_lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Preprocess_v2ìš© ìœ í‹¸ =====\n",
    "\n",
    "# 1) greeting / polite / short reaction íŒ¨í„´\n",
    "GREETING_KEYWORDS = [\n",
    "    \"ì•ˆë…•\", \"ì•ˆë…•í•˜ì„¸ìš”\", \"ì•ˆë…•í•˜ì„¸ìš©\", \"ì•ˆë‡½\", \"ì—¬ë³´ì„¸ìš”\", \"ì˜¤ëœë§Œ\", \"ë°˜ê°€ì›Œ\", \"ë°˜ê°‘\", \"ì˜ ì§€ëƒˆì–´\"\n",
    "]\n",
    "\n",
    "POLITE_KEYWORDS = [\n",
    "    \"ê°ì‚¬í•©ë‹ˆë‹¤\", \"ê°ì‚¬ë“œ\", \"ê³ ë§™ìŠµë‹ˆë‹¤\", \"ë„ì™€ë“œë¦¬\", \"ì£„ì†¡í•©ë‹ˆë‹¤\", \"ë¶ˆí¸ì„ ë“œë ¤\", \"ì‹¤ë¡€í•©ë‹ˆë‹¤\",\n",
    "    \"ì´ìš©í•´ ì£¼ì…”ì„œ\", \"ì´ìš©í•´ì£¼ì…”ì„œ\", \"ë„ì›€ì´ ë˜ì…¨\", \"ë„ì›€ì´ ë˜ì—ˆ\", \"ë„ì›€ì´ ë˜ê¸¸\"\n",
    "]\n",
    "\n",
    "ACK_KEYWORDS = [\n",
    "    \"ë„¤\", \"ë„µ\", \"ì˜ˆ\", \"ì‘\", \"ì›…\", \"ì–´\", \"ê·¸ë˜\", \"ê·¸ëŸ¼\", \"ë§ì•„\", \"ë§ì•„ìš”\",\n",
    "    \"ê·¸ë ‡ì§€\", \"ê·¸ë ‡ì£ \", \"ê·¸ë ‡êµ°\", \"ê·¸ë ‡êµ¬ë‚˜\", \"ì•Œê² ì–´\", \"ì•Œê² ìŠµë‹ˆë‹¤\", \"ì•Œê² ì–´ìš”\"\n",
    "]\n",
    "\n",
    "def _strip_punct(text: str) -> str:\n",
    "    \"\"\"ë¬¸ì¥ ëì˜ ë§ˆì¹¨í‘œ/ëŠë‚Œí‘œ/ë¬¼ìŒí‘œ/ë¬¼ê²°/ì  ë“±ì„ ê±·ì–´ë‚´ì„œ í•µì‹¬ í…ìŠ¤íŠ¸ë§Œ ë‚¨ê¹€.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    text = text.strip()\n",
    "    # ëì— ë¶™ì€ !?~.â€¦ ì œê±°\n",
    "    text = re.sub(r\"[!?~\\.â€¦]+$\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "def _contains_any(text: str, keywords) -> bool:\n",
    "    return any(kw in text for kw in keywords)\n",
    "\n",
    "def _is_greeting(text: str) -> bool:\n",
    "    text = _strip_punct(text)\n",
    "    return _contains_any(text, GREETING_KEYWORDS)\n",
    "\n",
    "def _is_polite_phrase(text: str) -> bool:\n",
    "    text = _strip_punct(text)\n",
    "    return _contains_any(text, POLITE_KEYWORDS)\n",
    "\n",
    "def _is_short_ack(text: str) -> bool:\n",
    "    text = _strip_punct(text)\n",
    "    # í•œë‘ ë‹¨ì–´ ì •ë„ì˜ ì§§ì€ ë°˜ì‘ë§Œ ACK í›„ë³´ë¡œ\n",
    "    if len(text.split()) > 3:\n",
    "        return False\n",
    "    return _contains_any(text, ACK_KEYWORDS)\n",
    "\n",
    "def apply_tier2_tier3_and_ack(dialogue: str, ack_token: str = \"<ACK>\") -> str:\n",
    "    \"\"\"\n",
    "    - Tier2 greeting ì œê±°\n",
    "    - Tier3 polite phrase ì œê±°\n",
    "    - ë°˜ì‘í˜• ì§§ì€ ë¬¸ì¥ â†’ <ACK> ì¶•ì•½\n",
    "    \"\"\"\n",
    "    if not isinstance(dialogue, str):\n",
    "        return dialogue\n",
    "\n",
    "    lines = dialogue.split(\"\\n\")\n",
    "    new_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        if not stripped:\n",
    "            continue\n",
    "\n",
    "        m = re.match(r\"^(#Person\\d+#:\\s*)(.+)$\", stripped)\n",
    "        if not m:\n",
    "            # í™”ì íƒœê·¸ ì—†ëŠ” ì¤„ì€ ê·¸ëŒ€ë¡œ ë‘ \n",
    "            new_lines.append(stripped)\n",
    "            continue\n",
    "\n",
    "        tag_prefix = m.group(1)   # \"#Person1#: \"\n",
    "        content = m.group(2).strip()\n",
    "\n",
    "        # greeting / polite phraseë§Œ ìˆëŠ” ì§§ì€ í„´ì´ë©´ ì œê±°\n",
    "        if _is_greeting(content) and len(content) <= 10:\n",
    "            # ì˜ˆ: \"#Person1#: ì•ˆë…•í•˜ì„¸ìš”\" â†’ ì œê±°\n",
    "            continue\n",
    "        if _is_polite_phrase(content) and len(content) <= 20:\n",
    "            # ì˜ˆ: \"#Person2#: ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤\" â†’ ì œê±°\n",
    "            continue\n",
    "\n",
    "        # ì§§ì€ ë°˜ì‘í˜• ë¬¸ì¥ â†’ <ACK>ë¡œ ì¶•ì•½\n",
    "        if _is_short_ack(content):\n",
    "            new_lines.append(f\"{tag_prefix}{ack_token}\")\n",
    "        else:\n",
    "            new_lines.append(f\"{tag_prefix}{content}\")\n",
    "\n",
    "    return \"\\n\".join(new_lines)\n",
    "\n",
    "# 2) topic ì¶•ì•½ (ë„ˆë¬´ ê¸´ topic ì˜ë¼ë‚´ê¸°)\n",
    "def shorten_topic(topic: str, max_len: int = 40) -> str:\n",
    "    \"\"\"\n",
    "    - topicì´ ë„ˆë¬´ ê¸´ ê²½ìš° ì• ë¶€ë¶„ë§Œ ë‚¨ê¸°ê¸°\n",
    "    - ê¸¸ì´ ê¸°ì¤€ì€ char ë‹¨ìœ„ (í•„ìš”í•˜ë©´ ì¡°ì • ê°€ëŠ¥)\n",
    "    \"\"\"\n",
    "    if not isinstance(topic, str):\n",
    "        return topic\n",
    "    topic = topic.strip()\n",
    "    if len(topic) <= max_len:\n",
    "        return topic\n",
    "    return topic[:max_len].rstrip() + \"â€¦\"\n",
    "\n",
    "# 3) summary outlier íŒë³„ (ë„ˆë¬´ ê¸´ ìš”ì•½ ì œê±°ìš©)\n",
    "def is_summary_outlier(summary: str, max_chars: int = 220) -> bool:\n",
    "    \"\"\"\n",
    "    - ë§¤ìš° ê¸´ summaryë¥¼ outlierë¡œ ê°„ì£¼\n",
    "    - thresholdëŠ” char ê¸°ì¤€, í•„ìš”í•˜ë©´ í† í° ê¸°ì¤€ìœ¼ë¡œ ë°”ê¿€ ìˆ˜ ìˆìŒ\n",
    "    \"\"\"\n",
    "    if not isinstance(summary, str):\n",
    "        return False\n",
    "    return len(summary) > max_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ì „ì²˜ë¦¬ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========== ì „ì²˜ë¦¬ v1 í´ë˜ìŠ¤ ==========#\n",
    "\n",
    "# ë°ì´í„°ì…‹ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ì…ë ¥ì„ ìƒì„±\n",
    "class Preprocess:\n",
    "    def __init__(self,\n",
    "            bos_token: str,\n",
    "            eos_token: str,\n",
    "        ) -> None:\n",
    "\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "\n",
    "    @staticmethod\n",
    "    def make_set_as_df(file_path, is_train: bool = True):\n",
    "        \"\"\"\n",
    "        ê¸°ì¡´ baselineê³¼ ë™ì¼í•œ ì—­í• :\n",
    "        - train/dev: fname, dialogue, summary\n",
    "        - test    : fname, dialogue\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        if is_train:\n",
    "            df = df[['fname', 'dialogue', 'summary']]\n",
    "        else:\n",
    "            df = df[['fname', 'dialogue']]\n",
    "        return df\n",
    "\n",
    "    def preprocess_pair(self, dialogue: str, summary: str | None = None, is_test: bool = False):\n",
    "        \"\"\"\n",
    "        Preprocess_v1 ì „ì²´ ì ìš©:\n",
    "        - í™”ì íƒœê·¸ 1/2 ì •ê·œí™”\n",
    "        - turn êµ¬ì¡° ìœ ì§€(ì¤„ ë‹¨ìœ„ ì²˜ë¦¬)\n",
    "        - ê³µë°±/ê°œí–‰ ì •ê·œí™”\n",
    "        - íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”\n",
    "        - Tier1 ë…¸ì´ì¦ˆ ì¶•ì•½\n",
    "        - leading filler ì œê±°\n",
    "        \"\"\"\n",
    "\n",
    "        # 1) í™”ì íƒœê·¸ 1/2 ì •ê·œí™” (dialogue & summary ë™ì‹œì—)\n",
    "        dialogue, summary = normalize_speaker_tags(dialogue, summary)\n",
    "\n",
    "        # 2) ê³µë°±/ê°œí–‰ ì •ê·œí™” (ì¤„ë‹¨ìœ„ strip + ë¹ˆì¤„ ì œê±°)\n",
    "        dialogue = normalize_spaces_and_newlines(dialogue)\n",
    "        if summary is not None:\n",
    "            summary = normalize_spaces_and_newlines(summary)\n",
    "\n",
    "        # 3) íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™” (.../!!/??/~~)\n",
    "        dialogue = normalize_special_chars(dialogue)\n",
    "        if summary is not None:\n",
    "            summary = normalize_special_chars(summary)\n",
    "\n",
    "        # 4) Tier1 ë…¸ì´ì¦ˆ ì¶•ì•½ (ì–´/ì•„/ìŒ, ã…‹ã…‹, ã… ã…  ë“±)\n",
    "        dialogue = compress_tier1_noise(dialogue)\n",
    "        if summary is not None:\n",
    "            summary = compress_tier1_noise(summary)\n",
    "\n",
    "        # 5) leading filler ì œê±° (#PersonX#: ë„¤, / ì•„, / ì‘, / ìŒ ë“±)\n",
    "        dialogue = remove_leading_filler_after_tag(dialogue)\n",
    "\n",
    "        if is_test:\n",
    "            return dialogue, None\n",
    "        else:\n",
    "            return dialogue, summary\n",
    "\n",
    "    # BART ëª¨ë¸ì˜ ì…ë ¥, ì¶œë ¥ í˜•íƒœë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì „ì²˜ë¦¬ë¥¼ ì§„í–‰\n",
    "    def make_input(self, dataset: pd.DataFrame, is_test: bool = False):\n",
    "        \"\"\"\n",
    "        - dataset: make_set_as_dfë¡œ ë§Œë“  df\n",
    "        - is_test:\n",
    "            - True  â†’ dialogueë§Œ ìˆê³  summary ì—†ìŒ\n",
    "            - False â†’ dialogue + summary ëª¨ë‘ ìˆìŒ\n",
    "        \"\"\"\n",
    "        if is_test:\n",
    "            encoder_input_list = []\n",
    "            decoder_input_list = []\n",
    "\n",
    "            for row in dataset.itertuples(index=False):\n",
    "                clean_dialogue, _ = self.preprocess_pair(row.dialogue, None, is_test=True)\n",
    "                encoder_input_list.append(clean_dialogue)\n",
    "                # testì—ì„œëŠ” ë””ì½”ë” ì…ë ¥ì— bos_tokenë§Œ ì‚¬ìš©\n",
    "                decoder_input_list.append(self.bos_token)\n",
    "\n",
    "            return encoder_input_list, decoder_input_list\n",
    "\n",
    "        else:\n",
    "            encoder_input_list = []\n",
    "            decoder_input_list = []\n",
    "            decoder_output_list = []\n",
    "\n",
    "            for row in dataset.itertuples(index=False):\n",
    "                clean_dialogue, clean_summary = self.preprocess_pair(row.dialogue, row.summary, is_test=False)\n",
    "\n",
    "                # encoder input: ì „ì²˜ë¦¬ëœ dialogue\n",
    "                encoder_input_list.append(clean_dialogue)\n",
    "\n",
    "                # decoder input: bos + summary (teacher forcing)\n",
    "                decoder_input_list.append(self.bos_token + str(clean_summary))\n",
    "\n",
    "                # decoder output: summary + eos\n",
    "                decoder_output_list.append(str(clean_summary) + self.eos_token)\n",
    "\n",
    "            return encoder_input_list, decoder_input_list, decoder_output_list\n",
    "        \n",
    "\n",
    "#========== ì „ì²˜ë¦¬ v2 í´ë˜ìŠ¤ ==========#\n",
    "class PreprocessV2(Preprocess):\n",
    "    \"\"\"\n",
    "    Preprocess_v1 + v2 (ì…ë ¥/ì¶œë ¥ ë¶„ë¦¬ ë²„ì „)\n",
    "\n",
    "    ğŸ”¹ dialogue ìª½ (encoder input)\n",
    "        - í™”ì íƒœê·¸ 1/2 ì •ê·œí™”\n",
    "        - ê³µë°±/ê°œí–‰ ì •ê·œí™”\n",
    "        - íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”\n",
    "        - Tier1 ë…¸ì´ì¦ˆ ì¶•ì•½\n",
    "        - leading filler ì œê±°\n",
    "        - Tier2 greeting ì œê±°\n",
    "        - Tier3 polite phrase ì œê±°\n",
    "        - ì§§ì€ ë°˜ì‘í˜• ë¬¸ì¥ <ACK> ì¶•ì•½\n",
    "\n",
    "    ğŸ”¹ summary ìª½ (decoder target)\n",
    "        - í™”ì íƒœê·¸ 1/2 ì •ê·œí™” (dialogueì™€ ì¼ê´€ì„± ìœ ì§€ìš©)\n",
    "        - ê³µë°±/ê°œí–‰ ì •ê·œí™”\n",
    "        - íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”\n",
    "        - âŒ Tier1 ë…¸ì´ì¦ˆ ì¶•ì•½ ì—†ìŒ\n",
    "        - âŒ greeting/polite/ACK ì „ì²˜ë¦¬ ì—†ìŒ\n",
    "\n",
    "    ì˜µì…˜:\n",
    "        - drop_summary_outlier: Trueë©´ ë„ˆë¬´ ê¸´ summaryëŠ” í•™ìŠµ ìƒ˜í”Œì—ì„œ ì œê±°\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "            bos_token: str,\n",
    "            eos_token: str,\n",
    "            drop_summary_outlier: bool = False,\n",
    "            summary_outlier_max_chars: int = 220,\n",
    "        ) -> None:\n",
    "        super().__init__(bos_token, eos_token)\n",
    "        self.drop_summary_outlier = drop_summary_outlier\n",
    "        self.summary_outlier_max_chars = summary_outlier_max_chars\n",
    "\n",
    "    def preprocess_pair(self, dialogue: str, summary: str | None = None, is_test: bool = False):\n",
    "        \"\"\"\n",
    "        ğŸ”¹ 1ë‹¨ê³„: í™”ì íƒœê·¸ ì •ê·œí™” (dialogue & summary ê³µí†µ)\n",
    "        ğŸ”¹ 2ë‹¨ê³„: dialogue ì „ì²˜ë¦¬ (ê°•í•˜ê²Œ)\n",
    "        ğŸ”¹ 3ë‹¨ê³„: summary ì „ì²˜ë¦¬ (ì•½í•˜ê²Œ)\n",
    "        ğŸ”¹ 4ë‹¨ê³„: (ì˜µì…˜) summary outlier ì œê±°\n",
    "        \"\"\"\n",
    "\n",
    "        # ========== 1) í™”ì íƒœê·¸ 1/2 ì •ê·œí™” ==========\n",
    "        dialogue, summary = normalize_speaker_tags(dialogue, summary)\n",
    "\n",
    "        # ========== 2) dialogueìš© ì „ì²˜ë¦¬ (ê°•í•˜ê²Œ) ==========\n",
    "        # 2-1) ê³µë°±/ê°œí–‰ ì •ê·œí™”\n",
    "        dialogue = normalize_spaces_and_newlines(dialogue)\n",
    "        # 2-2) íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™” (..., !!, ??, ~~)\n",
    "        dialogue = normalize_special_chars(dialogue)\n",
    "        # 2-3) Tier1 ë…¸ì´ì¦ˆ ì¶•ì•½ (ã…‹ã…‹, ã… ã… , ì–´ì–´ì–´ ë“±)\n",
    "        dialogue = compress_tier1_noise(dialogue)\n",
    "        # 2-4) leading filler ì œê±° (#PersonX#: ë„¤, / ì•„, / ì‘, / ìŒ ë“±)\n",
    "        dialogue = remove_leading_filler_after_tag(dialogue)\n",
    "        # 2-5) Tier2 greeting ì œê±° + Tier3 polite ì œê±° + ACK ì¶•ì•½\n",
    "        dialogue = apply_tier2_tier3_and_ack(dialogue, ack_token=\"<ACK>\")\n",
    "\n",
    "        # ========== 3) summaryìš© ì „ì²˜ë¦¬ (ì•½í•˜ê²Œ) ==========\n",
    "        if summary is not None:\n",
    "            # 3-1) ê³µë°±/ê°œí–‰ ì •ê·œí™”\n",
    "            summary = normalize_spaces_and_newlines(summary)\n",
    "            # 3-2) íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™” (..., !!, ??, ~~)\n",
    "            summary = normalize_special_chars(summary)\n",
    "            # âŒ compress_tier1_noise(summary)ëŠ” í•˜ì§€ ì•ŠìŒ\n",
    "            # âŒ greeting/polite/ACK ì „ì²˜ë¦¬ëŠ” summaryì—” ì ìš© X\n",
    "\n",
    "        # ========== 4) summary outlier ì œê±° ì˜µì…˜ ==========\n",
    "        if not is_test and self.drop_summary_outlier and isinstance(summary, str):\n",
    "            if is_summary_outlier(summary, max_chars=self.summary_outlier_max_chars):\n",
    "                # í•™ìŠµì—ì„œ ì œê±°í•  ìˆ˜ ìˆë„ë¡ summary=None ë¦¬í„´\n",
    "                return dialogue, None\n",
    "\n",
    "        # testì—ëŠ” summary ìì²´ê°€ ì—†ìœ¼ë‹ˆ ê·¸ëŒ€ë¡œ ë°˜í™˜\n",
    "        return dialogue, summary\n",
    "\n",
    "    def make_input(self, dataset: pd.DataFrame, is_test: bool = False):\n",
    "        \"\"\"\n",
    "        - is_test=True:\n",
    "            encoder_input_list: ì „ì²˜ë¦¬ëœ dialogue\n",
    "            decoder_input_list: bos_tokenë§Œ (summary ì—†ìŒ)\n",
    "\n",
    "        - is_test=False:\n",
    "            encoder_input_list: ì „ì²˜ë¦¬ëœ dialogue\n",
    "            decoder_input_list: bos + summary\n",
    "            decoder_output_list: summary + eos\n",
    "            (drop_summary_outlier=True ì´ë©´ outlier summary ìƒ˜í”Œì€ ìŠ¤í‚µ)\n",
    "        \"\"\"\n",
    "        if is_test:\n",
    "            encoder_input_list = []\n",
    "            decoder_input_list = []\n",
    "\n",
    "            for row in dataset.itertuples(index=False):\n",
    "                clean_dialogue, _ = self.preprocess_pair(row.dialogue, None, is_test=True)\n",
    "                encoder_input_list.append(clean_dialogue)\n",
    "                decoder_input_list.append(self.bos_token)\n",
    "\n",
    "            return encoder_input_list, decoder_input_list\n",
    "\n",
    "        else:\n",
    "            encoder_input_list = []\n",
    "            decoder_input_list = []\n",
    "            decoder_output_list = []\n",
    "\n",
    "            skipped = 0\n",
    "\n",
    "            for row in dataset.itertuples(index=False):\n",
    "                clean_dialogue, clean_summary = self.preprocess_pair(\n",
    "                    row.dialogue,\n",
    "                    row.summary,\n",
    "                    is_test=False\n",
    "                )\n",
    "\n",
    "                # summary outlier ì œê±° í™œì„±í™” + Noneì´ë©´ ìŠ¤í‚µ\n",
    "                if self.drop_summary_outlier and clean_summary is None:\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "                encoder_input_list.append(clean_dialogue)\n",
    "                decoder_input_list.append(self.bos_token + str(clean_summary))\n",
    "                decoder_output_list.append(str(clean_summary) + self.eos_token)\n",
    "\n",
    "            if skipped > 0:\n",
    "                print(f\"âš ï¸ summary outlierë¡œ ìŠ¤í‚µëœ ìƒ˜í”Œ ìˆ˜: {skipped}\")\n",
    "\n",
    "            return encoder_input_list, decoder_input_list, decoder_output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessV5(PreprocessV2):\n",
    "    \"\"\"\n",
    "    Preprocess_v2_input_only + ê¸¸ì´ ê¸°ë°˜ ë°ì´í„° ìŠ¤í‚µ ì„¸ë¶„í™” ë²„ì „.\n",
    "\n",
    "    ğŸ”¹ ê¸°ë°˜:\n",
    "        - PreprocessV2 (ì…ë ¥ ê°•í•˜ê²Œ, summary light ì „ì²˜ë¦¬)\n",
    "        - drop_summary_outlier, summary_outlier_max_chars ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "\n",
    "    ğŸ”¹ ì¶”ê°€ length filter (train/devì—ë§Œ ì ìš©):\n",
    "        - ëŒ€í™” ê¸€ì ìˆ˜ < min_dialogue_chars â†’ ìŠ¤í‚µ\n",
    "        - ìš”ì•½ ê¸€ì ìˆ˜ < min_summary_chars â†’ ìŠ¤í‚µ\n",
    "        - ëŒ€í™” í„´ ìˆ˜ < min_dialogue_turns â†’ ìŠ¤í‚µ\n",
    "        - (dialogue_chars / summary_chars) > max_dialogue_summary_ratio â†’ ìŠ¤í‚µ\n",
    "        - (dialogue_chars / summary_chars) < min_dialogue_summary_ratio â†’ ìŠ¤í‚µ\n",
    "\n",
    "    âš ï¸ test(is_test=True) ì—ì„œëŠ” ì–´ë–¤ ìƒ˜í”Œë„ ìŠ¤í‚µí•˜ì§€ ì•ŠìŒ.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        bos_token: str,\n",
    "        eos_token: str,\n",
    "        drop_summary_outlier: bool = True,\n",
    "        summary_outlier_max_chars: int = 220,\n",
    "        # ê¸¸ì´ ê¸°ë°˜ í•„í„°ë§ íŒŒë¼ë¯¸í„°\n",
    "        min_dialogue_chars: int = 30,\n",
    "        min_summary_chars: int = 5,\n",
    "        min_dialogue_turns: int = 2,\n",
    "        max_dialogue_summary_ratio: float = 15.0,\n",
    "        min_dialogue_summary_ratio: float = 0.5,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            bos_token=bos_token,\n",
    "            eos_token=eos_token,\n",
    "            drop_summary_outlier=drop_summary_outlier,\n",
    "            summary_outlier_max_chars=summary_outlier_max_chars,\n",
    "        )\n",
    "        self.min_dialogue_chars = min_dialogue_chars\n",
    "        self.min_summary_chars = min_summary_chars\n",
    "        self.min_dialogue_turns = min_dialogue_turns\n",
    "        self.max_dialogue_summary_ratio = max_dialogue_summary_ratio\n",
    "        self.min_dialogue_summary_ratio = min_dialogue_summary_ratio\n",
    "\n",
    "    def _is_length_outlier(self, dialogue: str, summary: str | None) -> bool:\n",
    "        \"\"\"\n",
    "        ê¸¸ì´ ê¸°ë°˜ ì´ìƒì¹˜ ì—¬ë¶€ íŒë‹¨.\n",
    "        summaryê°€ Noneì´ë©´ (ì´ë¯¸ ìƒìœ„ ë¡œì§ì—ì„œ outlier ì²˜ë¦¬ëœ ê²ƒ) ì—¬ê¸°ì„  True ë°˜í™˜ X.\n",
    "        \"\"\"\n",
    "        if summary is None:\n",
    "            return False\n",
    "\n",
    "        # ê¸€ì ìˆ˜\n",
    "        d_len = len(dialogue)\n",
    "        s_len = len(summary)\n",
    "\n",
    "        # ëŒ€í™”/ìš”ì•½ì´ ë„ˆë¬´ ì§§ì€ ê²½ìš°\n",
    "        if d_len < self.min_dialogue_chars:\n",
    "            return True\n",
    "        if s_len < self.min_summary_chars:\n",
    "            return True\n",
    "\n",
    "        # í„´ ìˆ˜ (ì¤„ ìˆ˜)\n",
    "        turns = [ln for ln in dialogue.split(\"\\n\") if ln.strip()]\n",
    "        if len(turns) < self.min_dialogue_turns:\n",
    "            return True\n",
    "\n",
    "        # ê¸¸ì´ ë¹„ìœ¨\n",
    "        if s_len > 0:\n",
    "            ratio = d_len / s_len\n",
    "            if ratio > self.max_dialogue_summary_ratio:\n",
    "                return True\n",
    "            if ratio < self.min_dialogue_summary_ratio:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def preprocess_pair(self, dialogue: str, summary: str | None = None, is_test: bool = False):\n",
    "        \"\"\"\n",
    "        1) ë¨¼ì € PreprocessV2 (ì…ë ¥ ê°•í•˜ê²Œ, summary light) ì „ì²˜ë¦¬ ìˆ˜í–‰\n",
    "        2) train/dev (is_test=False) ì—ì„œë§Œ ê¸¸ì´ ê¸°ë°˜ í•„í„° ì ìš©\n",
    "            - ê¸¸ì´ ì´ìƒì¹˜ë©´ summary=Noneìœ¼ë¡œ ëŒë ¤ë³´ë‚´ì„œ make_inputì—ì„œ ìŠ¤í‚µ\n",
    "        3) test (is_test=True) ì—ì„œëŠ” ê¸¸ì´ í•„í„° ì ìš© X (ê·¸ëŒ€ë¡œ í†µê³¼)\n",
    "        \"\"\"\n",
    "\n",
    "        # 1) v2_input_only ì „ì²˜ë¦¬ (í™”ì íƒœê·¸ ì •ê·œí™”, noise ì œê±° ë“±)\n",
    "        dialogue, summary = super().preprocess_pair(dialogue, summary, is_test=is_test)\n",
    "\n",
    "        # test ë°ì´í„°ëŠ” ì ˆëŒ€ ìŠ¤í‚µ X\n",
    "        if is_test:\n",
    "            return dialogue, summary\n",
    "\n",
    "        # summaryê°€ ì´ë¯¸ Noneì´ë©´ (ì˜ˆ: summary_outlier_max_chars ë•Œë¬¸ì—) ì—¬ê¸°ì„œ ë” ì²˜ë¦¬í•  í•„ìš” ì—†ìŒ\n",
    "        if summary is None:\n",
    "            return dialogue, None\n",
    "\n",
    "        # 2) ê¸¸ì´ ê¸°ë°˜ í•„í„°ë§\n",
    "        if self._is_length_outlier(dialogue, summary):\n",
    "            # í•™ìŠµì—ì„œ ì œì™¸í•  ìˆ˜ ìˆë„ë¡ summary=Noneìœ¼ë¡œ í‘œì‹œ\n",
    "            return dialogue, None\n",
    "\n",
    "        return dialogue, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preprocessed_csv(preprocessor: PreprocessV2, config, version=version_name):     # ë²„ì „ê´€ë¦¬\n",
    "    data_path = config['general']['data_path']\n",
    "\n",
    "    train_path = f\"{data_path}/raw/train.csv\"\n",
    "    dev_path = f\"{data_path}/raw/dev.csv\"\n",
    "    test_path = f\"{data_path}/raw/test.csv\"\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    dev_df = pd.read_csv(dev_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    new_train = []\n",
    "    new_dev = []\n",
    "    new_test = []\n",
    "\n",
    "    skipped_train = 0\n",
    "    skipped_dev = 0\n",
    "\n",
    "    # ===== Train =====\n",
    "    for row in train_df.itertuples(index=False):\n",
    "        # topic ì¶•ì•½ ë¨¼ì €\n",
    "        topic = shorten_topic(row.topic, max_len=40)\n",
    "\n",
    "        clean_dialogue, clean_summary = preprocessor.preprocess_pair(\n",
    "            row.dialogue,\n",
    "            row.summary,\n",
    "            is_test=False\n",
    "        )\n",
    "\n",
    "        if preprocessor.drop_summary_outlier and clean_summary is None:\n",
    "            skipped_train += 1\n",
    "            continue\n",
    "\n",
    "        new_train.append([row.fname, clean_dialogue, clean_summary, topic])\n",
    "\n",
    "    # ===== Dev =====\n",
    "    for row in dev_df.itertuples(index=False):\n",
    "        topic = shorten_topic(row.topic, max_len=40)\n",
    "\n",
    "        clean_dialogue, clean_summary = preprocessor.preprocess_pair(\n",
    "            row.dialogue,\n",
    "            row.summary,\n",
    "            is_test=False\n",
    "        )\n",
    "\n",
    "        if preprocessor.drop_summary_outlier and clean_summary is None:\n",
    "            skipped_dev += 1\n",
    "            continue\n",
    "\n",
    "        new_dev.append([row.fname, clean_dialogue, clean_summary, topic])\n",
    "\n",
    "    # ===== Test (topic ì—†ìŒ / í˜¹ì€ ì›ë³¸ topic ì•ˆ ì“°ëŠ” ê²½ìš°) =====\n",
    "    for row in test_df.itertuples(index=False):\n",
    "        clean_dialogue, _ = preprocessor.preprocess_pair(\n",
    "            row.dialogue,\n",
    "            None,\n",
    "            is_test=True\n",
    "        )\n",
    "        new_test.append([row.fname, clean_dialogue])\n",
    "\n",
    "    new_train_df = pd.DataFrame(new_train, columns=[\"fname\", \"dialogue\", \"summary\", \"topic\"])\n",
    "    new_dev_df = pd.DataFrame(new_dev, columns=[\"fname\", \"dialogue\", \"summary\", \"topic\"])\n",
    "    new_test_df = pd.DataFrame(new_test, columns=[\"fname\", \"dialogue\"])\n",
    "\n",
    "    save_dir = f\"{data_path}/processed/preprocessed_{version}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    new_train_df.to_csv(f\"{save_dir}/train_{exp_name}.csv\", index=False)    # ë²„ì „ê´€ë¦¬\n",
    "    new_dev_df.to_csv(f\"{save_dir}/dev_{exp_name}.csv\", index=False)\n",
    "    new_test_df.to_csv(f\"{save_dir}/test_{exp_name}.csv\", index=False)\n",
    "\n",
    "    print(\"\\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ | ì €ì¥ ìœ„ì¹˜: {save_dir}\")\n",
    "    print(f\"âš ï¸ ìŠ¤í‚µëœ ì´ìƒì¹˜ | Train : {skipped_train}, Dev : {skipped_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ê°€ê³µ ë° ë°ì´í„°ì…‹ í´ë˜ìŠ¤ êµ¬ì¶•\n",
    ">- csv file ì„ ë¶ˆëŸ¬ì™€ì„œ encoder ì™€ decoderì˜ ì…ë ¥í˜•íƒœë¡œ ê°€ê³µí•˜ê¸°\n",
    ">- ê°€ê³µëœ ë°ì´í„°ë¥¼ torch dataset class ë¡œ êµ¬ì¶•í•˜ì—¬ ëª¨ë¸ì— ì…ë ¥ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "6GDvodoF8sED"
   },
   "outputs": [],
   "source": [
    "# Trainì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜\n",
    "class DatasetForTrain(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}      # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()}     # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        # item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item.update(item2)\n",
    "        # item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]                                                                  \n",
    "        item['labels'] = self.labels['input_ids'][idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Validationì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜\n",
    "class DatasetForVal(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}      # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()}     # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        # item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item.update(item2)\n",
    "        # item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        item['labels'] = self.labels['input_ids'][idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Testì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜\n",
    "class DatasetForInference(Dataset):\n",
    "    def __init__(self, encoder_input, test_id, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.test_id = test_id\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
    "        item['ID'] = self.test_id[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "hT9z4vvS2CCb"
   },
   "outputs": [],
   "source": [
    "# tokenization ê³¼ì •ê¹Œì§€ ì§„í–‰ëœ ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì— ì…ë ¥ë  ë°ì´í„°ë¥¼ ì¶œë ¥\n",
    "def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n",
    "    train_file_path = os.path.join(data_path, 'raw', 'train.csv')\n",
    "    val_file_path = os.path.join(data_path, 'raw', 'dev.csv')\n",
    "\n",
    "    # train, validationì— ëŒ€í•´ ê°ê° ë°ì´í„°í”„ë ˆì„ì„ êµ¬ì¶•\n",
    "    train_data = preprocessor.make_set_as_df(train_file_path)\n",
    "    val_data = preprocessor.make_set_as_df(val_file_path)\n",
    "\n",
    "    # print('\\nğŸš€ train, valid ë°ì´í„° ë¡œë“œ ì¤‘...')\n",
    "    encoder_input_train , decoder_input_train, decoder_output_train = preprocessor.make_input(train_data)\n",
    "    encoder_input_val , decoder_input_val, decoder_output_val = preprocessor.make_input(val_data)\n",
    "    print(\"\\nâœ… í•™ìŠµ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\")\n",
    "\n",
    "    # print('\\nğŸš€ train, valid ë°ì´í„°ì…‹ ìƒì„± ì¤‘...')\n",
    "    tokenized_encoder_inputs = tokenizer(encoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                            add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_inputs = tokenizer(decoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_ouputs = tokenizer(decoder_output_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    train_inputs_dataset = DatasetForTrain(tokenized_encoder_inputs, tokenized_decoder_inputs, tokenized_decoder_ouputs,len(encoder_input_train))\n",
    "\n",
    "    val_tokenized_encoder_inputs = tokenizer(encoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_inputs = tokenizer(decoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_ouputs = tokenizer(decoder_output_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    val_inputs_dataset = DatasetForVal(val_tokenized_encoder_inputs, val_tokenized_decoder_inputs, val_tokenized_decoder_ouputs,len(encoder_input_val))\n",
    "    print(\"\\nâœ… í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!\")\n",
    "\n",
    "    # print(\"\\nğŸ” len filter ì „ì²˜ë¦¬ í›„ ë‚¨ì€ ìƒ˜í”Œì˜ ê°œìˆ˜\")\n",
    "    # print(f\"- encoder_input_train: {len(encoder_input_train)}ê°œ ìƒ˜í”Œ\")\n",
    "    # print(f\"- decoder_input_train: {len(decoder_input_train)}ê°œ ìƒ˜í”Œ\")\n",
    "    # print(f\"- decoder_output_train: {len(decoder_output_train)}ê°œ ìƒ˜í”Œ\")\n",
    "\n",
    "    return train_inputs_dataset, val_inputs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5sKIJ5K5Pz1"
   },
   "source": [
    "### Trainer ë° Trainingargs êµ¬ì¶•í•˜ê¸°\n",
    ">- Huggingface ì˜ Trainer ì™€ Training argumentsë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµì„ ì¼ê´„ì ìœ¼ë¡œ ì²˜ë¦¬í•´ì£¼ëŠ” í´ë˜ìŠ¤ë¥¼ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "aQk8ILcEeGNz"
   },
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì„±ëŠ¥ì— ëŒ€í•œ í‰ê°€ ì§€í‘œ ì •ì˜\n",
    "def compute_metrics(config,tokenizer,pred):\n",
    "    rouge = Rouge()\n",
    "    predictions = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    # ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•´ ë¯¸ë¦¬ ì •ì˜ëœ ë¶ˆí•„ìš”í•œ ìƒì„± í† í°ë“¤ì„ ì œê±°\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "    remove_tokens = config['inference']['remove_tokens']        # configì—ì„œ ì •ì˜í•œ ë¶ˆí•„ìš”í•œ ìƒì„± í† í°\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "\n",
    "    print('\\nğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...')\n",
    "    print(f\"PRED: {replaced_predictions[0]}\")\n",
    "    print(f\"GOLD: {replaced_labels[0]}\")\n",
    "    # print('-'*150)\n",
    "    # print(f\"PRED: {replaced_predictions[1]}\")\n",
    "    # print(f\"GOLD: {replaced_labels[1]}\")\n",
    "    # print('-'*150)\n",
    "    # print(f\"PRED: {replaced_predictions[2]}\")\n",
    "    # print(f\"GOLD: {replaced_labels[2]}\")\n",
    "    print('\\nâœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!')\n",
    "\n",
    "    # ìµœì¢…ì ì¸ ROUGE ì ìˆ˜ë¥¼ ê³„ì‚°\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "\n",
    "    # ROUGE ì ìˆ˜ ì¤‘ F-1 scoreë¥¼ í†µí•´ í‰ê°€\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "RInkG8g-HjBi"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµì„ ìœ„í•œ trainer í´ë˜ìŠ¤ì™€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì •ì˜\n",
    "def load_trainer_for_train(config,generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset):\n",
    "    \n",
    "    # print('\\nğŸš€ training arguments ì •ì˜ ì¤‘...')\n",
    "    # set training args\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "                output_dir=config['general']['output_dir'],\n",
    "                overwrite_output_dir=config['training']['overwrite_output_dir'],\n",
    "                num_train_epochs=config['training']['num_train_epochs'],\n",
    "                learning_rate=config['training']['learning_rate'],\n",
    "                per_device_train_batch_size=config['training']['per_device_train_batch_size'],\n",
    "                per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],\n",
    "                warmup_ratio=config['training']['warmup_ratio'],\n",
    "                weight_decay=config['training']['weight_decay'],\n",
    "                lr_scheduler_type=config['training']['lr_scheduler_type'],\n",
    "                optim =config['training']['optim'],\n",
    "                gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],\n",
    "                evaluation_strategy=config['training']['evaluation_strategy'],\n",
    "                save_strategy =config['training']['save_strategy'],\n",
    "                save_total_limit=config['training']['save_total_limit'],\n",
    "                fp16=config['training']['fp16'],\n",
    "                load_best_model_at_end=config['training']['load_best_model_at_end'],\n",
    "                seed=config['training']['seed'],\n",
    "                logging_dir=config['training']['logging_dir'],\n",
    "                logging_strategy=config['training']['logging_strategy'],\n",
    "                predict_with_generate=config['training']['predict_with_generate'],\n",
    "                generation_max_length=config['training']['generation_max_length'],\n",
    "                do_train=config['training']['do_train'],\n",
    "                do_eval=config['training']['do_eval'],\n",
    "                report_to=config['training']['report_to']                             # wandb ì‚¬ìš© ì„¤ì •\n",
    "            )\n",
    "\n",
    "    # wandb ì´ˆê¸°í™”\n",
    "    wandb.init(\n",
    "        # entity=config['wandb']['entity'],\n",
    "        project=config['wandb']['project'],\n",
    "        name=config['wandb']['name'],\n",
    "        dir=\"/root/nlp-competition/wandb\",\n",
    "    )\n",
    "\n",
    "    # wandb checkpoints ì €ì¥í•˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •\n",
    "    os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "    os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "\n",
    "    # EarlyStopping : Validation lossê°€ ë” ì´ìƒ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ í•™ìŠµì„ ì¤‘ë‹¨\n",
    "    MyCallback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=config['training']['early_stopping_patience'],\n",
    "        early_stopping_threshold=config['training']['early_stopping_threshold']\n",
    "    )\n",
    "    print('\\nâœ… training arguments ì •ì˜ ì™„ë£Œ!')\n",
    "    \n",
    "    # print('\\nğŸš€ trainer ìƒì„± ì¤‘...')\n",
    "    # Trainer í´ë˜ìŠ¤ ì •ì˜\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=generate_model,                                                           # ì‚¬ìš©ìê°€ ì‚¬ì „ í•™ìŠµí•˜ê¸° ìœ„í•´ ì‚¬ìš©í•  ëª¨ë¸ ì…ë ¥\n",
    "        args=training_args,\n",
    "        train_dataset=train_inputs_dataset,\n",
    "        eval_dataset=val_inputs_dataset,\n",
    "        compute_metrics = lambda pred: compute_metrics(config,tokenizer, pred),\n",
    "        callbacks = [MyCallback]\n",
    "    )\n",
    "    print('\\nâœ… trainer ìƒì„± ì™„ë£Œ!')\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "KKWHe8dE5fSx"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµì„ ìœ„í•œ tokenizerì™€ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "def load_tokenizer_and_model_for_train(config,device):\n",
    "\n",
    "    # print('\\nğŸš€ tokenizer & model ë¡œë“œ ì¤‘...')\n",
    "    print(f'\\nğŸ¤– ëª¨ë¸ëª… : {config[\"general\"][\"model_name\"]}')\n",
    "    model_name = config['general']['model_name']\n",
    "    bart_config = BartConfig().from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    generate_model = BartForConditionalGeneration.from_pretrained(config['general']['model_name'],config=bart_config)\n",
    "\n",
    "    special_tokens_dict={'additional_special_tokens':config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))          # ì‚¬ì „ì— special tokenì„ ì¶”ê°€í–ˆìœ¼ë¯€ë¡œ ì¬êµ¬ì„±\n",
    "    generate_model.to(device)\n",
    "    # print(generate_model.config)\n",
    "    # print('âœ… tokenizer & model ë¡œë“œ ì™„ë£Œ!')\n",
    "\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´í¬í¬ì¸íŠ¸ í‰ê°€ í•¨ìˆ˜\n",
    "def eval_checkpoint(ckpt_path, config, tokenizer, eval_dataset):\n",
    "    print(f\"\\n=== Evaluate {ckpt_path} ===\")\n",
    "    model = BartForConditionalGeneration.from_pretrained(ckpt_path)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    args = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"../outputs/tmp_eval\",\n",
    "        per_device_eval_batch_size=config[\"training\"][\"per_device_eval_batch_size\"],\n",
    "        predict_with_generate=True,\n",
    "        do_train=False,\n",
    "        do_eval=True,\n",
    "        report_to=\"wandb\",           # wandb ì„¤ì •\n",
    "    )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=lambda pred: compute_metrics(config, tokenizer, pred),\n",
    "    )\n",
    "\n",
    "    metrics = trainer.evaluate()\n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best & ë§ˆì§€ë§‰ checkpoint ì°¾ëŠ” í•¨ìˆ˜\n",
    "def get_best_and_last_checkpoints(config):\n",
    "    output_dir = Path(config[\"general\"][\"output_dir\"])\n",
    "    ckpt_root = Path(config[\"inference\"][\"ckt_path\"])\n",
    "\n",
    "    # ë§ˆì§€ë§‰ checkpoint ì°¾ê¸°\n",
    "    ckpt_dirs = [p for p in ckpt_root.glob(\"checkpoint-*\") if p.is_dir()]\n",
    "    def _get_step(p: Path) -> int:\n",
    "        return int(p.name.split(\"-\")[-1])\n",
    "    ckpt_dirs = sorted(ckpt_dirs, key=_get_step)\n",
    "    last_ckpt = ckpt_dirs[-1]\n",
    "\n",
    "    # best checkpoint ì°¾ê¸°\n",
    "    state_path = last_ckpt / \"trainer_state.json\"\n",
    "    with open(state_path, \"r\") as f:\n",
    "        state = json.load(f)\n",
    "    best_ckpt = state.get(\"best_model_checkpoint\", None)\n",
    "\n",
    "    print(f\"\\nğŸš€ ì²´í¬í¬ì¸íŠ¸ íƒìƒ‰ ì¤‘...\")\n",
    "    print(\"- best checkpoint :\", best_ckpt)\n",
    "    print(\"- last_ckpt :\", last_ckpt)\n",
    "\n",
    "    return str(best_ckpt), str(last_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_exp_config(config: dict) -> dict:\n",
    "    # ìˆ˜ì • í•„ìš”\n",
    "    return {\n",
    "        \"exp_name\": config.get(\"wandb\", {}).get(\"name\", \"no_name\"),\n",
    "        \"model_name\": config[\"general\"][\"model_name\"],\n",
    "        \"num_train_epochs\": config[\"training\"][\"num_train_epochs\"],\n",
    "        \"learning_rate\": config[\"training\"][\"learning_rate\"],\n",
    "        \"per_device_train_batch_size\": config[\"training\"][\"per_device_train_batch_size\"],\n",
    "        \"per_device_eval_batch_size\": config[\"training\"][\"per_device_eval_batch_size\"],\n",
    "        \"warmup_ratio\": config[\"training\"][\"warmup_ratio\"],\n",
    "        \"weight_decay\": config[\"training\"][\"weight_decay\"],\n",
    "        \"gradient_accumulation_steps\": config[\"training\"][\"gradient_accumulation_steps\"],\n",
    "        \"seed\": config[\"training\"][\"seed\"],\n",
    "        \"lr_scheduler_type\": config[\"training\"][\"lr_scheduler_type\"],\n",
    "        \"optim\": config[\"training\"][\"optim\"],\n",
    "        \"generation_max_length\": config[\"training\"][\"generation_max_length\"],\n",
    "    }\n",
    "\n",
    "# í•œ ë²ˆì˜ ì‹¤í—˜ ê²°ê³¼ë¥¼ exp_log.csvì— ëˆ„ì  ì €ì¥í•˜ëŠ” í•¨ìˆ˜\n",
    "def log_experiment_result(config: dict, metrics: dict, ckpt_info: dict | None = None,\n",
    "                          csv_path: str = \"../outputs/exp_log.csv\",) -> pd.DataFrame:\n",
    "\n",
    "    row = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        **extract_exp_config(config),\n",
    "    }\n",
    "\n",
    "    row[\"exp_name\"] = exp_name\n",
    "\n",
    "    # í‰ê°€ì§€í‘œ ë¶™ì´ê¸° (eval_* ë§Œ í•„í„°ë§)\n",
    "    for k, v in metrics.items():\n",
    "        if k.startswith(\"eval_\"):\n",
    "            col_name = k.replace(\"-\", \"_\")\n",
    "            row[col_name] = v\n",
    "\n",
    "    # checkpoint ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€\n",
    "    if ckpt_info is not None:\n",
    "        row.update(ckpt_info)\n",
    "\n",
    "    # DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "    row_df = pd.DataFrame([row])\n",
    "\n",
    "    # ê¸°ì¡´ csvê°€ ìˆìœ¼ë©´ append, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±\n",
    "    csv_path = Path(csv_path)\n",
    "    if csv_path.exists():\n",
    "        prev_df = pd.read_csv(csv_path)\n",
    "        new_df = pd.concat([prev_df, row_df], ignore_index=True)\n",
    "    else:\n",
    "        new_df = row_df\n",
    "\n",
    "    # ì €ì¥\n",
    "    new_df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nğŸ’¾ ì‹¤í—˜ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {csv_path}\")\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvutzKQYvQgl"
   },
   "source": [
    "### ëª¨ë¸ í•™ìŠµ\n",
    ">- ì•ì—ì„œ êµ¬ì¶•í•œ í´ë˜ìŠ¤ ë° í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "qnA96wmR44is"
   },
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    # ì‚¬ìš©í•  device ì •ì˜\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print(f'âš¡ ì‚¬ìš© ë””ë°”ì´ìŠ¤ : {device} | torch ë²„ì „ : {torch.__version__}')\n",
    "\n",
    "    # ì‚¬ìš©í•  ëª¨ë¸ê³¼ tokenizer ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_train(config,device)\n",
    "    print('âœ… tokenizer ìŠ¤í˜ì…œ í† í° :', tokenizer.special_tokens_map)\n",
    "\n",
    "    # í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    preprocessor = PreprocessV5(\n",
    "    bos_token=config['tokenizer']['bos_token'],\n",
    "    eos_token=config['tokenizer']['eos_token'],\n",
    "    drop_summary_outlier=True,          # outlier ì œê±°í• ì§€ ì—¬ë¶€\n",
    "    summary_outlier_max_chars=220,      # threshold\n",
    "    min_dialogue_chars=30,              # í•„ìš”í•˜ë©´ ì—¬ê¸° ê°’ë“¤ë§Œ ì¡°ì •\n",
    "    min_summary_chars=15,\n",
    "    min_dialogue_turns=2,\n",
    "    # max_dialogue_summary_ratio=1.0,\n",
    "    # min_dialogue_summary_ratio=0.05,\n",
    "    )\n",
    "\n",
    "    data_path = config['general']['data_path']\n",
    "    train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config,preprocessor, data_path, tokenizer)\n",
    "\n",
    "    # ì „ì²˜ë¦¬í•œ íŒŒì¼ csvë¡œ ì €ì¥í•˜ê¸°\n",
    "    save_preprocessed_csv(preprocessor, config, version=version_name)       # ë²„ì „ê´€ë¦¬\n",
    "\n",
    "    # Trainer í´ë˜ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    trainer = load_trainer_for_train(config, generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset)\n",
    "    # ì €ì¥ëœ checkpoint ì´í›„ë¶€í„° ì‹¤í–‰ (ì¤‘ê°„ì— í•™ìŠµì´ ì¤‘ë‹¨ë¼ë„ ë¬¸ì œ ì—†ë„ë¡ í•˜ê¸° ìœ„í•¨)\n",
    "    trainer.train()\n",
    "\n",
    "    # best / last ckpt ìë™ ì°¾ê¸°\n",
    "    best_ckpt, last_ckpt = get_best_and_last_checkpoints(config)\n",
    "\n",
    "    # ë‘ ê°œ ì²´í¬í¬ì¸íŠ¸ í‰ê°€ â†’ DataFrame ë¹„êµ\n",
    "    all_results = []\n",
    "    for name, ckpt in [(\"best\", best_ckpt), (\"last\", last_ckpt)]:\n",
    "        metrics = eval_checkpoint(ckpt, config, tokenizer, val_inputs_dataset)\n",
    "        all_results.append({\n",
    "            \"type\": name,\n",
    "            \"checkpoint\": os.path.basename(ckpt),\n",
    "            **{k: v for k, v in metrics.items() if k.startswith(\"eval_\")},\n",
    "        })\n",
    "    df = pd.DataFrame(all_results)\n",
    "    display(df.round(4))\n",
    "\n",
    "    # ì‹¤í—˜ ë¡œê·¸ ì‘ì„±\n",
    "    exp_df = log_experiment_result(\n",
    "        config,\n",
    "        metrics,\n",
    "        ckpt_info={\"which\": \"best\", \"ckpt\": best_ckpt},\n",
    "        csv_path=\"../outputs/exp_log.csv\",\n",
    "    )\n",
    "\n",
    "    # wandb ì¢…ë£Œ\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1DMS60wL-Dhv",
    "outputId": "cbb6aba7-18ff-4d12-b9e7-2a2ef31d94d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ ì‚¬ìš© ë””ë°”ì´ìŠ¤ : cuda:0 | torch ë²„ì „ : 2.1.0\n",
      "\n",
      "ğŸ¤– ëª¨ë¸ëª… : digit82/kobart-summarization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… tokenizer ìŠ¤í˜ì…œ í† í° : {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask>', 'additional_special_tokens': ['#PassportNumber#', '#Person2#', '#Address#', '#Person1#', '#PhoneNumber#', '#Person3#']}\n",
      "âš ï¸ summary outlierë¡œ ìŠ¤í‚µëœ ìƒ˜í”Œ ìˆ˜: 59\n",
      "âš ï¸ summary outlierë¡œ ìŠ¤í‚µëœ ìƒ˜í”Œ ìˆ˜: 2\n",
      "\n",
      "âœ… í•™ìŠµ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\n",
      "\n",
      "âœ… í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!\n",
      "\n",
      "âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!\n",
      "ğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ | ì €ì¥ ìœ„ì¹˜: ../data//processed/preprocessed_v5\n",
      "âš ï¸ ìŠ¤í‚µëœ ì´ìƒì¹˜ | Train : 59, Dev : 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/nlp-competition/wandb/wandb/run-20251204_080633-8jf84gli</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aistages-nlp-3/NLP-private/runs/8jf84gli' target=\"_blank\">preprocessed_v5_lenfilter</a></strong> to <a href='https://wandb.ai/aistages-nlp-3/NLP-private' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aistages-nlp-3/NLP-private' target=\"_blank\">https://wandb.ai/aistages-nlp-3/NLP-private</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aistages-nlp-3/NLP-private/runs/8jf84gli' target=\"_blank\">https://wandb.ai/aistages-nlp-3/NLP-private/runs/8jf84gli</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… training arguments ì •ì˜ ì™„ë£Œ!\n",
      "\n",
      "âœ… trainer ìƒì„± ì™„ë£Œ!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2480' max='4960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2480/4960 18:18 < 18:19, 2.26 it/s, Epoch 10/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.586800</td>\n",
       "      <td>2.474733</td>\n",
       "      <td>0.214186</td>\n",
       "      <td>0.037754</td>\n",
       "      <td>0.205972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.250900</td>\n",
       "      <td>0.585741</td>\n",
       "      <td>0.335850</td>\n",
       "      <td>0.107070</td>\n",
       "      <td>0.319361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>0.543554</td>\n",
       "      <td>0.349001</td>\n",
       "      <td>0.113536</td>\n",
       "      <td>0.326602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.530500</td>\n",
       "      <td>0.532200</td>\n",
       "      <td>0.359520</td>\n",
       "      <td>0.126690</td>\n",
       "      <td>0.338008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.500100</td>\n",
       "      <td>0.525560</td>\n",
       "      <td>0.360126</td>\n",
       "      <td>0.130554</td>\n",
       "      <td>0.340271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.475600</td>\n",
       "      <td>0.525934</td>\n",
       "      <td>0.364855</td>\n",
       "      <td>0.134269</td>\n",
       "      <td>0.342586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.454900</td>\n",
       "      <td>0.524102</td>\n",
       "      <td>0.363072</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.341944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.437600</td>\n",
       "      <td>0.525170</td>\n",
       "      <td>0.359467</td>\n",
       "      <td>0.131865</td>\n",
       "      <td>0.337510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.421300</td>\n",
       "      <td>0.525202</td>\n",
       "      <td>0.364240</td>\n",
       "      <td>0.133246</td>\n",
       "      <td>0.343222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.408500</td>\n",
       "      <td>0.528613</td>\n",
       "      <td>0.356657</td>\n",
       "      <td>0.128558</td>\n",
       "      <td>0.335069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë„ë¡ ê¶Œìœ í•©ë‹ˆë‹¤.                                                                        \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ê°ê¸°ì— ê±¸ë ¸ë‹¤ê³  ë§í•©ë‹ˆë‹¤. #Person2# ëŠ” ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œí•©ë‹ˆë‹¤.                                                                       \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person1# ì€ ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, #Person2# ëŠ” ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                                               \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person1# ì€ ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, #Person2# ëŠ” ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œí•©ë‹ˆë‹¤.                                                \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, #Person1# ì€ ì•Œë ˆë¥´ê¸°ê°€ ì—†ë‹¤ê³  ì„¤ëª…í•©ë‹ˆë‹¤.                                                     \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë¦¬ì§€ ì•Šì•˜ìœ¼ë©°, #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œí•©ë‹ˆë‹¤.                                                   \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person1# ì€ ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œì¥í•©ë‹ˆë‹¤.                                                                              \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë¦¬ì§€ ì•Šì•˜ìœ¼ë©°, #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œí•©ë‹ˆë‹¤.                                                              \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë¦¬ì§€ ì•Šì•˜ìœ¼ë©°, #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œí•©ë‹ˆë‹¤.                                                                           \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë¦¬ì§€ ì•Šì•˜ìœ¼ë©°, #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œí•©ë‹ˆë‹¤.                                                           \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ì²´í¬í¬ì¸íŠ¸ íƒìƒ‰ ì¤‘...\n",
      "- best checkpoint : ../outputs/checkpoints/checkpoint-1736\n",
      "- last_ckpt : ../outputs/checkpoints/checkpoint-2480\n",
      "\n",
      "=== Evaluate ../outputs/checkpoints/checkpoint-1736 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person1# ì€ ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œ \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "{'eval_loss': 0.5241019129753113, 'eval_rouge-1': 0.3129591865692689, 'eval_rouge-2': 0.1291223390256183, 'eval_rouge-l': 0.2893608881829338, 'eval_runtime': 5.1421, 'eval_samples_per_second': 96.652, 'eval_steps_per_second': 3.112}\n",
      "\n",
      "=== Evaluate ../outputs/checkpoints/checkpoint-2480 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì¤‘...\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë¦¬ì§€ ì•Šì•˜ìœ¼ë©°, #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "\n",
      "âœ… ë¶ˆí•„ìš”í•œ ìƒì„± í† í° ì œê±° ì™„ë£Œ!\n",
      "{'eval_loss': 0.5286132097244263, 'eval_rouge-1': 0.3060446033559577, 'eval_rouge-2': 0.1260921097363075, 'eval_rouge-l': 0.2818419115114695, 'eval_runtime': 5.1315, 'eval_samples_per_second': 96.853, 'eval_steps_per_second': 3.118}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_rouge-1</th>\n",
       "      <th>eval_rouge-2</th>\n",
       "      <th>eval_rouge-l</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best</td>\n",
       "      <td>checkpoint-1736</td>\n",
       "      <td>0.5241</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.2894</td>\n",
       "      <td>5.1421</td>\n",
       "      <td>96.652</td>\n",
       "      <td>3.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>last</td>\n",
       "      <td>checkpoint-2480</td>\n",
       "      <td>0.5286</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.1261</td>\n",
       "      <td>0.2818</td>\n",
       "      <td>5.1315</td>\n",
       "      <td>96.853</td>\n",
       "      <td>3.118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type       checkpoint  eval_loss  eval_rouge-1  eval_rouge-2  eval_rouge-l  \\\n",
       "0  best  checkpoint-1736     0.5241         0.313        0.1291        0.2894   \n",
       "1  last  checkpoint-2480     0.5286         0.306        0.1261        0.2818   \n",
       "\n",
       "   eval_runtime  eval_samples_per_second  eval_steps_per_second  \n",
       "0        5.1421                   96.652                  3.112  \n",
       "1        5.1315                   96.853                  3.118  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ ì‹¤í—˜ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: ../outputs/exp_log.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6461c3292c314c25beba0c050fd3ab13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='472.660 MB of 472.660 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>eval/rouge-1</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–…</td></tr><tr><td>eval/rouge-2</td><td>â–â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡</td></tr><tr><td>eval/rouge-l</td><td>â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–…</td></tr><tr><td>eval/runtime</td><td>â–ˆâ–…â–…â–…â–„â–…â–…â–…â–…â–…â–â–</td></tr><tr><td>eval/samples_per_second</td><td>â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ˆ</td></tr><tr><td>eval/steps_per_second</td><td>â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ˆ</td></tr><tr><td>train/epoch</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–â–</td></tr><tr><td>train/learning_rate</td><td>â–â–ˆâ–ˆâ–ˆâ–‡â–†â–†â–…â–„â–‚</td></tr><tr><td>train/loss</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.52861</td></tr><tr><td>eval/rouge-1</td><td>0.30604</td></tr><tr><td>eval/rouge-2</td><td>0.12609</td></tr><tr><td>eval/rouge-l</td><td>0.28184</td></tr><tr><td>eval/runtime</td><td>5.1315</td></tr><tr><td>eval/samples_per_second</td><td>96.853</td></tr><tr><td>eval/steps_per_second</td><td>3.118</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>0</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.4085</td></tr><tr><td>train/total_flos</td><td>3.77975630462976e+16</td></tr><tr><td>train/train_loss</td><td>1.06524</td></tr><tr><td>train/train_runtime</td><td>1095.5419</td></tr><tr><td>train/train_samples_per_second</td><td>226.335</td></tr><tr><td>train/train_steps_per_second</td><td>4.527</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">preprocessed_v5_lenfilter</strong> at: <a href='https://wandb.ai/aistages-nlp-3/NLP-private/runs/8jf84gli' target=\"_blank\">https://wandb.ai/aistages-nlp-3/NLP-private/runs/8jf84gli</a><br/>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/root/nlp-competition/wandb/wandb/run-20251204_080633-8jf84gli/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(loaded_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFtWqowCGzEc"
   },
   "source": [
    "### ëª¨ë¸ ì¶”ë¡ \n",
    ">- test dataë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "lV1Do7nlTylG"
   },
   "outputs": [],
   "source": [
    "# tokenization ê³¼ì •ê¹Œì§€ ì§„í–‰ëœ test ë°ì´í„° ì¶œë ¥\n",
    "def prepare_test_dataset(config,preprocessor, tokenizer):\n",
    "    \n",
    "    test_file_path = os.path.join(config['general']['data_path'], 'raw', 'test.csv')\n",
    "\n",
    "    test_data = preprocessor.make_set_as_df(test_file_path,is_train=False)\n",
    "    test_id = test_data['fname']\n",
    "    encoder_input_test , decoder_input_test = preprocessor.make_input(test_data,is_test=True)\n",
    "    print('\\nâœ… test ë°ì´í„° ë¡œë“œ ì™„ë£Œ!')\n",
    "\n",
    "    test_tokenized_encoder_inputs = tokenizer(encoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,)\n",
    "    test_tokenized_decoder_inputs = tokenizer(decoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False,)\n",
    "\n",
    "    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n",
    "    print('\\nâœ… test ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!')\n",
    "\n",
    "    return test_data, test_encoder_inputs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "eb49bLULT3aS"
   },
   "outputs": [],
   "source": [
    "# ì¶”ë¡ ì„ ìœ„í•œ tokenizerì™€ í•™ìŠµì‹œí‚¨ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "def load_tokenizer_and_model_for_test(config,device):\n",
    "    model_name = config['general']['model_name']\n",
    "    ckt_path = config['inference']['ckt_path']\n",
    "    print('\\nğŸ¤– ëª¨ë¸ëª… :', model_name)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    # ìë™ íƒìƒ‰ëœ best checkpointë¥¼ ëª¨ë¸ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    best_ckpt, last_ckpt = get_best_and_last_checkpoints(config)\n",
    "    generate_model = BartForConditionalGeneration.from_pretrained(best_ckpt)\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))\n",
    "    generate_model.to(device)\n",
    "    print('ğŸ§  ìµœì¢… ëª¨ë¸ :', best_ckpt)\n",
    "    print('âœ… tokenizer & model ë¡œë“œ ì™„ë£Œ!')\n",
    "\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "Axzu9rsoGLgJ"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ì´ ìƒì„±í•œ ìš”ì•½ë¬¸ì˜ ì¶œë ¥ ê²°ê³¼ ë³´ê¸°\n",
    "def inference(config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print(f'âš¡ ì‚¬ìš© ë””ë°”ì´ìŠ¤ : {device} | torch ë²„ì „ : {torch.__version__}')\n",
    "    \n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_test(config,device)\n",
    "\n",
    "    data_path = config['general']['data_path']\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
    "\n",
    "    test_data, test_encoder_inputs_dataset = prepare_test_dataset(config,preprocessor, tokenizer)\n",
    "    dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=config['inference']['batch_size'])\n",
    "\n",
    "    summary = []\n",
    "    text_ids = []\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataloader):\n",
    "            text_ids.extend(item['ID'])\n",
    "            generated_ids = generate_model.generate(input_ids=item['input_ids'].to('cuda:0'),\n",
    "                            no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                            early_stopping=config['inference']['early_stopping'],\n",
    "                            max_length=config['inference']['generate_max_length'],\n",
    "                            num_beams=config['inference']['num_beams'],\n",
    "                        )\n",
    "            for ids in generated_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "\n",
    "    # ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•˜ì—¬ ë…¸ì´ì¦ˆì— í•´ë‹¹ë˜ëŠ” ìŠ¤í˜ì…œ í† í° ì œê±°\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    preprocessed_summary = summary.copy()\n",
    "    for token in remove_tokens:\n",
    "        preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": test_data['fname'],\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    result_path = config['inference']['result_path']\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    save_name = f\"output_{exp_name}.csv\"                                # ë²„ì „ê´€ë¦¬\n",
    "    output.to_csv(os.path.join(result_path, save_name), index=False)         \n",
    "    print(f\"ğŸ’¾ ì¶”ë¡  ê²°ê³¼ ì €ì¥ ì™„ë£Œ : {result_path}{save_name}\")\n",
    "\n",
    "    print(\"\\nğŸ’¬ testë¬¸ ìš”ì•½ ê²°ê³¼\")\n",
    "    print(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "-pJ1ZXf-5V50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ ì‚¬ìš© ë””ë°”ì´ìŠ¤ : cuda:0 | torch ë²„ì „ : 2.1.0\n",
      "\n",
      "ğŸ¤– ëª¨ë¸ëª… : digit82/kobart-summarization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ì²´í¬í¬ì¸íŠ¸ íƒìƒ‰ ì¤‘...\n",
      "- best checkpoint : ../outputs/checkpoints/checkpoint-1736\n",
      "- last_ckpt : ../outputs/checkpoints/checkpoint-2480\n",
      "ğŸ§  ìµœì¢… ëª¨ë¸ : ../outputs/checkpoints/checkpoint-1736\n",
      "âœ… tokenizer & model ë¡œë“œ ì™„ë£Œ!\n",
      "\n",
      "âœ… test ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\n",
      "\n",
      "âœ… test ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ ì¶”ë¡  ê²°ê³¼ ì €ì¥ ì™„ë£Œ : ../outputs/prediction/output_preprocessed_v5_lenfilter.csv\n",
      "\n",
      "ğŸ’¬ testë¬¸ ìš”ì•½ ê²°ê³¼\n",
      "        fname                                            summary\n",
      "0      test_0   #Person1# ì€ Ms. Dawsonì—ê²Œ ì‚¬ë‚´ ë©”ëª¨ë¥¼ ì‘ì„±í•˜ê³  ë°°í¬í•  ê²ƒì„ ìš”...\n",
      "1      test_1   #Person1# ê³¼ #Person2# ëŠ” êµí†µì²´ì¦ìœ¼ë¡œ ì¸í•´ ëŒ€ì¤‘êµí†µìœ¼ë¡œ ì¶œí‡´ê·¼í•˜...\n",
      "2      test_2    KateëŠ” Mashaì™€ Heroê°€ ì´í˜¼í–ˆë‹¤ê³  #Person1# ì—ê²Œ ë§í•©ë‹ˆë‹¤. ...\n",
      "3      test_3    Brianì€ #Person1# ì˜ ìƒì¼ íŒŒí‹°ì— ì´ˆëŒ€ë°›ì•„ í•¨ê»˜ ì¶¤ì„ ì¶”ê¸°ë¡œ í–ˆë‹¤....\n",
      "4      test_4   #Person1# ê³¼ #Person2# ëŠ” ì˜¬ë¦¼í”½ ê³µì›ì˜ í¬ê¸°ì™€ ì‹œì„¤ì— ëŒ€í•´ ì´ì•¼...\n",
      "..        ...                                                ...\n",
      "494  test_495    Jackì€ Charlieì—ê²Œ ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ê²Œì„ì„ ì œì•ˆí•˜ë©°, #Person1# ...\n",
      "495  test_496   #Person2# ëŠ” #Person1# ì—ê²Œ ì‹œê³¨ ìŒì•…ì— ê´€ì‹¬ì„ ê°–ê²Œ ëœ ê³„ê¸°ì™€ ...\n",
      "496  test_497    AliceëŠ” ì„¸íƒê¸° ì‚¬ìš©ë²•ì„ #Person1# ì—ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤. ì„¸íƒê¸°ëŠ” ë¹„ëˆ„ë¥¼...\n",
      "497  test_498    SteveëŠ” Matthewì—ê²Œ ìƒˆë¡œ ì´ì‚¬í•  ì§‘ì„ ì°¾ê³  ìˆë‹¤ê³  ë§í•˜ë©°, Mrs. ...\n",
      "498  test_499    FrankëŠ” ìŠ¹ì§„í•˜ì—¬ íŒŒí‹°ë¥¼ ì—´ ì˜ˆì •ì´ë©°, íŒŒí‹°ì— 150ëª… ì •ë„ê°€ ì°¸ì„í•  ì˜ˆì •ì´...\n",
      "\n",
      "[499 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ì¶”ë¡  ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    output = inference(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "OsPmLfhbzZqS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ê²°ì¸¡ì¹˜ ë° ë°ì´í„°íƒ€ì… í™•ì¸ | ì •ìƒ shape : (499, 2)\n",
      "- shape: (499, 2)\n",
      "\n",
      "- null check:\n",
      " fname      0\n",
      "summary    0\n",
      "dtype: int64\n",
      "\n",
      "- dtypes:\n",
      " fname      object\n",
      "summary    object\n",
      "dtype: object\n",
      "\n",
      "- duplicated id: 0\n",
      "\n",
      "ğŸ”ìš”ì•½ ê¸¸ì´ ì´ìƒì¹˜ í™•ì¸\n",
      "count    499.000000\n",
      "mean     109.028056\n",
      "std       20.515427\n",
      "min       64.000000\n",
      "25%       94.000000\n",
      "50%      107.000000\n",
      "75%      121.000000\n",
      "max      189.000000\n",
      "Name: summary_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ì œì¶œ ì „ í™•ì¸\n",
    "print(\"ğŸ” ê²°ì¸¡ì¹˜ ë° ë°ì´í„°íƒ€ì… í™•ì¸ | ì •ìƒ shape : (499, 2)\")\n",
    "print(\"- shape:\", output.shape)\n",
    "print(\"\\n- null check:\\n\", output.isnull().sum())\n",
    "print(\"\\n- dtypes:\\n\", output.dtypes)\n",
    "print(\"\\n- duplicated id:\", output['fname'].duplicated().sum())\n",
    "\n",
    "print(\"\\nğŸ”ìš”ì•½ ê¸¸ì´ ì´ìƒì¹˜ í™•ì¸\")\n",
    "output_summary_length = output.copy()\n",
    "output_summary_length['summary_length'] = output_summary_length['summary'].str.len()\n",
    "print(output_summary_length['summary_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ì‹¤í—˜ ë¡œê·¸\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>num_train_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>warmup_ratio</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_rouge_l</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>which</th>\n",
       "      <th>ckpt</th>\n",
       "      <th>lb_rouge_1</th>\n",
       "      <th>lb_rouge_2</th>\n",
       "      <th>lb_rouge_l</th>\n",
       "      <th>lb_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-28 18:01:14</td>\n",
       "      <td>baseline_v1</td>\n",
       "      <td>digit82/kobart-summarization</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148929</td>\n",
       "      <td>5.0999</td>\n",
       "      <td>97.845</td>\n",
       "      <td>3.137</td>\n",
       "      <td>best</td>\n",
       "      <td>../outputs/checkpoints/checkpoint-1750</td>\n",
       "      <td>0.5634</td>\n",
       "      <td>0.3668</td>\n",
       "      <td>0.4819</td>\n",
       "      <td>47.0683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-12-03 10:17:28</td>\n",
       "      <td>preprocessed_v1</td>\n",
       "      <td>digit82/kobart-summarization</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284882</td>\n",
       "      <td>5.0909</td>\n",
       "      <td>98.018</td>\n",
       "      <td>3.143</td>\n",
       "      <td>best</td>\n",
       "      <td>../outputs/checkpoints/checkpoint-1750</td>\n",
       "      <td>0.5638</td>\n",
       "      <td>0.3680</td>\n",
       "      <td>0.4789</td>\n",
       "      <td>47.0228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-03 14:42:29</td>\n",
       "      <td>preprocessed_v2_full</td>\n",
       "      <td>digit82/kobart-summarization</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288991</td>\n",
       "      <td>5.1341</td>\n",
       "      <td>96.999</td>\n",
       "      <td>3.116</td>\n",
       "      <td>best</td>\n",
       "      <td>../outputs/checkpoints/checkpoint-1743</td>\n",
       "      <td>0.5624</td>\n",
       "      <td>0.3668</td>\n",
       "      <td>0.4785</td>\n",
       "      <td>46.9238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-12-04 03:30:26</td>\n",
       "      <td>preprocessed_v2_input_only</td>\n",
       "      <td>digit82/kobart-summarization</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282453</td>\n",
       "      <td>5.0989</td>\n",
       "      <td>97.668</td>\n",
       "      <td>3.138</td>\n",
       "      <td>best</td>\n",
       "      <td>../outputs/checkpoints/checkpoint-1743</td>\n",
       "      <td>0.5693</td>\n",
       "      <td>0.3733</td>\n",
       "      <td>0.4854</td>\n",
       "      <td>47.6004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-12-04 06:02:58</td>\n",
       "      <td>preprocessed_v3_turntrunc</td>\n",
       "      <td>digit82/kobart-summarization</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284264</td>\n",
       "      <td>5.1334</td>\n",
       "      <td>97.013</td>\n",
       "      <td>3.117</td>\n",
       "      <td>best</td>\n",
       "      <td>../outputs/checkpoints/checkpoint-1743</td>\n",
       "      <td>0.5699</td>\n",
       "      <td>0.3707</td>\n",
       "      <td>0.4814</td>\n",
       "      <td>47.4004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-12-04 07:14:39</td>\n",
       "      <td>preprocessed_v4_topicprefix</td>\n",
       "      <td>digit82/kobart-summarization</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288019</td>\n",
       "      <td>5.1205</td>\n",
       "      <td>97.256</td>\n",
       "      <td>3.125</td>\n",
       "      <td>best</td>\n",
       "      <td>../outputs/checkpoints/checkpoint-1743</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.3686</td>\n",
       "      <td>0.4791</td>\n",
       "      <td>47.0793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-12-04 08:25:09</td>\n",
       "      <td>preprocessed_v5_lenfilter</td>\n",
       "      <td>digit82/kobart-summarization</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281842</td>\n",
       "      <td>5.1315</td>\n",
       "      <td>96.853</td>\n",
       "      <td>3.118</td>\n",
       "      <td>best</td>\n",
       "      <td>../outputs/checkpoints/checkpoint-1736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                     exp_name  \\\n",
       "0  2025-11-28 18:01:14                  baseline_v1   \n",
       "1  2025-12-03 10:17:28              preprocessed_v1   \n",
       "2  2025-12-03 14:42:29         preprocessed_v2_full   \n",
       "3  2025-12-04 03:30:26   preprocessed_v2_input_only   \n",
       "4  2025-12-04 06:02:58    preprocessed_v3_turntrunc   \n",
       "5  2025-12-04 07:14:39  preprocessed_v4_topicprefix   \n",
       "6  2025-12-04 08:25:09    preprocessed_v5_lenfilter   \n",
       "\n",
       "                     model_name  num_train_epochs  learning_rate  \\\n",
       "0  digit82/kobart-summarization                20        0.00001   \n",
       "1  digit82/kobart-summarization                20        0.00001   \n",
       "2  digit82/kobart-summarization                20        0.00001   \n",
       "3  digit82/kobart-summarization                20        0.00001   \n",
       "4  digit82/kobart-summarization                20        0.00001   \n",
       "5  digit82/kobart-summarization                20        0.00001   \n",
       "6  digit82/kobart-summarization                20        0.00001   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  warmup_ratio  \\\n",
       "0                           50                          32           0.1   \n",
       "1                           50                          32           0.1   \n",
       "2                           50                          32           0.1   \n",
       "3                           50                          32           0.1   \n",
       "4                           50                          32           0.1   \n",
       "5                           50                          32           0.1   \n",
       "6                           50                          32           0.1   \n",
       "\n",
       "   weight_decay  gradient_accumulation_steps  ...  eval_rouge_l eval_runtime  \\\n",
       "0          0.01                            1  ...      0.148929       5.0999   \n",
       "1          0.01                            1  ...      0.284882       5.0909   \n",
       "2          0.01                            1  ...      0.288991       5.1341   \n",
       "3          0.01                            1  ...      0.282453       5.0989   \n",
       "4          0.01                            1  ...      0.284264       5.1334   \n",
       "5          0.01                            1  ...      0.288019       5.1205   \n",
       "6          0.01                            1  ...      0.281842       5.1315   \n",
       "\n",
       "  eval_samples_per_second  eval_steps_per_second  which  \\\n",
       "0                  97.845                  3.137   best   \n",
       "1                  98.018                  3.143   best   \n",
       "2                  96.999                  3.116   best   \n",
       "3                  97.668                  3.138   best   \n",
       "4                  97.013                  3.117   best   \n",
       "5                  97.256                  3.125   best   \n",
       "6                  96.853                  3.118   best   \n",
       "\n",
       "                                     ckpt  lb_rouge_1  lb_rouge_2  lb_rouge_l  \\\n",
       "0  ../outputs/checkpoints/checkpoint-1750      0.5634      0.3668      0.4819   \n",
       "1  ../outputs/checkpoints/checkpoint-1750      0.5638      0.3680      0.4789   \n",
       "2  ../outputs/checkpoints/checkpoint-1743      0.5624      0.3668      0.4785   \n",
       "3  ../outputs/checkpoints/checkpoint-1743      0.5693      0.3733      0.4854   \n",
       "4  ../outputs/checkpoints/checkpoint-1743      0.5699      0.3707      0.4814   \n",
       "5  ../outputs/checkpoints/checkpoint-1743      0.5647      0.3686      0.4791   \n",
       "6  ../outputs/checkpoints/checkpoint-1736         NaN         NaN         NaN   \n",
       "\n",
       "   lb_final  \n",
       "0   47.0683  \n",
       "1   47.0228  \n",
       "2   46.9238  \n",
       "3   47.6004  \n",
       "4   47.4004  \n",
       "5   47.0793  \n",
       "6       NaN  \n",
       "\n",
       "[7 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ì œì¶œ í›„ LB ì ìˆ˜ > ì‹¤í—˜ ë¡œê·¸ì— ê¸°ë¡\n",
    "log_path = \"../outputs/exp_log.csv\"\n",
    "exp_log = pd.read_csv(log_path)\n",
    "\n",
    "# ì „ì²´ ë¡œê·¸ ë³´ê¸°\n",
    "print(\"ğŸ“ ì‹¤í—˜ ë¡œê·¸\")\n",
    "display(exp_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_rouge_1</th>\n",
       "      <th>eval_rouge_2</th>\n",
       "      <th>eval_rouge_l</th>\n",
       "      <th>lb_rouge_1</th>\n",
       "      <th>lb_rouge_2</th>\n",
       "      <th>lb_rouge_l</th>\n",
       "      <th>lb_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-28 18:01:14</td>\n",
       "      <td>baseline_v1</td>\n",
       "      <td>0.596968</td>\n",
       "      <td>0.154657</td>\n",
       "      <td>0.042543</td>\n",
       "      <td>0.148929</td>\n",
       "      <td>0.5634</td>\n",
       "      <td>0.3668</td>\n",
       "      <td>0.4819</td>\n",
       "      <td>47.0683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-12-03 10:17:28</td>\n",
       "      <td>preprocessed_v1</td>\n",
       "      <td>0.523068</td>\n",
       "      <td>0.310635</td>\n",
       "      <td>0.129385</td>\n",
       "      <td>0.284882</td>\n",
       "      <td>0.5638</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.4789</td>\n",
       "      <td>47.0228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-03 14:42:29</td>\n",
       "      <td>preprocessed_v2_full</td>\n",
       "      <td>0.527580</td>\n",
       "      <td>0.313429</td>\n",
       "      <td>0.125728</td>\n",
       "      <td>0.288991</td>\n",
       "      <td>0.5624</td>\n",
       "      <td>0.3668</td>\n",
       "      <td>0.4785</td>\n",
       "      <td>46.9238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-12-04 03:30:26</td>\n",
       "      <td>preprocessed_v2_input_only</td>\n",
       "      <td>0.527293</td>\n",
       "      <td>0.307280</td>\n",
       "      <td>0.124184</td>\n",
       "      <td>0.282453</td>\n",
       "      <td>0.5693</td>\n",
       "      <td>0.3733</td>\n",
       "      <td>0.4854</td>\n",
       "      <td>47.6004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-12-04 06:02:58</td>\n",
       "      <td>preprocessed_v3_turntrunc</td>\n",
       "      <td>0.527554</td>\n",
       "      <td>0.308070</td>\n",
       "      <td>0.126483</td>\n",
       "      <td>0.284264</td>\n",
       "      <td>0.5699</td>\n",
       "      <td>0.3707</td>\n",
       "      <td>0.4814</td>\n",
       "      <td>47.4004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-12-04 07:14:39</td>\n",
       "      <td>preprocessed_v4_topicprefix</td>\n",
       "      <td>0.527666</td>\n",
       "      <td>0.310780</td>\n",
       "      <td>0.127985</td>\n",
       "      <td>0.288019</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.3686</td>\n",
       "      <td>0.4791</td>\n",
       "      <td>47.0793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-12-04 08:25:09</td>\n",
       "      <td>preprocessed_v5_lenfilter</td>\n",
       "      <td>0.528613</td>\n",
       "      <td>0.306045</td>\n",
       "      <td>0.126092</td>\n",
       "      <td>0.281842</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                     exp_name  eval_loss  eval_rouge_1  \\\n",
       "0  2025-11-28 18:01:14                  baseline_v1   0.596968      0.154657   \n",
       "1  2025-12-03 10:17:28              preprocessed_v1   0.523068      0.310635   \n",
       "2  2025-12-03 14:42:29         preprocessed_v2_full   0.527580      0.313429   \n",
       "3  2025-12-04 03:30:26   preprocessed_v2_input_only   0.527293      0.307280   \n",
       "4  2025-12-04 06:02:58    preprocessed_v3_turntrunc   0.527554      0.308070   \n",
       "5  2025-12-04 07:14:39  preprocessed_v4_topicprefix   0.527666      0.310780   \n",
       "6  2025-12-04 08:25:09    preprocessed_v5_lenfilter   0.528613      0.306045   \n",
       "\n",
       "   eval_rouge_2  eval_rouge_l lb_rouge_1 lb_rouge_2 lb_rouge_l lb_final  \n",
       "0      0.042543      0.148929     0.5634     0.3668     0.4819  47.0683  \n",
       "1      0.129385      0.284882     0.5638      0.368     0.4789  47.0228  \n",
       "2      0.125728      0.288991     0.5624     0.3668     0.4785  46.9238  \n",
       "3      0.124184      0.282453     0.5693     0.3733     0.4854  47.6004  \n",
       "4      0.126483      0.284264     0.5699     0.3707     0.4814  47.4004  \n",
       "5      0.127985      0.288019     0.5647     0.3686     0.4791  47.0793  \n",
       "6      0.126092      0.281842          -          -          -        -  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ì ìˆ˜ë§Œ ë³´ê¸°\n",
    "display(exp_log[[\"timestamp\", \"exp_name\", \"eval_loss\", \"eval_rouge_1\", \"eval_rouge_2\", \"eval_rouge_l\", \"lb_rouge_1\", \"lb_rouge_2\", \"lb_rouge_l\", \"lb_final\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_467899/1138885340.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  exp_log.loc[n, \"lb_rouge_1\"] = \"-\"\n",
      "/tmp/ipykernel_467899/1138885340.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  exp_log.loc[n, \"lb_rouge_2\"] = \"-\"\n",
      "/tmp/ipykernel_467899/1138885340.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  exp_log.loc[n, \"lb_rouge_l\"] = \"-\"\n",
      "/tmp/ipykernel_467899/1138885340.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  exp_log.loc[n, \"lb_final\"]   = \"-\"\n"
     ]
    }
   ],
   "source": [
    "# # ë¦¬ë”ë³´ë“œ ê°’ ì¶”ê°€í•˜ê¸°\n",
    "# n=\n",
    "# exp_log.loc[n, \"lb_rouge_1\"] = 0.5647\n",
    "# exp_log.loc[n, \"lb_rouge_2\"] = 0.3686\n",
    "# exp_log.loc[n, \"lb_rouge_l\"] = 0.4791\n",
    "# exp_log.loc[n, \"lb_final\"]   = 47.0793\n",
    "\n",
    "# exp_log.to_csv(log_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ì¤‘ë³µ í–‰ ì‚­ì œí•˜ê¸°\n",
    "# exp_log = exp_log.drop(index=n).reset_index(drop=True)\n",
    "# exp_log.to_csv(log_path, index=False)\n",
    "\n",
    "# # íŠ¹ì • ì…€ ê°’ë§Œ ë³€ê²½í•˜ê¸°\n",
    "# exp_log.loc[n, \"exp_name\"] = \"preprocessed_v2_full\"\n",
    "# exp_log.to_csv(log_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²˜ë¦¬\n",
    "# ë°ì´í„° ì¦ê°•, hard case ë¶„ì„, error patternì— ë”°ë¥¸ rule ì¶”ê°€\n",
    "# Solar + baseline ì¡°í•©\n",
    "#     (1) ì—ëŸ¬ ì¼€ì´ìŠ¤ì— í•œí•´ Solarë¡œ í›„ì²˜ë¦¬\n",
    "#     (2) baseline ìš”ì•½ì´ ë„ˆë¬´ ì§§ì„ ë•Œë§Œ Solar ì¬ìš”ì•½"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "NLP venv",
   "language": "python",
   "name": "nlp-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "083ea69907bb48d4a8fff919bac51aad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08d05bc20a96432badd459e1ffaf868e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13651c09564a4337b8274c1cb436faa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14f6c91d6c634379b498586c51e606e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21d2e54b5a0a4f79973a512105da43eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2307c6dcbe0141acb5e61baae19cade7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "285007b45236478ca147c6df752c8da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a190bda0b72407e9a953cd2104dd3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fd3d7bbcd6948d8904d33001f95ea03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3645438ace1f4596a8dbc157b48c1521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14f6c91d6c634379b498586c51e606e0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_08d05bc20a96432badd459e1ffaf868e",
      "value": " 295/295 [00:00&lt;00:00, 21.3kB/s]"
     }
    },
    "3a04e871b74b45d7bf02fd33bb103577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bcd6b6b956347b29e1efa20a1d00542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c284a826f6843f6aa47eacad478ac30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_affff1d8a89e4c14955d1b2aa39ff1ab",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_13651c09564a4337b8274c1cb436faa5",
      "value": "tokenizer.json: 100%"
     }
    },
    "45187decb58b4ad39ad532259c6277e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4747b668e2fa4ab58a449446f80030f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52095cc7087243ac916055e569fd22f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c18f0e3bc35e44d9915c3f84cd282a26",
      "max": 109,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a04e871b74b45d7bf02fd33bb103577",
      "value": 109
     }
    },
    "58001a60eacc44d5b38a68648adccde4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58c794fb7ce543a39fdf66d757f6eeab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f5fde5b0ac840a18bd5cc380e564ff6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_45187decb58b4ad39ad532259c6277e5",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "5dfcf310ca9e4e2794076098a5d69cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c284a826f6843f6aa47eacad478ac30",
       "IPY_MODEL_6caedd60c6b747469c82930be1f95d6d",
       "IPY_MODEL_64f2218f899d446393cfea44f206f0a6"
      ],
      "layout": "IPY_MODEL_d068f541df3f438dbd5138863e64b2f2"
     }
    },
    "64f2218f899d446393cfea44f206f0a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d22fbc2c5dbf422399e496c9b500025a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_775d8bbeceac4e2da4f21ab6235c89ed",
      "value": " 682k/682k [00:00&lt;00:00, 5.40MB/s]"
     }
    },
    "6caedd60c6b747469c82930be1f95d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bcd6b6b956347b29e1efa20a1d00542",
      "max": 682133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fd3d7bbcd6948d8904d33001f95ea03",
      "value": 682133
     }
    },
    "6f5fde5b0ac840a18bd5cc380e564ff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775d8bbeceac4e2da4f21ab6235c89ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a6464a355f7464c989033965d418a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2307c6dcbe0141acb5e61baae19cade7",
      "max": 295,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4747b668e2fa4ab58a449446f80030f5",
      "value": 295
     }
    },
    "a15af9e8158f4903b9189f3d322a5ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac00d6c2cf974b33a628acb3f1471316",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_285007b45236478ca147c6df752c8da4",
      "value": " 109/109 [00:00&lt;00:00, 9.44kB/s]"
     }
    },
    "ac00d6c2cf974b33a628acb3f1471316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "affff1d8a89e4c14955d1b2aa39ff1ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18f0e3bc35e44d9915c3f84cd282a26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d068f541df3f438dbd5138863e64b2f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d22fbc2c5dbf422399e496c9b500025a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de1a3f7701c243839fe03b930a9b9e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebc22683058a4f229c5588e52fc93536",
       "IPY_MODEL_52095cc7087243ac916055e569fd22f3",
       "IPY_MODEL_a15af9e8158f4903b9189f3d322a5ef3"
      ],
      "layout": "IPY_MODEL_21d2e54b5a0a4f79973a512105da43eb"
     }
    },
    "e920dbc173c045d1a32143349f1dff8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58c794fb7ce543a39fdf66d757f6eeab",
       "IPY_MODEL_8a6464a355f7464c989033965d418a8a",
       "IPY_MODEL_3645438ace1f4596a8dbc157b48c1521"
      ],
      "layout": "IPY_MODEL_58001a60eacc44d5b38a68648adccde4"
     }
    },
    "ebc22683058a4f229c5588e52fc93536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_083ea69907bb48d4a8fff919bac51aad",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2a190bda0b72407e9a953cd2104dd3b2",
      "value": "special_tokens_map.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
