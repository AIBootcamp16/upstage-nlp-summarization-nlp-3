<!-- Header -->
<div align="center">

![header](https://capsule-render.vercel.app/api?type=rounded&height=170&text=Dialogue%20Summarization&desc=%EC%9D%BC%EC%83%81%20%EB%8C%80%ED%99%94%20%EC%9A%94%EC%95%BD%20NLP%20%EB%8C%80%ED%9A%8C%20%ED%8C%80%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8&fontSize=35&descSize=15&descAlignY=65&color=gradient&fontColor=ffffff&animation=fadeIn)

<h3>ğŸ—£ï¸ Encoderâ€“Decoder + LLM ê¸°ë°˜ ì¼ìƒ ëŒ€í™” ìš”ì•½ ëª¨ë¸ Â· Dialogue Summarization Competition ğŸ—£ï¸</h3>

</div>

---

## ğŸ’» í”„ë¡œì íŠ¸ ì†Œê°œ

### ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”

ì´ ë¦¬í¬ì§€í† ë¦¬ëŠ” **ì¼ìƒ ëŒ€í™”(dialogue)ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ 1~2ë¬¸ì¥ ìš”ì•½(summary)ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸**ì„ êµ¬ì¶•í•œ  
NLP ëŒ€íšŒ(team)ìš© ì½”ë“œ ë° ì‹¤í—˜ ê²°ê³¼ë¥¼ ì •ë¦¬í•œ ì €ì¥ì†Œì…ë‹ˆë‹¤.

- **Task**: Dialogue Summarization (Abstractive Summarization)  
- **Main Models**:  
  - Encoderâ€“Decoder: `digit82/kobart-summarization`, `gogamza/kobart-base-v1`, `wisenut-nlp-team/KoT5-base`  
  - Decoder-only & LLM: `Llama-3.2-1B-Instruct`, `Llama-3-8B-Instruct`, ê¸°íƒ€ gemma / HyperCLOVAX ë“±  
- **Goal**:  
  - ëŒ€í™” ë‚´ìš©ì„ **ì‚¬ì‹¤ ê¸°ë°˜ìœ¼ë¡œ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½**  
  - ë‹¤ì–‘í•œ ëª¨ë¸/ì „ì²˜ë¦¬/íŠœë‹ ì „ëµ ë¹„êµ  
- **Metric**: ROUGE-1 / ROUGE-2 / ROUGE-L (F1 í‰ê· )

> ì´ ë¦¬í¬ì§€í† ë¦¬ëŠ”  
> **EDA â†’ ì „ì²˜ë¦¬ ì „ëµ â†’ KoBART/KoT5 íŒŒì¸íŠœë‹ â†’ LLM ë¹„êµ ì‹¤í—˜ â†’ Ablation & ì‹¤íŒ¨ ì‹¤í—˜ ë¶„ì„ â†’ ìµœì¢… ì œì¶œ**  
> ì „ì²´ ì‹¤í—˜ ê³¼ì •ì„ íŒ€ ë‹¨ìœ„ë¡œ ì¬í˜„í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

> ì‹¤ì œ í´ë” êµ¬ì„±ì— ë§ê²Œ ì¼ë¶€ ê²½ë¡œë¥¼ ìˆ˜ì •í•´ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

```bash
nlp-competition/
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config_kobart.yaml           # KoBART ì‹¤í—˜ ì„¤ì •
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # ëŒ€íšŒ ì œê³µ ì›ë³¸ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â”œâ”€â”€ dev.csv
â”‚   â”‚   â”œâ”€â”€ test.csv
â”‚   â”‚   â””â”€â”€ sample_submission.csv
â”‚   â””â”€â”€ processed/                   # ì „ì²˜ë¦¬ í›„ ë°ì´í„°
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda/
â”‚   â”‚   â”œâ”€â”€ eda_overview.ipynb       # ê³µí†µ EDA
â”‚   â”‚   â””â”€â”€ eda_v2_input_only.ipynb  # ì „ì²˜ë¦¬ v2_input_only ë¶„ì„
â”‚   â”œâ”€â”€ 02_preprocessing/
â”‚   â”‚   â””â”€â”€ preprocessing_v2_input_only.ipynb
â”‚   â”œâ”€â”€ 03_modeling_kobart/
â”‚   â”‚   â”œâ”€â”€ modeling_kobart_baseline.ipynb
â”‚   â”‚   â””â”€â”€ modeling_kobart_ls_wd.ipynb
â”‚   â”œâ”€â”€ 04_modeling_kot5/
â”‚   â”‚   â””â”€â”€ modeling_kot5.ipynb
â”‚   â”œâ”€â”€ 05_modeling_llm/
â”‚   â”‚   â”œâ”€â”€ modeling_llama_1b.ipynb
â”‚   â”‚   â””â”€â”€ modeling_llama_8b_qLoRA.ipynb
â”‚   â”œâ”€â”€ baseline.ipynb               # ëŒ€íšŒ ì œê³µ baseline ì°¸ê³ 
â”‚   â””â”€â”€ baseline_solar.ipynb         # Solar API ì¬ìš”ì•½ ì‹¤í—˜
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ prediction/
â”‚   â”‚   â”œâ”€â”€ kobart_v2_input_only.csv
â”‚   â”‚   â”œâ”€â”€ kobart_v2_input_only_wd0.01_ls0.1.csv
â”‚   â”‚   â””â”€â”€ kot5_overlap_inference.csv
â”‚   â””â”€â”€ exp_log.csv                  # ì‹¤í—˜ ë¡œê·¸ (ë²„ì „/ìŠ¤ì½”ì–´ ì •ë¦¬)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ preprocessing.py         # ì „ì²˜ë¦¬ í•¨ìˆ˜ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train_kobart.py
â”‚   â”‚   â”œâ”€â”€ train_kot5.py
â”‚   â”‚   â””â”€â”€ train_llama_lora.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ metrics.py               # ROUGE ê³„ì‚° ë“±
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
````

---

## ğŸ§ª ëŒ€íšŒ & ë°ì´í„° ìš”ì•½

### ğŸ¯ ëŒ€íšŒ ì •ë³´

* **ëŒ€íšŒ ì´ë¦„**: Dialogue Summarization
* **ëª©í‘œ**: ì¼ìƒ ëŒ€í™”ë¥¼ ì…ë ¥ë°›ì•„ í•µì‹¬ ìš”ì•½ë¬¸ 1~2ë¬¸ì¥ì„ ìƒì„±
* **í‰ê°€ ì§€í‘œ**: ROUGE-1 / ROUGE-2 / ROUGE-L F1 í‰ê·  (reference 3ê°œ í‰ê· )

### ğŸ§¾ ë°ì´í„° êµ¬ì„±

| íŒŒì¼        | ê°œìˆ˜     | ì„¤ëª…                         |
| --------- | ------ | -------------------------- |
| train.csv | 12,4xx | dialogue + summary + topic |
| dev.csv   | 498    | ê²€ì¦ìš©                        |
| test.csv  | 499    | summary ì—†ìŒ                 |

ê° ìƒ˜í”Œ ì˜ˆì‹œ:

```csv
fname,dialogue,summary,topic
train_0,"#Person1#: ...", "ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ëŸ¬ ì˜¨ #Person1#ì´ ...", "ê±´ê°•ê²€ì§„"
```

---

## ğŸ§· ë¬¸ì œ ì •ì˜ & ìš”ì•½ í’ˆì§ˆ ê¸°ì¤€

ëª¨ë¸ì´ ë§Œë“¤ì–´ì•¼ í•  **â€œì¢‹ì€ ìš”ì•½â€** ì€ ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤.

* ğŸ”„ **ì—­í•  ë³´ì¡´**

  * `#Person1#`, `#Person2#` ë“± í™”ì ì—­í• ì´ ë’¤ë°”ë€Œì§€ ì•Šì„ ê²ƒ
* ğŸ§¾ **ì‚¬ì‹¤ ê¸°ë°˜**

  * ëŒ€í™”ì— ì—†ëŠ” ë‚´ìš©ì„ **ì¶”ê°€ë¡œ ì§€ì–´ë‚´ì§€ ì•Šì„ ê²ƒ (no hallucination)**
* âœ‚ **ê¸¸ì´ ì œì•½**

  * 1~2ë¬¸ì¥, ì›ë¬¸ ê¸¸ì´ì˜ ì•½ 20% ì´ë‚´
* â± **ì‹œì  ìœ ì§€**

  * ì´ë¯¸ ì¼ì–´ë‚œ ì¼ vs ì•ìœ¼ë¡œ í•  ì¼ì„ êµ¬ë¶„í•´ì„œ í‘œí˜„
* â™» **ì¤‘ë³µ ìµœì†Œí™”**

  * ê°™ì€ ì •ë³´ë¥¼ ë¶ˆí•„ìš”í•˜ê²Œ ë°˜ë³µí•˜ì§€ ì•Šê¸°

ì‹¤í—˜ ì¤‘ ìì£¼ ê´€ì¸¡ëœ ì‹¤íŒ¨ íŒ¨í„´:

* `#Person1#` â†” `#Person2#` ì—­í•  ë’¤ë°”ë€œ
* ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì‚¬ê±´ ìƒì„±
* ê¸´ ëŒ€í™”ì—ì„œ ì‚¬ê±´ ìˆœì„œ ê¼¬ì„
* ì˜ëª»ëœ CoT(prompt) ë¶™ì´ê¸° â†’ ìš”ì•½ ì „ì²´ ë¶•ê´´

> ì´ ê¸°ì¤€ì„ ë°”íƒ•ìœ¼ë¡œ **ì…ë ¥ í…œí”Œë¦¿, ì „ì²˜ë¦¬ ì„¤ê³„, ëª¨ë¸ ì„ íƒ, í›„ì²˜ë¦¬ ê·œì¹™**ì„ ì •í–ˆìŠµë‹ˆë‹¤.

---

## ğŸ” EDA & ì „ì²˜ë¦¬ ì „ëµ

### 1ï¸âƒ£ EDA í•µì‹¬ ì¸ì‚¬ì´íŠ¸

* Dialogue ê¸¸ì´: í‰ê·  **320â€“360 tokens**, long-tail ë¶„í¬
* Summary:

  * ëŒ€ë¶€ë¶„ **í•œ ë¬¸ì¥**
  * 100~110ì ë‚´ì™¸, â€œ~ë‹¤.â€ ì¢…ê²°
* Topic:

  * summaryì— **ë¬¸ì ê·¸ëŒ€ë¡œ** ë“±ì¥í•˜ëŠ” ë¹„ìœ¨ì€ ë‚®ì§€ë§Œ
  * ì˜ë¯¸ì ì¸ ë°©í–¥ì„±ì€ ì œê³µ
* Noise:

  * â€œã…‹ã…‹ã…‹, ã…ã…, ã… ã… , ìŒâ€¦, ì•„â€¦â€ ë“± ê°ì •/ê°íƒ„ì‚¬ ë‹¤ìˆ˜
  * ìš”ì•½ì—ëŠ” ê±°ì˜ ë°˜ì˜ë˜ì§€ ì•ŠìŒ â†’ encoder ì…ì¥ì—ì„œ **ì¡ìŒ**

ğŸ“Œ **ê²°ë¡ **

* âœ‚ **ì…ë ¥ ì „ì²˜ë¦¬ëŠ” ê³µê²©ì ìœ¼ë¡œ**,
* ğŸ§¼ **ì¶œë ¥(summary) ì „ì²˜ë¦¬ëŠ” ìµœì†Œí™”** í•´ì•¼ ì„±ëŠ¥ì´ ì˜¤ë¥¸ë‹¤.

---

### 2ï¸âƒ£ ì „ì²˜ë¦¬ ë²„ì „ ì‹¤í—˜ ìš”ì•½

| ë²„ì „                | ì„¤ëª…                             | ê²°ê³¼ / ê²°ë¡                             |
| ----------------- | ------------------------------ | ---------------------------------- |
| v1                | baseline ì „ì²˜ë¦¬                   | ì°¸ê³ ìš©                                |
| v2_full           | ì…ë ¥ + ì¶œë ¥ ëª¨ë‘ ì „ì²˜ë¦¬                 | ì¶œë ¥ ì†ìƒ â†’ label bias â†’ ê°œì„  ì—†ìŒ         |
| **v2_input_only** | **ì…ë ¥ë§Œ ê³µê²©ì ìœ¼ë¡œ ì •ì œ (noise ì œê±°)**    | **LB +0.5pt í–¥ìƒ â†’ ìµœì¢… ì±„íƒ**           |
| v3                | truncation                     | ì¤‘ìš”í•œ ë¬¸ë§¥ê¹Œì§€ ì˜ë ¤ë‚˜ê°€ ì„±ëŠ¥ í•˜ë½                |
| v4                | topic prefix ì¶”ê°€                | ì •ë³´ ì¤‘ë³µ/ë…¸ì´ì¦ˆ ì¦ê°€ â†’ íš¨ê³¼ ì—†ìŒ               |
| v5â€“v6             | ê¸¸ì´ ê¸°ë°˜ filtering, unigram í•„í„°ë§ ë“± | ë°ì´í„° ë¶„í¬ ì™œê³¡ / abstract sample ì œê±° â†’ â†“ |

ğŸ“Œ **ìµœì¢… ê²°ë¡ **

> "ì…ë ¥ë§Œ ì „ì²˜ë¦¬í•˜ê³ , ì¶œë ¥(summary)ì€ ì ˆëŒ€ ì†ëŒ€ì§€ ì•ŠëŠ”ë‹¤."

---

## ğŸ¤– ëª¨ë¸ë§ ê°œìš”

ì´ í”„ë¡œì íŠ¸ì—ì„œëŠ” **Encoderâ€“Decoder ê³„ì—´(ì£¼ë ¥)** ê³¼
**Decoder-only LLM ê³„ì—´(ë¹„êµ/ì—°êµ¬ìš©)** ì„ í•¨ê»˜ ì‹¤í—˜í–ˆìŠµë‹ˆë‹¤.

---

### 1ï¸âƒ£ Encoderâ€“Decoder ê³„ì—´ (Main)

#### ğŸ§© KoBART (`digit82/kobart-summarization`)

**ì—­í• **

* íŒ€ ê³µí†µ **Baseline & ìµœì¢… ì œì¶œìš© ì£¼ë ¥ ëª¨ë¸**

**ì„¤ì • (ìµœì¢… ì„¸íŒ…)**

* encoder_max_len: 512
* decoder_max_len: 100
* LR: `1e-5`
* Epochs: `20`
* Train batch: 50
* Weight decay: `0.01`
* Label smoothing: `0.1`
* Warmup: 0.1 (cosine scheduler)
* Early stopping: patience=3
* ì „ì²˜ë¦¬: **v2_input_only**

#### ğŸ§© gogamza/kobart-base-v1

**íŠ¹ì§•**

* í•œêµ­ì–´ ë¬¸ì¥ êµ¬ì¡°Â·ëŒ€í™” íŒ¨í„´ì— ê°•í•¨
* encoder_max_lenì„ **1024**ê¹Œì§€ í™•ì¥í•´ ê¸´ ëŒ€í™” ì²˜ë¦¬

**ê´€ì°°**

* Public LB: total ROUGE â‰ˆ 50.01
* Private LB: 46.5ë¡œ ê¸‰ë½ â†’ Public overfit ê²½í–¥

#### ğŸ§© KoT5 (`wisenut-nlp-team/KoT5-base`)

**ì„¤ì •**

* encoder_max_len = 896
* decoder_max_len = 80
* LR = `3e-4`
* batch_size = 4 (VRAM ì—¬ìœ  ì‹œ 8 ê¶Œì¥)
* gradient_accumulation_steps = 2
* epochs = 5, fp32
* overlap ê¸°ë²•ìœ¼ë¡œ ë¬¸ì¥ ì˜ë¦¼ ì¼ë¶€ ì™„í™”

**ê´€ì°°**

* Public: 49.7 (ì´ˆë°˜ 2ë“± ìˆ˜ì¤€)
* Private: **47.5** (ì¼ë°˜í™” ì„±ëŠ¥ ê°€ì¥ ì•ˆì •ì ì¸ ì¶• ì¤‘ í•˜ë‚˜)
* í•˜ì§€ë§Œ **ì‹œê°„/íš¨ìœ¨ ë©´ì—ì„œ KoBARTê°€ ë” ìœ ë¦¬**í•˜ì—¬
  ìµœì¢… íŒŒì´í”„ë¼ì¸ì€ KoBART ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±

---

### 2ï¸âƒ£ Decoder-only & LLM ê³„ì—´

#### ğŸ‘ Llama-3.2-1B-Instruct + LoRA

* í•™ìŠµ ì‹œê°„: ì•½ 46ë¶„, ì¶”ë¡  8ë¶„
* LoRA ê¸°ë°˜ íŒŒë¼ë¯¸í„° íš¨ìœ¨ íŠœë‹
* ê²°ê³¼: **LB 47.8310**

> âœ… 8B ëª¨ë¸ ëŒ€ë¹„ ì„±ëŠ¥ì°¨ ê±°ì˜ ì—†ìŒ
> âœ… í•™ìŠµ/ì¶”ë¡  ì†ë„Â·ë¹„ìš©ì´ ë§¤ìš° ì €ë ´ â†’ ì‹¤í—˜ íš¨ìœ¨ ìµœê³ 

#### ğŸ‘ Llama-3-8B-Instruct + QLoRA

* 3090 í™˜ê²½ì—ì„œ QLoRAë¡œ í•™ìŠµ
* í•™ìŠµ ì‹œê°„: ì•½ 7ì‹œê°„
* SYSTEM/USER í”„ë¡¬í”„íŠ¸ì— **ë§¤ìš° ë¯¼ê°**, ì˜ëª» ì„¤ê³„ ì‹œ

  * ì„¤ëª…í˜• ì¥ë¬¸ ì¶œë ¥
  * ìš”ì•½ ê¸¸ì´ ê³¼ë„ â†’ ROUGE ê¸‰ë½

#### ê¸°íƒ€ Decoder-only ëª¨ë¸

* `gemma-7b`, `HyperCLOVAX-SEED-Text-Instruct-1.5B`, `kanana-nano-2.1b` ë“±
* ì¼ë¶€ëŠ” í”„ë¡¬í”„íŠ¸/ì½”ë”© ì´ìŠˆë¡œ ì¶œë ¥ í’ˆì§ˆì´ ë¶ˆì•ˆì •í•˜ì—¬
  **ìŠ¤ëª¨í¬ëŸ° ìˆ˜ì¤€ì—ì„œ ì¢…ë£Œ**

---

### 3ï¸âƒ£ Solar API (í›„ì²˜ë¦¬/ì¬ì‘ì„± ì‹¤í—˜)

* Input: ì›ë¬¸ ëŒ€í™” + KoBART/KoT5 ìš”ì•½
* Task: Solar Proë¡œ â€œë‹¤ì‹œ ìš”ì•½â€ ì‹œí‚¤ê¸° (post-editing)

**ê²°ê³¼**

* ì‚¬ëŒì´ ë³´ê¸°ì—ëŠ” í›¨ì”¬ ìì—°ìŠ¤ëŸ½ê³  ë¶€ë“œëŸ¬ìš´ ìš”ì•½
* í•˜ì§€ë§Œ **ROUGE ê¸°ì¤€ìœ¼ë¡œëŠ” KoBART ë‹¨ë…ë³´ë‹¤ í•­ìƒ ë‚®ìŒ**

> â¡ ì‹¤ì œ ì„œë¹„ìŠ¤ë¼ë©´ â€œì¸ê°„ í‰ê°€ + ìë™ì§€í‘œâ€ë¥¼ í•¨ê»˜ ë´ì•¼ê² ì§€ë§Œ,
> ì´ë²ˆ ëŒ€íšŒ ì„¸íŒ…(ROUGE ìµœì í™”)ì—ì„œëŠ” **Solar í›„ì²˜ë¦¬ë¥¼ ì œì™¸**í–ˆìŠµë‹ˆë‹¤.

---

## ğŸ“Š ì„±ëŠ¥ ê²°ê³¼ ìš”ì•½

### âœ… KoBART

| ì‹¤í—˜ëª…                              | ì „ì²˜ë¦¬      | ì£¼ìš” ì„¤ì •                | Dev ROUGE-L | LB          |
| -------------------------------- | -------- | -------------------- | ----------- | ----------- |
| baseline_v1                      | baseline | ê¸°ë³¸                   | ~0.27       | 47.06       |
| v2_input_only                    | ì…ë ¥ë§Œ ì •ì œ   | ê¸°ë³¸                   | 0.282       | 47.6004     |
| **v2_input_only + WD + LS (ìµœì¢…)** | ì…ë ¥ë§Œ ì •ì œ   | **LS 0.1 + WD 0.01** | **0.298**   | **47.8581** |

### âœ… KoT5 / ê¸°íƒ€

* KoT5-base:

  * Public: 49.7
  * Private: **47.5**

### âœ… LLM

* Llama-3.2-1B + LoRA:

  * LB: **47.8310**
* Llama-3-8B + QLoRA:

  * 1B ëŒ€ë¹„ ëšœë ·í•œ ìš°ìœ„ X, ë¹„ìš©ì€ í›¨ì”¬ í¼

---

## ğŸ§­ ì „ì²´ íŒŒì´í”„ë¼ì¸

```text
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   Raw Data   â”‚
               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚        EDA ë¶„ì„        â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Preprocess v2_input_only    â”‚
      â”‚  - noise ì œê±°                â”‚
      â”‚  - leakage í† í° ì œê±° X       â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   Tokenization (512/100)   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  KoBART Fine-tuning (20ep) â”‚
     â”‚  + LS 0.1 + WD 0.01        â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Best Checkpoint Selection (ROUGE-L)   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚    Beam Search (num_beams=4)  â”‚
       â”‚  no_repeat_ngram=2, max_len=100 â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Final Output  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Decoder-only / LLM ì‹¤í—˜ì€ ìœ„ íŒŒì´í”„ë¼ì¸ ì¤‘
**â€œëª¨ë¸ë§ ë¸”ë¡(Modeling)â€** ì„ êµì²´í•˜ì—¬ ì‹¤í—˜í•œ ë³„ë„ ë¼ì¸ì…ë‹ˆë‹¤.

---

## ğŸ›  ì‚¬ìš© ë°©ë²• (How to Run)

### 1ï¸âƒ£ ë°ì´í„° ì¤€ë¹„

```bash
data/raw/train.csv
data/raw/dev.csv
data/raw/test.csv
data/raw/sample_submission.csv
```

### 2ï¸âƒ£ EDA ì‹¤í–‰

```bash
notebooks/01_eda/eda_overview.ipynb
notebooks/01_eda/eda_v2_input_only.ipynb
```

### 3ï¸âƒ£ ì „ì²˜ë¦¬ ì‹¤í–‰

```bash
notebooks/02_preprocessing/preprocessing_v2_input_only.ipynb
```

### 4ï¸âƒ£ KoBART ëª¨ë¸ í•™ìŠµ

```bash
notebooks/03_modeling_kobart/modeling_kobart_ls_wd.ipynb
# ë˜ëŠ”
python src/models/train_kobart.py --config configs/config_kobart.yaml
```

### 5ï¸âƒ£ ì œì¶œ íŒŒì¼ ìƒì„±

```bash
outputs/prediction/kobart_v2_input_only_wd0.01_ls0.1.csv
```

---

## ğŸ™‹â€â™€ï¸ íŒ€ & ë¸Œëœì¹˜ ì „ëµ

| ë¸Œëœì¹˜       | ì—­í•                        |
| --------- | ------------------------ |
| **main**  | ìµœì¢… ë¦¬ë”ë³´ë“œ ì œì¶œìš© / ì•ˆì • ë²„ì „      |
| **dev**   | ê³µí†µ ì½”ë“œÂ·ì „ì²˜ë¦¬Â·íŒŒì´í”„ë¼ì¸ ê°œë°œ       |
| **\*-dev** | íŒ€ì›ë³„ ì‹¤í—˜ ë¸Œëœì¹˜ (KoT5, LLM ë“±) |

---

## ğŸ§  íšŒê³  & ë°°ìš´ ì 

### âœ¨ í•µì‹¬ ì¸ì‚¬ì´íŠ¸

* **ì…ë ¥ ì „ì²˜ë¦¬ë§Œ ì˜í•´ë„** ìš”ì•½ ëª¨ë¸ í’ˆì§ˆì´ í¬ê²Œ í–¥ìƒëœë‹¤.
* Label smoothing, weight decay ê°™ì€ **loss/regularization ì„¤ê³„**ê°€
  decoding íŠœë‹ë³´ë‹¤ í›¨ì”¬ í° ì˜í–¥ì„ ì¤€ë‹¤.
* ìµœì‹  LLM(Decoder-only)ì´ í•­ìƒ ìµœì„ ì€ ì•„ë‹ˆë©°,
  **íƒœìŠ¤í¬ íŠ¹ì„±ìƒ Encoderâ€“Decoder(KoBART, KoT5)ê°€ ë” ì í•©**í•  ìˆ˜ ìˆë‹¤.
* ROUGE ê¸°ë°˜ ëŒ€íšŒì—ì„œëŠ”
  â€œìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥â€ë³´ë‹¤ **referenceì™€ì˜ ê²¹ì¹¨**ì´ ë” ì¤‘ìš”í•˜ë‹¤.

### ğŸ‘¥ í˜‘ì—… ì¸¡ë©´ì—ì„œ ì–»ì€ ì 

* LLM ê²½ì§„ëŒ€íšŒëŠ”
  í•œ ì‚¬ëŒì´ ëª¨ë“  ì‹¤í—˜ì„ ëê¹Œì§€ íŒŒë³´ëŠ” ê²ƒë³´ë‹¤
  **ëª¨ë¸Â·ì˜ì—­ë³„ ì—­í•  ë¶„ë‹´ + ë³‘ë ¬ ì‹¤í—˜ + ë¹ ë¥¸ ê³µìœ **ê°€ í›¨ì”¬ ì¤‘ìš”í–ˆë‹¤.
* ì´ë¯¸ì§€ ë¶„ë¥˜ ëŒ€íšŒì™€ ë‹¬ë¦¬,
  **â€œíŒ€ ë‹¨ìœ„ë¡œ ì›€ì§ì´ëŠ” ê²ƒì´ ì „ì œëœ íƒœìŠ¤í¬â€** ë¼ëŠ” ê²ƒì„ ì‹¤ì œë¡œ ì²´ê°í–ˆë‹¤.

---

## ğŸ“« Contact

ë²„ê·¸ ì œë³´, ê°œì„  ì œì•ˆ, ì§ˆë¬¸ ë“±ì€
ğŸ‘‰ GitHub Issue ë˜ëŠ” Pull Requestë¡œ ë‚¨ê²¨ì£¼ì„¸ìš”.
